{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jwonne/RL_Shared-Control/blob/main/JW_pytorch_realnvp_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-03-15T00:33:27.979800Z",
          "start_time": "2022-03-15T00:33:26.713172Z"
        },
        "id": "SppESO-AD7yL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.transforms import ToTensor, Lambda\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-03-15T00:33:27.999829Z",
          "start_time": "2022-03-15T00:33:27.981836Z"
        },
        "scrolled": true,
        "id": "o9ahb4PxD7yN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e16da1dd-e27a-4048-997c-004716df3200"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cuda available: True\n",
            "Current device: 0\n",
            "Device: cuda:0\n",
            "Device count: 1\n",
            "Device name: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "available = torch.cuda.is_available()\n",
        "curr_device = torch.cuda.current_device()\n",
        "device = torch.device(\"cuda:0\" if available else \"cpu\")\n",
        "device_count = torch.cuda.device_count()\n",
        "device_name =  torch.cuda.get_device_name(0)\n",
        "\n",
        "print(f'Cuda available: {available}')\n",
        "print(f'Current device: {curr_device}')\n",
        "print(f'Device: {device}')\n",
        "print(f'Device count: {device_count}')\n",
        "print(f'Device name: {device_name}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-03-15T00:33:28.097169Z",
          "start_time": "2022-03-15T00:33:28.001249Z"
        },
        "id": "IPlfAGCfD7yO"
      },
      "outputs": [],
      "source": [
        "# (Adapted) Code from PyTorch's Resnet impl: https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py\n",
        "\n",
        "def conv3x3(in_planes: int, out_planes: int, stride: int = 1, groups: int = 1, dilation: int = 1) -> nn.Conv2d:\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(\n",
        "        in_planes,\n",
        "        out_planes,\n",
        "        kernel_size=3,\n",
        "        stride=stride,\n",
        "        padding=dilation,\n",
        "        groups=groups,\n",
        "        bias=False,\n",
        "        dilation=dilation,\n",
        "    )\n",
        "\n",
        "\n",
        "def conv1x1(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:\n",
        "    \"\"\"1x1 convolution\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion: int = 1\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        inplanes: int,\n",
        "        planes: int,\n",
        "        stride: int = 1,\n",
        "        downsample = None,\n",
        "        groups: int = 1,\n",
        "        base_width: int = 64,\n",
        "        dilation: int = 1,\n",
        "        norm_layer = None,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        if norm_layer is None:\n",
        "            # norm_layer = nn.BatchNorm2d\n",
        "            norm_layer = nn.InstanceNorm2d\n",
        "        if groups != 1 or base_width != 64:\n",
        "            raise ValueError(\"BasicBlock only supports groups=1 and base_width=64\")\n",
        "        if dilation > 1:\n",
        "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
        "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = norm_layer(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = norm_layer(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)\n",
        "    # while original implementation places the stride at the first 1x1 convolution(self.conv1)\n",
        "    # according to \"Deep residual learning for image recognition\"https://arxiv.org/abs/1512.03385.\n",
        "    # This variant is also known as ResNet V1.5 and improves accuracy according to\n",
        "    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.\n",
        "\n",
        "    expansion: int = 1\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        inplanes: int,\n",
        "        planes: int,\n",
        "        stride: int = 1,\n",
        "        downsample = None,\n",
        "        groups: int = 1,\n",
        "        base_width: int = 64,\n",
        "        dilation: int = 1,\n",
        "        norm_layer = None,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        if norm_layer is None:\n",
        "            #norm_layer = nn.BatchNorm2d\n",
        "            norm_layer = nn.InstanceNorm2d\n",
        "        width = int(planes * (base_width / 64.0)) * groups\n",
        "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv1x1(inplanes, width)\n",
        "        self.bn1 = norm_layer(width)\n",
        "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
        "        self.bn2 = norm_layer(width)\n",
        "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
        "        self.bn3 = norm_layer(planes * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-03-15T00:33:28.225185Z",
          "start_time": "2022-03-15T00:33:28.099703Z"
        },
        "id": "TD4nuKzPD7yO"
      },
      "outputs": [],
      "source": [
        "class MyBatchNorm2d(nn.modules.batchnorm._NormBase):\n",
        "    ''' Partially based on:\n",
        "        https://pytorch.org/docs/stable/_modules/torch/nn/modules/batchnorm.html#BatchNorm2d\n",
        "        https://discuss.pytorch.org/t/implementing-batchnorm-in-pytorch-problem-with-updating-self-running-mean-and-self-running-var/49314/5\n",
        "    '''\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_features,\n",
        "        eps=1e-5,\n",
        "        momentum=0.005,\n",
        "        device=None,\n",
        "        dtype=None\n",
        "    ):\n",
        "        factory_kwargs = {'device': device, 'dtype': dtype, 'affine': False, 'track_running_stats': True}\n",
        "        super(MyBatchNorm2d, self).__init__(\n",
        "            num_features, eps, momentum, **factory_kwargs\n",
        "        )\n",
        "\n",
        "    def _check_input_dim(self, input):\n",
        "        if input.dim() != 4:\n",
        "            raise ValueError(\"expected 4D input (got {}D input)\".format(input.dim()))\n",
        "\n",
        "    def forward(self, input, validation=False):\n",
        "        self._check_input_dim(input)\n",
        "\n",
        "        if self.training:\n",
        "            # Note: Need to detatch `running_{mean,var}` so don't backwards propagate through them\n",
        "            unbiased_var, tmean = torch.var_mean(input, [0, 2, 3], unbiased=True)\n",
        "            mean = torch.mean(input, [0, 2, 3]) # along channel axis\n",
        "            unbiased_var = torch.var(input, [0, 2, 3], unbiased=True) # along channel axis\n",
        "            running_mean = (1.0 - self.momentum) * self.running_mean.detach() + self.momentum * mean\n",
        "\n",
        "            # Strange: PyTorch impl. of running variance uses biased_variance for the batch calc but\n",
        "            # *unbiased_var* for the running_var!\n",
        "            # https://github.com/pytorch/pytorch/blob/master/aten/src/ATen/native/Normalization.cpp#L190\n",
        "            running_var = (1.0 - self.momentum) * self.running_var.detach() + self.momentum * unbiased_var\n",
        "\n",
        "            # BK: Modification from the paper to use running mean/var instead of batch mean/var\n",
        "            # change shape\n",
        "            current_mean = running_mean.view([1, self.num_features, 1, 1]).expand_as(input)\n",
        "            current_var = running_var.view([1, self.num_features, 1, 1]).expand_as(input)\n",
        "\n",
        "            denom = (current_var + self.eps)\n",
        "            y = (input - current_mean) / denom.sqrt()\n",
        "\n",
        "            self.running_mean = running_mean\n",
        "            self.running_var = running_var\n",
        "\n",
        "            return y, -0.5 * torch.log(denom)\n",
        "        else:\n",
        "            current_mean = self.running_mean.view([1, self.num_features, 1, 1]).expand_as(input)\n",
        "            current_var = self.running_var.view([1, self.num_features, 1, 1]).expand_as(input)\n",
        "\n",
        "            if validation:\n",
        "                denom = (current_var + self.eps)\n",
        "                y = (input - current_mean) / denom.sqrt()\n",
        "            else:\n",
        "                # Reverse operation for testing\n",
        "                denom = (current_var + self.eps)\n",
        "                y = input * denom.sqrt() + current_mean\n",
        "\n",
        "            return y, -0.5 * torch.log(denom)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-03-15T00:33:28.343846Z",
          "start_time": "2022-03-15T00:33:28.227570Z"
        },
        "id": "WRP0Vk8eD7yP"
      },
      "outputs": [],
      "source": [
        "class Reshape(nn.Module):\n",
        "    def __init__(self, shape):\n",
        "        super(Reshape, self).__init__()\n",
        "        self.shape = tuple([-1] + list(shape))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.reshape(x, self.shape)\n",
        "\n",
        "def dense_backbone(shape, network_width):\n",
        "    input_width = shape[0] * shape[1] * shape[2]\n",
        "    return nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(input_width, network_width),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(network_width, network_width),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(network_width, network_width),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(network_width, input_width),\n",
        "        Reshape(shape)\n",
        "    )\n",
        "\n",
        "def bottleneck_backbone(in_planes, planes):\n",
        "    return nn.Sequential(\n",
        "        conv3x3(in_planes, planes),\n",
        "        BasicBlock(planes, planes),\n",
        "        BasicBlock(planes, planes),\n",
        "        conv3x3(planes, in_planes),\n",
        "    )\n",
        "\n",
        "check_mask = {}\n",
        "check_mask_device = {}\n",
        "def checkerboard_mask(shape, to_device=True):\n",
        "    global check_mask, check_mask_device\n",
        "    if shape not in check_mask:\n",
        "        check_mask[shape] = 1 - np.indices(shape).sum(axis=0) % 2\n",
        "        check_mask[shape] = torch.Tensor(check_mask[shape])\n",
        "\n",
        "    if to_device and shape not in check_mask_device:\n",
        "        check_mask_device[shape] = check_mask[shape].to(device)\n",
        "\n",
        "    return check_mask_device[shape] if to_device else check_mask[shape]\n",
        "\n",
        "chan_mask = {}\n",
        "chan_mask_device = {}\n",
        "def channel_mask(shape, to_device=True):\n",
        "    assert len(shape) == 3, shape\n",
        "    assert shape[0] % 2 == 0, shape\n",
        "    global chan_mask, chan_mask_device\n",
        "    if shape not in chan_mask:\n",
        "        chan_mask[shape] = torch.cat([torch.zeros((shape[0] // 2, shape[1], shape[2])),\n",
        "                                      torch.ones((shape[0] // 2, shape[1], shape[2])),],\n",
        "                                      dim=0)\n",
        "        assert chan_mask[shape].shape == shape, (chan_mask[shape].shape, shape)\n",
        "\n",
        "    if to_device and shape not in chan_mask_device:\n",
        "        chan_mask_device[shape] = chan_mask[shape].to(device)\n",
        "\n",
        "    return chan_mask_device[shape] if to_device else chan_mask[shape]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-03-15T00:33:28.461255Z",
          "start_time": "2022-03-15T00:33:28.346571Z"
        },
        "id": "1J2zNHdCD7yP"
      },
      "outputs": [],
      "source": [
        "class NormalizingFlowMNist(nn.Module):\n",
        "    EPSILON = 1e-5\n",
        "\n",
        "    def __init__(self, num_coupling, num_final_coupling, planes):\n",
        "        super(NormalizingFlowMNist, self).__init__()\n",
        "        self.num_coupling = num_coupling\n",
        "        self.num_final_coupling = num_final_coupling\n",
        "        self.shape = (1, 28, 28)\n",
        "\n",
        "        self.planes = planes\n",
        "        self.s = nn.ModuleList()\n",
        "        self.t = nn.ModuleList()\n",
        "        self.norms = nn.ModuleList()\n",
        "\n",
        "        # Learnable scalar scaling parameters for outputs of S and T\n",
        "        self.s_scale = nn.ParameterList()\n",
        "        self.t_scale = nn.ParameterList()\n",
        "        self.t_bias = nn.ParameterList()\n",
        "        self.shapes = []\n",
        "\n",
        "        shape = self.shape\n",
        "        for i in range(num_coupling):\n",
        "            self.s.append(dense_backbone(shape, planes))\n",
        "            self.t.append(dense_backbone(shape, planes))\n",
        "\n",
        "            self.s_scale.append(torch.nn.Parameter(torch.zeros(shape), requires_grad=True))\n",
        "            self.t_scale.append(torch.nn.Parameter(torch.zeros(shape), requires_grad=True))\n",
        "            self.t_bias.append(torch.nn.Parameter(torch.zeros(shape), requires_grad=True))\n",
        "\n",
        "            self.norms.append(MyBatchNorm2d(shape[0]))\n",
        "\n",
        "            self.shapes.append(shape)\n",
        "\n",
        "            if i % 6 == 2:\n",
        "                shape = (4 * shape[0], shape[1] // 2, shape[2] // 2)\n",
        "\n",
        "            if i % 6 == 5 or self.num_coupling - 1 == i:\n",
        "                # Factoring out half the channels\n",
        "                shape = (shape[0] // 2, shape[1], shape[2])\n",
        "                planes = 2 * planes\n",
        "\n",
        "        # Final coupling layers checkerboard\n",
        "        for i in range(num_final_coupling):\n",
        "            self.s.append(dense_backbone(shape, planes))\n",
        "            self.t.append(dense_backbone(shape, planes))\n",
        "\n",
        "            self.s_scale.append(torch.nn.Parameter(torch.zeros(shape), requires_grad=True))\n",
        "            self.t_scale.append(torch.nn.Parameter(torch.zeros(shape), requires_grad=True))\n",
        "            self.t_bias.append(torch.nn.Parameter(torch.zeros(shape), requires_grad=True))\n",
        "\n",
        "            self.norms.append(MyBatchNorm2d(shape[0]))\n",
        "\n",
        "            self.shapes.append(shape)\n",
        "\n",
        "        self.validation = False\n",
        "\n",
        "\n",
        "    def validate(self):\n",
        "        self.eval()\n",
        "        self.validation = True\n",
        "\n",
        "    def train(self, mode=True):\n",
        "        nn.Module.train(self, mode)\n",
        "        self.validation = False\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.training or self.validation:\n",
        "            s_vals = []\n",
        "            norm_vals = []\n",
        "            y_vals = []\n",
        "\n",
        "            for i in range(self.num_coupling):\n",
        "                shape = self.shapes[i]\n",
        "                mask = checkerboard_mask(shape) if i % 6 < 3 else channel_mask(shape)\n",
        "                mask = mask if i % 2 == 0 else (1 - mask)\n",
        "\n",
        "                t = (self.t_scale[i]) * self.t[i](mask * x) + (self.t_bias[i])\n",
        "                s = (self.s_scale[i]) * torch.tanh(self.s[i](mask * x))\n",
        "                y = mask * x + (1 - mask) * (x * torch.exp(s) + t)\n",
        "                s_vals.append(torch.flatten((1 - mask) * s))\n",
        "\n",
        "                if self.norms[i] is not None:\n",
        "                    y, norm_loss = self.norms[i](y, validation=self.validation)\n",
        "                    norm_vals.append(norm_loss)\n",
        "\n",
        "                if i % 6 == 2:\n",
        "                    y = torch.nn.functional.pixel_unshuffle(y, 2)\n",
        "\n",
        "                if i % 6 == 5 or self.num_coupling -1 == i:\n",
        "                    factor_channels = y.shape[1] // 2\n",
        "                    y_vals.append(torch.flatten(y[:, factor_channels:, :, :], 1))\n",
        "                    y = y[:, :factor_channels, :, :]\n",
        "\n",
        "                x = y\n",
        "\n",
        "            # Final checkboard coupling\n",
        "            for i in range(self.num_coupling, self.num_coupling + self.num_final_coupling):\n",
        "                shape = self.shapes[i]\n",
        "                mask = checkerboard_mask(shape)\n",
        "                mask = mask if i % 2 == 0 else (1 - mask)\n",
        "\n",
        "                t = (self.t_scale[i]) * self.t[i](mask * x) + (self.t_bias[i])\n",
        "                s = (self.s_scale[i]) * torch.tanh(self.s[i](mask * x))\n",
        "                y = mask * x + (1 - mask) * (x * torch.exp(s) + t)\n",
        "                s_vals.append(torch.flatten((1 - mask) * s))\n",
        "\n",
        "                if self.norms[i] is not None:\n",
        "                    y, norm_loss = self.norms[i](y, validation=self.validation)\n",
        "                    norm_vals.append(norm_loss)\n",
        "\n",
        "                x = y\n",
        "\n",
        "            y_vals.append(torch.flatten(y, 1))\n",
        "\n",
        "            # Return outputs and vars needed for determinant\n",
        "            return (torch.flatten(torch.cat(y_vals, 1), 1),\n",
        "                    torch.cat(s_vals),\n",
        "                    torch.cat([torch.flatten(v) for v in norm_vals]) if len(norm_vals) > 0 else torch.zeros(1),\n",
        "                    torch.cat([torch.flatten(s) for s in self.s_scale]))\n",
        "        else:\n",
        "            y = x\n",
        "            y_remaining = y\n",
        "\n",
        "            layer_vars = np.prod(self.shapes[-1])\n",
        "            y = torch.reshape(y_remaining[:, -layer_vars:], (-1,) + self.shapes[-1])\n",
        "            y_remaining = y_remaining[:, :-layer_vars]\n",
        "\n",
        "            # Reversed final checkboard coupling\n",
        "            for i in reversed(range(self.num_coupling, self.num_coupling + self.num_final_coupling)):\n",
        "                shape = self.shapes[i]\n",
        "                mask = checkerboard_mask(shape)\n",
        "                mask = mask if i % 2 == 0 else (1 - mask)\n",
        "\n",
        "                if self.norms[i] is not None:\n",
        "                    y, _ = self.norms[i](y)\n",
        "\n",
        "                t = (self.t_scale[i]) * self.t[i](mask * y) + (self.t_bias[i])\n",
        "                s = (self.s_scale[i]) * torch.tanh(self.s[i](mask * y))\n",
        "                x = mask * y + (1 - mask) * ((y - t) * torch.exp(-s))\n",
        "\n",
        "                y = x\n",
        "\n",
        "            layer_vars = np.prod(shape)\n",
        "            y = torch.cat((y, torch.reshape(y_remaining[:, -layer_vars:], (-1,) + shape)), 1)\n",
        "            y_remaining = y_remaining[:, :-layer_vars]\n",
        "\n",
        "            # Multi-scale coupling layers\n",
        "            for i in reversed(range(self.num_coupling)):\n",
        "                shape = self.shapes[i]\n",
        "                mask = checkerboard_mask(shape) if i % 6 < 3 else channel_mask(shape)\n",
        "                mask = mask if i % 2 == 0 else (1 - mask)\n",
        "\n",
        "                if self.norms[i] is not None:\n",
        "                    y, _ = self.norms[i](y)\n",
        "\n",
        "                t = (self.t_scale[i]) * self.t[i](mask * y) + (self.t_bias[i])\n",
        "                s = (self.s_scale[i]) * torch.tanh(self.s[i](mask * y))\n",
        "                x = mask * y + (1 - mask) * ((y - t) * torch.exp(-s))\n",
        "\n",
        "                if i % 6 == 3:\n",
        "                    x = torch.nn.functional.pixel_shuffle(x, 2)\n",
        "\n",
        "                y = x\n",
        "\n",
        "                if i > 0 and i % 6 == 0:\n",
        "                    layer_vars = np.prod(shape)\n",
        "                    y = torch.cat((y, torch.reshape(y_remaining[:, -layer_vars:], (-1,) + shape)), 1)\n",
        "                    y_remaining = y_remaining[:, :-layer_vars]\n",
        "\n",
        "            assert np.prod(y_remaining.shape) == 0\n",
        "\n",
        "            return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-03-15T00:33:30.921081Z",
          "start_time": "2022-03-15T00:33:28.463060Z"
        },
        "id": "bCxMM3SxD7yQ"
      },
      "outputs": [],
      "source": [
        "PI = torch.tensor(np.pi).to(device)\n",
        "def loss_fn(y, s, norms, scale, batch_size):\n",
        "    # -log(zero-mean gaussian) + log determinant\n",
        "    # -log p_x = log(pz(f(x))) + log(det(\\partial f/\\partial x))\n",
        "    # -log p_x = 0.5 * y**2 + s1 + s2 + ... + batch_norm_scalers + l2_regularizers(scale)\n",
        "    logpx = -torch.sum(0.5 * torch.log(2 * PI) + 0.5 * y**2)\n",
        "    det = torch.sum(s)\n",
        "    norms = torch.sum(norms)\n",
        "    reg = 5e-5 * torch.sum(scale ** 2)\n",
        "    loss = -(logpx + det + norms) + reg\n",
        "    return torch.div(loss, batch_size), (-logpx, -det, -norms, reg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKiW-7soD7yQ"
      },
      "source": [
        "# MNist Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-03-15T00:33:30.925891Z",
          "start_time": "2022-03-15T00:33:30.922862Z"
        },
        "id": "PS-4hBQpD7yR"
      },
      "outputs": [],
      "source": [
        "def pre_process(x):\n",
        "    # Convert back to integer values\n",
        "    x = x * 255.\n",
        "\n",
        "    # Add random uniform [0, 1] noise to get a proper likelihood estimate\n",
        "    # https://bjlkeng.github.io/posts/a-note-on-using-log-likelihood-for-generative-models/\n",
        "    x = x + torch.rand(x.shape, device=x.device)\n",
        "\n",
        "\n",
        "    # Apply transform to deal with boundary effects (see realNVP paper)\n",
        "    #x = torch.logit(0.05 + 0.90 * x / 256)\n",
        "    #return x\n",
        "    return x / 255\n",
        "\n",
        "def post_process(x):\n",
        "    # Convert back to integer values\n",
        "    #return torch.clip(torch.floor(256 / 0.90 * (torch.sigmoid(x) - 0.05)), min=0, max=255) / 255\n",
        "    return torch.clip(x, min=0, max=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-03-15T00:33:31.097756Z",
          "start_time": "2022-03-15T00:33:30.927309Z"
        },
        "id": "F0-m9taHD7yS",
        "outputId": "122bbbeb-4783-498d-f4a6-0624ac1570b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 104892488.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 24807637.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 28118637.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 12467623.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train_dataset = datasets.MNIST('data', train=True, download=True,\n",
        "                               transform=transforms.Compose([\n",
        "                                   transforms.ToTensor(),\n",
        "                               ]))\n",
        "\n",
        "# TODO FIX ME\n",
        "# debug_data = []\n",
        "# for i, x in enumerate(train_dataset):\n",
        "#     if i >= 200:\n",
        "#         break\n",
        "#     debug_data.append(x)\n",
        "\n",
        "test_dataset = datasets.MNIST('data', train=False, download=True,\n",
        "                              transform=transforms.Compose([\n",
        "                                  transforms.ToTensor(),\n",
        "                              ]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-03-15T00:33:31.124980Z",
          "start_time": "2022-03-15T00:33:31.102645Z"
        },
        "id": "RhSY--JBD7yS"
      },
      "outputs": [],
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer, batch_size, report_iters=10, num_pixels=28*28):\n",
        "    size = len(dataloader)\n",
        "    prev = []\n",
        "    for batch, (X, _) in enumerate(dataloader):\n",
        "        # Transfer to GPU\n",
        "        X = pre_process(X)\n",
        "        X = X.to(device)\n",
        "\n",
        "        # Compute prediction and loss\n",
        "        y, s, norms, scale = model(X)\n",
        "        loss, comps = loss_fn(y, s, norms, scale, batch_size)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1) # gradient_clipping = 1\n",
        "\n",
        "        prev = [(name, x, x.grad) for name, x in model.named_parameters(recurse=True)]\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % report_iters == 0:\n",
        "            loss, current = loss.item(), batch\n",
        "            # Account for x/255 preprocessing\n",
        "            loss += num_pixels * np.log(255)\n",
        "            print(f\"loss: {loss:.2f} = -logpx[{comps[0]:.1f}], -det[{comps[1]:.1f}], -norms[{comps[2]:.1f}], reg[{comps[3]:.4f}]\"\n",
        "                  f\"; bits/pixel: {loss / num_pixels / np.log(2):>.2f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn, num_pixels=28*28):\n",
        "    size = len(dataloader)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model.validate()\n",
        "        for X, _ in dataloader:\n",
        "            X = pre_process(X)\n",
        "            X = X.to(device)\n",
        "            y, s, norms, scale = model(X)\n",
        "            loss, _ = loss_fn(y, s, norms, scale, batch_size)\n",
        "            test_loss += loss\n",
        "\n",
        "        model.train()\n",
        "\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    # Account for x/255 preprocessing\n",
        "    test_loss += num_pixels * np.log(255)\n",
        "    print(f\"Test Error: \\n Avg loss: {test_loss:.2f}; {test_loss / num_pixels / np.log(2):.2f} \\n\")\n",
        "    return test_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-03-15T00:33:31.519257Z",
          "start_time": "2022-03-15T00:33:31.128663Z"
        },
        "id": "cDLwk6IfD7yS"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.0005\n",
        "batch_size = 128\n",
        "epochs = 20\n",
        "\n",
        "model = NormalizingFlowMNist(num_coupling=4, num_final_coupling=1, planes=256).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-03-15T01:45:49.330260Z",
          "start_time": "2022-03-15T00:33:31.521419Z"
        },
        "scrolled": true,
        "id": "8F-a_4mwD7yS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2564ae8d-e098-4cb5-ee2f-9dabe1b37ba4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 5101.23 = -logpx[97901.9], -det[-0.0], -norms[-1021.5], reg[0.0000]; bits/pixel: 9.39  [    0/  469]\n",
            "loss: 5029.86 = -logpx[99133.6], -det[-205.7], -norms[-11182.4], reg[0.0000]; bits/pixel: 9.26  [   10/  469]\n",
            "loss: 4938.49 = -logpx[99370.6], -det[-2101.7], -norms[-21218.6], reg[0.0000]; bits/pixel: 9.09  [   20/  469]\n",
            "loss: 4846.23 = -logpx[99032.0], -det[-3566.8], -norms[-31224.2], reg[0.0000]; bits/pixel: 8.92  [   30/  469]\n",
            "loss: 4768.27 = -logpx[100241.3], -det[-4780.5], -norms[-41199.6], reg[0.0000]; bits/pixel: 8.77  [   40/  469]\n",
            "loss: 4700.06 = -logpx[102500.9], -det[-5992.8], -norms[-50977.0], reg[0.0001]; bits/pixel: 8.65  [   50/  469]\n",
            "loss: 4634.30 = -logpx[104799.2], -det[-7198.2], -norms[-60487.6], reg[0.0001]; bits/pixel: 8.53  [   60/  469]\n",
            "loss: 4570.36 = -logpx[107012.9], -det[-8320.2], -norms[-69763.0], reg[0.0001]; bits/pixel: 8.41  [   70/  469]\n",
            "loss: 4519.73 = -logpx[110429.2], -det[-9282.2], -norms[-78698.3], reg[0.0002]; bits/pixel: 8.32  [   80/  469]\n",
            "loss: 4465.31 = -logpx[112862.5], -det[-10063.0], -norms[-87316.1], reg[0.0002]; bits/pixel: 8.22  [   90/  469]\n",
            "loss: 4429.44 = -logpx[117077.7], -det[-10669.4], -norms[-95516.4], reg[0.0002]; bits/pixel: 8.15  [  100/  469]\n",
            "loss: 4386.85 = -logpx[119932.8], -det[-11101.9], -norms[-103391.4], reg[0.0002]; bits/pixel: 8.07  [  110/  469]\n",
            "loss: 4348.47 = -logpx[122860.5], -det[-11427.3], -norms[-110906.4], reg[0.0002]; bits/pixel: 8.00  [  120/  469]\n",
            "loss: 4306.37 = -logpx[124827.9], -det[-11664.8], -norms[-118025.2], reg[0.0003]; bits/pixel: 7.92  [  130/  469]\n",
            "loss: 4280.64 = -logpx[128485.0], -det[-11829.2], -norms[-124810.8], reg[0.0003]; bits/pixel: 7.88  [  140/  469]\n",
            "loss: 4240.92 = -logpx[129850.1], -det[-11929.9], -norms[-131160.0], reg[0.0003]; bits/pixel: 7.80  [  150/  469]\n",
            "loss: 4191.91 = -logpx[129567.1], -det[-11974.2], -norms[-137105.0], reg[0.0003]; bits/pixel: 7.71  [  160/  469]\n",
            "loss: 4196.46 = -logpx[135727.1], -det[-11975.4], -norms[-142681.7], reg[0.0003]; bits/pixel: 7.72  [  170/  469]\n",
            "loss: 4197.27 = -logpx[140866.1], -det[-11940.8], -norms[-147751.3], reg[0.0003]; bits/pixel: 7.72  [  180/  469]\n",
            "loss: 4178.96 = -logpx[143065.3], -det[-11872.3], -norms[-152363.0], reg[0.0003]; bits/pixel: 7.69  [  190/  469]\n",
            "loss: 4155.19 = -logpx[144173.8], -det[-11776.9], -norms[-156609.3], reg[0.0003]; bits/pixel: 7.65  [  200/  469]\n",
            "loss: 4150.29 = -logpx[147079.1], -det[-11661.1], -norms[-160258.3], reg[0.0003]; bits/pixel: 7.64  [  210/  469]\n",
            "loss: 4151.48 = -logpx[150488.3], -det[-11544.9], -norms[-163630.4], reg[0.0003]; bits/pixel: 7.64  [  220/  469]\n",
            "loss: 4129.74 = -logpx[150435.3], -det[-11419.8], -norms[-166486.1], reg[0.0003]; bits/pixel: 7.60  [  230/  469]\n",
            "loss: 4106.89 = -logpx[149987.1], -det[-11293.7], -norms[-169089.0], reg[0.0003]; bits/pixel: 7.56  [  240/  469]\n",
            "loss: 4139.50 = -logpx[156190.9], -det[-11151.9], -norms[-171259.8], reg[0.0004]; bits/pixel: 7.62  [  250/  469]\n",
            "loss: 4134.61 = -logpx[157096.8], -det[-10992.1], -norms[-172950.9], reg[0.0004]; bits/pixel: 7.61  [  260/  469]\n",
            "loss: 4132.20 = -logpx[158020.8], -det[-10830.2], -norms[-174345.6], reg[0.0004]; bits/pixel: 7.60  [  270/  469]\n",
            "loss: 4079.81 = -logpx[152589.0], -det[-10672.5], -norms[-175778.2], reg[0.0004]; bits/pixel: 7.51  [  280/  469]\n",
            "loss: 4097.84 = -logpx[155665.2], -det[-10520.9], -norms[-176697.9], reg[0.0004]; bits/pixel: 7.54  [  290/  469]\n",
            "loss: 4093.62 = -logpx[155824.4], -det[-10366.0], -norms[-177551.4], reg[0.0004]; bits/pixel: 7.53  [  300/  469]\n",
            "loss: 4066.50 = -logpx[152890.7], -det[-10208.2], -norms[-178246.9], reg[0.0004]; bits/pixel: 7.48  [  310/  469]\n",
            "loss: 4035.17 = -logpx[149023.8], -det[-10057.5], -norms[-178541.6], reg[0.0004]; bits/pixel: 7.43  [  320/  469]\n",
            "loss: 4040.27 = -logpx[149748.7], -det[-9919.5], -norms[-178751.9], reg[0.0004]; bits/pixel: 7.43  [  330/  469]\n",
            "loss: 4030.11 = -logpx[148444.0], -det[-9784.8], -norms[-178882.0], reg[0.0004]; bits/pixel: 7.42  [  340/  469]\n",
            "loss: 4036.98 = -logpx[149218.4], -det[-9659.4], -norms[-178902.0], reg[0.0005]; bits/pixel: 7.43  [  350/  469]\n",
            "loss: 4036.54 = -logpx[149002.9], -det[-9541.7], -norms[-178860.7], reg[0.0005]; bits/pixel: 7.43  [  360/  469]\n",
            "loss: 4016.51 = -logpx[146299.1], -det[-9433.9], -norms[-178829.2], reg[0.0005]; bits/pixel: 7.39  [  370/  469]\n",
            "loss: 4010.69 = -logpx[145437.6], -det[-9337.4], -norms[-178809.2], reg[0.0005]; bits/pixel: 7.38  [  380/  469]\n",
            "loss: 4002.25 = -logpx[144091.0], -det[-9244.6], -norms[-178635.2], reg[0.0005]; bits/pixel: 7.36  [  390/  469]\n",
            "loss: 3997.66 = -logpx[143187.6], -det[-9161.5], -norms[-178402.0], reg[0.0005]; bits/pixel: 7.36  [  400/  469]\n",
            "loss: 3981.25 = -logpx[140916.6], -det[-9096.8], -norms[-178296.8], reg[0.0005]; bits/pixel: 7.33  [  410/  469]\n",
            "loss: 3958.45 = -logpx[137907.5], -det[-9043.0], -norms[-178260.0], reg[0.0006]; bits/pixel: 7.28  [  420/  469]\n",
            "loss: 3977.79 = -logpx[140330.1], -det[-9005.3], -norms[-178244.2], reg[0.0006]; bits/pixel: 7.32  [  430/  469]\n",
            "loss: 3959.12 = -logpx[137684.5], -det[-8968.1], -norms[-178025.8], reg[0.0006]; bits/pixel: 7.29  [  440/  469]\n",
            "loss: 3974.01 = -logpx[139491.3], -det[-8936.7], -norms[-177957.8], reg[0.0006]; bits/pixel: 7.31  [  450/  469]\n",
            "loss: 3956.10 = -logpx[137062.9], -det[-8912.3], -norms[-177846.1], reg[0.0006]; bits/pixel: 7.28  [  460/  469]\n",
            "Test Error: \n",
            " Avg loss: 3944.70; 7.26 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 3926.57 = -logpx[133338.4], -det[-8899.7], -norms[-177914.0], reg[0.0007]; bits/pixel: 7.23  [    0/  469]\n",
            "loss: 3949.59 = -logpx[136161.9], -det[-8898.5], -norms[-177792.9], reg[0.0007]; bits/pixel: 7.27  [   10/  469]\n",
            "loss: 3944.49 = -logpx[135415.7], -det[-8902.2], -norms[-177695.3], reg[0.0007]; bits/pixel: 7.26  [   20/  469]\n",
            "loss: 3939.50 = -logpx[134864.7], -det[-8916.3], -norms[-177769.0], reg[0.0007]; bits/pixel: 7.25  [   30/  469]\n",
            "loss: 3924.61 = -logpx[132934.6], -det[-8937.9], -norms[-177723.2], reg[0.0008]; bits/pixel: 7.22  [   40/  469]\n",
            "loss: 3928.35 = -logpx[133514.3], -det[-8967.0], -norms[-177795.1], reg[0.0008]; bits/pixel: 7.23  [   50/  469]\n",
            "loss: 3914.99 = -logpx[132101.8], -det[-9007.9], -norms[-178052.2], reg[0.0008]; bits/pixel: 7.20  [   60/  469]\n",
            "loss: 3913.39 = -logpx[131993.7], -det[-9052.2], -norms[-178103.8], reg[0.0008]; bits/pixel: 7.20  [   70/  469]\n",
            "loss: 3896.15 = -logpx[129994.2], -det[-9102.4], -norms[-178261.6], reg[0.0009]; bits/pixel: 7.17  [   80/  469]\n",
            "loss: 3896.71 = -logpx[130398.4], -det[-9163.9], -norms[-178532.9], reg[0.0009]; bits/pixel: 7.17  [   90/  469]\n",
            "loss: 3886.12 = -logpx[129292.4], -det[-9233.0], -norms[-178712.6], reg[0.0009]; bits/pixel: 7.15  [  100/  469]\n",
            "loss: 3895.23 = -logpx[130806.5], -det[-9305.5], -norms[-178988.0], reg[0.0009]; bits/pixel: 7.17  [  110/  469]\n",
            "loss: 3883.86 = -logpx[129728.2], -det[-9384.1], -norms[-179287.5], reg[0.0010]; bits/pixel: 7.15  [  120/  469]\n",
            "loss: 3869.56 = -logpx[128199.3], -det[-9460.7], -norms[-179511.4], reg[0.0010]; bits/pixel: 7.12  [  130/  469]\n",
            "loss: 3854.09 = -logpx[126788.1], -det[-9546.6], -norms[-179995.1], reg[0.0010]; bits/pixel: 7.09  [  140/  469]\n",
            "loss: 3881.79 = -logpx[130626.2], -det[-9638.2], -norms[-180195.4], reg[0.0011]; bits/pixel: 7.14  [  150/  469]\n",
            "loss: 3837.15 = -logpx[125537.3], -det[-9736.0], -norms[-180723.2], reg[0.0011]; bits/pixel: 7.06  [  160/  469]\n",
            "loss: 3843.70 = -logpx[126924.3], -det[-9835.2], -norms[-181172.5], reg[0.0011]; bits/pixel: 7.07  [  170/  469]\n",
            "loss: 3833.42 = -logpx[126238.2], -det[-9943.4], -norms[-181694.3], reg[0.0011]; bits/pixel: 7.05  [  180/  469]\n",
            "loss: 3831.17 = -logpx[126565.2], -det[-10054.3], -norms[-182198.0], reg[0.0012]; bits/pixel: 7.05  [  190/  469]\n",
            "loss: 3827.10 = -logpx[126582.4], -det[-10160.6], -norms[-182630.3], reg[0.0012]; bits/pixel: 7.04  [  200/  469]\n",
            "loss: 3834.78 = -logpx[128139.7], -det[-10263.4], -norms[-183101.3], reg[0.0012]; bits/pixel: 7.06  [  210/  469]\n",
            "loss: 3837.81 = -logpx[129130.9], -det[-10369.8], -norms[-183597.9], reg[0.0013]; bits/pixel: 7.06  [  220/  469]\n",
            "loss: 3832.08 = -logpx[129117.1], -det[-10484.3], -norms[-184203.4], reg[0.0013]; bits/pixel: 7.05  [  230/  469]\n",
            "loss: 3832.05 = -logpx[129821.1], -det[-10601.8], -norms[-184794.0], reg[0.0013]; bits/pixel: 7.05  [  240/  469]\n",
            "loss: 3818.71 = -logpx[128902.0], -det[-10707.7], -norms[-185476.2], reg[0.0014]; bits/pixel: 7.03  [  250/  469]\n",
            "loss: 3848.67 = -logpx[133511.9], -det[-10820.0], -norms[-186139.1], reg[0.0014]; bits/pixel: 7.08  [  260/  469]\n",
            "loss: 3842.55 = -logpx[133323.0], -det[-10926.8], -norms[-186627.2], reg[0.0015]; bits/pixel: 7.07  [  270/  469]\n",
            "loss: 3797.23 = -logpx[128359.0], -det[-11039.5], -norms[-187350.8], reg[0.0015]; bits/pixel: 6.99  [  280/  469]\n",
            "loss: 3814.88 = -logpx[131314.5], -det[-11148.5], -norms[-187938.0], reg[0.0015]; bits/pixel: 7.02  [  290/  469]\n",
            "loss: 3802.44 = -logpx[130444.3], -det[-11249.0], -norms[-188559.8], reg[0.0016]; bits/pixel: 7.00  [  300/  469]\n",
            "loss: 3794.71 = -logpx[130248.9], -det[-11351.8], -norms[-189250.7], reg[0.0016]; bits/pixel: 6.98  [  310/  469]\n",
            "loss: 3790.29 = -logpx[130480.4], -det[-11454.6], -norms[-189945.4], reg[0.0016]; bits/pixel: 6.97  [  320/  469]\n",
            "loss: 3781.88 = -logpx[130217.6], -det[-11542.9], -norms[-190671.0], reg[0.0017]; bits/pixel: 6.96  [  330/  469]\n",
            "loss: 3775.14 = -logpx[130047.3], -det[-11624.5], -norms[-191282.2], reg[0.0017]; bits/pixel: 6.95  [  340/  469]\n",
            "loss: 3782.33 = -logpx[131698.8], -det[-11705.1], -norms[-191932.3], reg[0.0017]; bits/pixel: 6.96  [  350/  469]\n",
            "loss: 3784.59 = -logpx[132610.4], -det[-11807.0], -norms[-192452.3], reg[0.0018]; bits/pixel: 6.96  [  360/  469]\n",
            "loss: 3761.14 = -logpx[130249.0], -det[-11902.4], -norms[-192997.5], reg[0.0018]; bits/pixel: 6.92  [  370/  469]\n",
            "loss: 3780.22 = -logpx[133342.3], -det[-11994.8], -norms[-193556.5], reg[0.0019]; bits/pixel: 6.96  [  380/  469]\n",
            "loss: 3755.95 = -logpx[130904.4], -det[-12077.2], -norms[-194142.8], reg[0.0019]; bits/pixel: 6.91  [  390/  469]\n",
            "loss: 3771.73 = -logpx[133662.6], -det[-12157.0], -norms[-194801.3], reg[0.0019]; bits/pixel: 6.94  [  400/  469]\n",
            "loss: 3744.98 = -logpx[130962.1], -det[-12239.9], -norms[-195441.8], reg[0.0020]; bits/pixel: 6.89  [  410/  469]\n",
            "loss: 3743.52 = -logpx[131633.4], -det[-12327.8], -norms[-196211.4], reg[0.0020]; bits/pixel: 6.89  [  420/  469]\n",
            "loss: 3717.16 = -logpx[128922.3], -det[-12410.2], -norms[-196793.0], reg[0.0021]; bits/pixel: 6.84  [  430/  469]\n",
            "loss: 3715.40 = -logpx[129476.5], -det[-12487.4], -norms[-197494.2], reg[0.0021]; bits/pixel: 6.84  [  440/  469]\n",
            "loss: 3713.00 = -logpx[129962.4], -det[-12563.0], -norms[-198212.6], reg[0.0022]; bits/pixel: 6.83  [  450/  469]\n",
            "loss: 3720.20 = -logpx[131678.3], -det[-12635.3], -norms[-198934.7], reg[0.0022]; bits/pixel: 6.85  [  460/  469]\n",
            "Test Error: \n",
            " Avg loss: 3722.10; 6.85 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 3726.37 = -logpx[133088.2], -det[-12695.5], -norms[-199494.1], reg[0.0022]; bits/pixel: 6.86  [    0/  469]\n",
            "loss: 3748.55 = -logpx[136673.1], -det[-12763.5], -norms[-200171.7], reg[0.0023]; bits/pixel: 6.90  [   10/  469]\n",
            "loss: 3706.37 = -logpx[132002.3], -det[-12828.4], -norms[-200834.8], reg[0.0023]; bits/pixel: 6.82  [   20/  469]\n",
            "loss: 3717.29 = -logpx[134122.7], -det[-12892.4], -norms[-201494.6], reg[0.0024]; bits/pixel: 6.84  [   30/  469]\n",
            "loss: 3707.08 = -logpx[133574.2], -det[-12960.7], -norms[-202184.0], reg[0.0024]; bits/pixel: 6.82  [   40/  469]\n",
            "loss: 3717.42 = -logpx[135523.8], -det[-13025.9], -norms[-202744.8], reg[0.0025]; bits/pixel: 6.84  [   50/  469]\n",
            "loss: 3702.49 = -logpx[134399.9], -det[-13085.5], -norms[-203471.9], reg[0.0025]; bits/pixel: 6.81  [   60/  469]\n",
            "loss: 3717.27 = -logpx[137076.4], -det[-13147.3], -norms[-204195.4], reg[0.0025]; bits/pixel: 6.84  [   70/  469]\n",
            "loss: 3687.75 = -logpx[134042.8], -det[-13200.3], -norms[-204887.4], reg[0.0026]; bits/pixel: 6.79  [   80/  469]\n",
            "loss: 3686.91 = -logpx[134589.4], -det[-13255.5], -norms[-205485.6], reg[0.0026]; bits/pixel: 6.78  [   90/  469]\n",
            "loss: 3672.51 = -logpx[133385.5], -det[-13300.8], -norms[-206080.5], reg[0.0027]; bits/pixel: 6.76  [  100/  469]\n",
            "loss: 3677.68 = -logpx[134684.7], -det[-13343.4], -norms[-206674.9], reg[0.0027]; bits/pixel: 6.77  [  110/  469]\n",
            "loss: 3683.45 = -logpx[136138.1], -det[-13383.4], -norms[-207349.6], reg[0.0028]; bits/pixel: 6.78  [  120/  469]\n",
            "loss: 3686.79 = -logpx[137140.5], -det[-13416.3], -norms[-207892.5], reg[0.0028]; bits/pixel: 6.78  [  130/  469]\n",
            "loss: 3663.89 = -logpx[134904.4], -det[-13447.1], -norms[-208556.3], reg[0.0029]; bits/pixel: 6.74  [  140/  469]\n",
            "loss: 3646.42 = -logpx[133529.1], -det[-13481.2], -norms[-209382.5], reg[0.0029]; bits/pixel: 6.71  [  150/  469]\n",
            "loss: 3642.22 = -logpx[133737.2], -det[-13519.8], -norms[-210090.6], reg[0.0030]; bits/pixel: 6.70  [  160/  469]\n",
            "loss: 3633.71 = -logpx[133359.0], -det[-13557.5], -norms[-210762.9], reg[0.0030]; bits/pixel: 6.69  [  170/  469]\n",
            "loss: 3645.92 = -logpx[135450.6], -det[-13588.1], -norms[-211261.8], reg[0.0031]; bits/pixel: 6.71  [  180/  469]\n",
            "loss: 3660.09 = -logpx[137856.5], -det[-13614.4], -norms[-211827.4], reg[0.0031]; bits/pixel: 6.74  [  190/  469]\n",
            "loss: 3622.81 = -logpx[133728.5], -det[-13640.9], -norms[-212444.9], reg[0.0032]; bits/pixel: 6.67  [  200/  469]\n",
            "loss: 3634.80 = -logpx[135710.6], -det[-13661.6], -norms[-212871.8], reg[0.0032]; bits/pixel: 6.69  [  210/  469]\n",
            "loss: 3628.66 = -logpx[135656.8], -det[-13680.7], -norms[-213584.0], reg[0.0033]; bits/pixel: 6.68  [  220/  469]\n",
            "loss: 3631.40 = -logpx[136480.5], -det[-13701.5], -norms[-214037.0], reg[0.0033]; bits/pixel: 6.68  [  230/  469]\n",
            "loss: 3651.50 = -logpx[139592.5], -det[-13715.9], -norms[-214561.9], reg[0.0034]; bits/pixel: 6.72  [  240/  469]\n",
            "loss: 3611.05 = -logpx[134985.3], -det[-13725.0], -norms[-215122.3], reg[0.0034]; bits/pixel: 6.64  [  250/  469]\n",
            "loss: 3623.82 = -logpx[137190.7], -det[-13733.1], -norms[-215685.3], reg[0.0035]; bits/pixel: 6.67  [  260/  469]\n",
            "loss: 3598.27 = -logpx[134629.3], -det[-13743.7], -norms[-216384.5], reg[0.0035]; bits/pixel: 6.62  [  270/  469]\n",
            "loss: 3607.29 = -logpx[136161.1], -det[-13749.1], -norms[-216755.3], reg[0.0036]; bits/pixel: 6.64  [  280/  469]\n",
            "loss: 3618.49 = -logpx[138110.7], -det[-13751.5], -norms[-217269.8], reg[0.0036]; bits/pixel: 6.66  [  290/  469]\n",
            "loss: 3634.72 = -logpx[140761.0], -det[-13758.4], -norms[-217835.7], reg[0.0036]; bits/pixel: 6.69  [  300/  469]\n",
            "loss: 3622.95 = -logpx[139784.2], -det[-13762.3], -norms[-218361.3], reg[0.0037]; bits/pixel: 6.67  [  310/  469]\n",
            "loss: 3566.92 = -logpx[133061.3], -det[-13760.7], -norms[-218811.7], reg[0.0037]; bits/pixel: 6.56  [  320/  469]\n",
            "loss: 3617.26 = -logpx[140112.5], -det[-13772.8], -norms[-219406.9], reg[0.0038]; bits/pixel: 6.66  [  330/  469]\n",
            "loss: 3587.70 = -logpx[136740.2], -det[-13768.6], -norms[-219822.6], reg[0.0038]; bits/pixel: 6.60  [  340/  469]\n",
            "loss: 3571.35 = -logpx[135148.6], -det[-13762.9], -norms[-220329.5], reg[0.0039]; bits/pixel: 6.57  [  350/  469]\n",
            "loss: 3598.77 = -logpx[139068.9], -det[-13756.9], -norms[-220746.5], reg[0.0040]; bits/pixel: 6.62  [  360/  469]\n",
            "loss: 3576.62 = -logpx[136763.3], -det[-13752.1], -norms[-221280.5], reg[0.0040]; bits/pixel: 6.58  [  370/  469]\n",
            "loss: 3572.50 = -logpx[136730.4], -det[-13745.0], -norms[-221781.9], reg[0.0041]; bits/pixel: 6.57  [  380/  469]\n",
            "loss: 3569.56 = -logpx[136881.8], -det[-13740.8], -norms[-222313.8], reg[0.0041]; bits/pixel: 6.57  [  390/  469]\n",
            "loss: 3573.26 = -logpx[137957.6], -det[-13739.9], -norms[-222917.3], reg[0.0042]; bits/pixel: 6.58  [  400/  469]\n",
            "loss: 3573.06 = -logpx[138330.3], -det[-13738.0], -norms[-223317.3], reg[0.0042]; bits/pixel: 6.58  [  410/  469]\n",
            "loss: 3582.13 = -logpx[140054.1], -det[-13733.0], -norms[-223885.6], reg[0.0043]; bits/pixel: 6.59  [  420/  469]\n",
            "loss: 3574.00 = -logpx[139528.0], -det[-13730.4], -norms[-224402.8], reg[0.0044]; bits/pixel: 6.58  [  430/  469]\n",
            "loss: 3539.22 = -logpx[135634.8], -det[-13730.3], -norms[-224960.8], reg[0.0044]; bits/pixel: 6.51  [  440/  469]\n",
            "loss: 3528.95 = -logpx[134749.7], -det[-13727.5], -norms[-225393.0], reg[0.0045]; bits/pixel: 6.49  [  450/  469]\n",
            "loss: 3568.71 = -logpx[140298.2], -det[-13723.7], -norms[-225857.0], reg[0.0045]; bits/pixel: 6.57  [  460/  469]\n",
            "Test Error: \n",
            " Avg loss: 3553.59; 6.54 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 3555.43 = -logpx[138881.2], -det[-13706.5], -norms[-226156.9], reg[0.0046]; bits/pixel: 6.54  [    0/  469]\n",
            "loss: 3551.48 = -logpx[138734.9], -det[-13689.4], -norms[-226532.6], reg[0.0047]; bits/pixel: 6.54  [   10/  469]\n",
            "loss: 3521.40 = -logpx[135303.4], -det[-13682.4], -norms[-226958.5], reg[0.0047]; bits/pixel: 6.48  [   20/  469]\n",
            "loss: 3560.13 = -logpx[140580.8], -det[-13672.2], -norms[-227289.3], reg[0.0048]; bits/pixel: 6.55  [   30/  469]\n",
            "loss: 3560.89 = -logpx[141184.6], -det[-13663.0], -norms[-227804.6], reg[0.0048]; bits/pixel: 6.55  [   40/  469]\n",
            "loss: 3551.51 = -logpx[140470.7], -det[-13656.8], -norms[-228297.0], reg[0.0049]; bits/pixel: 6.54  [   50/  469]\n",
            "loss: 3547.13 = -logpx[140405.8], -det[-13651.6], -norms[-228797.9], reg[0.0050]; bits/pixel: 6.53  [   60/  469]\n",
            "loss: 3504.21 = -logpx[135393.0], -det[-13644.2], -norms[-229286.7], reg[0.0050]; bits/pixel: 6.45  [   70/  469]\n",
            "loss: 3530.18 = -logpx[139230.7], -det[-13636.3], -norms[-229807.8], reg[0.0051]; bits/pixel: 6.50  [   80/  469]\n",
            "loss: 3518.40 = -logpx[138220.7], -det[-13625.6], -norms[-230317.2], reg[0.0051]; bits/pixel: 6.47  [   90/  469]\n",
            "loss: 3535.14 = -logpx[140649.4], -det[-13607.7], -norms[-230620.6], reg[0.0052]; bits/pixel: 6.51  [  100/  469]\n",
            "loss: 3517.55 = -logpx[138732.0], -det[-13581.9], -norms[-230980.1], reg[0.0052]; bits/pixel: 6.47  [  110/  469]\n",
            "loss: 3548.34 = -logpx[143074.5], -det[-13564.9], -norms[-231398.8], reg[0.0053]; bits/pixel: 6.53  [  120/  469]\n",
            "loss: 3528.93 = -logpx[141057.8], -det[-13549.4], -norms[-231882.1], reg[0.0054]; bits/pixel: 6.49  [  130/  469]\n",
            "loss: 3498.29 = -logpx[137556.0], -det[-13533.8], -norms[-232318.5], reg[0.0054]; bits/pixel: 6.44  [  140/  469]\n",
            "loss: 3521.74 = -logpx[140955.7], -det[-13518.9], -norms[-232731.0], reg[0.0055]; bits/pixel: 6.48  [  150/  469]\n",
            "loss: 3512.16 = -logpx[140157.3], -det[-13510.0], -norms[-233168.0], reg[0.0055]; bits/pixel: 6.46  [  160/  469]\n",
            "loss: 3514.61 = -logpx[140834.8], -det[-13498.7], -norms[-233542.8], reg[0.0056]; bits/pixel: 6.47  [  170/  469]\n",
            "loss: 3531.13 = -logpx[143308.2], -det[-13481.4], -norms[-233919.6], reg[0.0057]; bits/pixel: 6.50  [  180/  469]\n",
            "loss: 3482.47 = -logpx[137500.0], -det[-13461.2], -norms[-234360.1], reg[0.0057]; bits/pixel: 6.41  [  190/  469]\n",
            "loss: 3498.35 = -logpx[139901.2], -det[-13439.6], -norms[-234749.7], reg[0.0058]; bits/pixel: 6.44  [  200/  469]\n",
            "loss: 3492.87 = -logpx[139674.0], -det[-13421.2], -norms[-235242.3], reg[0.0059]; bits/pixel: 6.43  [  210/  469]\n",
            "loss: 3509.47 = -logpx[142159.2], -det[-13406.4], -norms[-235618.0], reg[0.0059]; bits/pixel: 6.46  [  220/  469]\n",
            "loss: 3483.81 = -logpx[139255.4], -det[-13386.1], -norms[-236018.0], reg[0.0060]; bits/pixel: 6.41  [  230/  469]\n",
            "loss: 3456.12 = -logpx[136019.6], -det[-13357.9], -norms[-236354.9], reg[0.0061]; bits/pixel: 6.36  [  240/  469]\n",
            "loss: 3509.72 = -logpx[143236.9], -det[-13336.9], -norms[-236732.5], reg[0.0061]; bits/pixel: 6.46  [  250/  469]\n",
            "loss: 3476.78 = -logpx[139494.9], -det[-13322.8], -norms[-237221.5], reg[0.0062]; bits/pixel: 6.40  [  260/  469]\n",
            "loss: 3513.33 = -logpx[144471.2], -det[-13303.4], -norms[-237538.1], reg[0.0063]; bits/pixel: 6.47  [  270/  469]\n",
            "loss: 3465.83 = -logpx[138737.8], -det[-13279.9], -norms[-237908.0], reg[0.0063]; bits/pixel: 6.38  [  280/  469]\n",
            "loss: 3464.95 = -logpx[139069.4], -det[-13263.9], -norms[-238369.4], reg[0.0064]; bits/pixel: 6.38  [  290/  469]\n",
            "loss: 3449.78 = -logpx[137581.6], -det[-13249.2], -norms[-238837.7], reg[0.0064]; bits/pixel: 6.35  [  300/  469]\n",
            "loss: 3448.54 = -logpx[137611.6], -det[-13233.1], -norms[-239042.4], reg[0.0065]; bits/pixel: 6.35  [  310/  469]\n",
            "loss: 3472.50 = -logpx[140966.2], -det[-13216.9], -norms[-239346.6], reg[0.0066]; bits/pixel: 6.39  [  320/  469]\n",
            "loss: 3443.70 = -logpx[137688.5], -det[-13198.5], -norms[-239773.6], reg[0.0066]; bits/pixel: 6.34  [  330/  469]\n",
            "loss: 3466.63 = -logpx[140984.6], -det[-13185.0], -norms[-240148.3], reg[0.0067]; bits/pixel: 6.38  [  340/  469]\n",
            "loss: 3458.71 = -logpx[140268.4], -det[-13159.5], -norms[-240470.7], reg[0.0068]; bits/pixel: 6.36  [  350/  469]\n",
            "loss: 3470.49 = -logpx[141985.3], -det[-13132.7], -norms[-240707.4], reg[0.0068]; bits/pixel: 6.39  [  360/  469]\n",
            "loss: 3447.99 = -logpx[139599.2], -det[-13113.9], -norms[-241218.9], reg[0.0069]; bits/pixel: 6.34  [  370/  469]\n",
            "loss: 3462.43 = -logpx[141886.1], -det[-13102.9], -norms[-241669.5], reg[0.0070]; bits/pixel: 6.37  [  380/  469]\n",
            "loss: 3419.62 = -logpx[136871.1], -det[-13094.7], -norms[-242141.8], reg[0.0071]; bits/pixel: 6.29  [  390/  469]\n",
            "loss: 3446.70 = -logpx[140555.5], -det[-13079.6], -norms[-242374.8], reg[0.0071]; bits/pixel: 6.34  [  400/  469]\n",
            "loss: 3440.10 = -logpx[140101.9], -det[-13058.8], -norms[-242787.2], reg[0.0072]; bits/pixel: 6.33  [  410/  469]\n",
            "loss: 3439.73 = -logpx[140486.0], -det[-13040.4], -norms[-243237.5], reg[0.0073]; bits/pixel: 6.33  [  420/  469]\n",
            "loss: 3418.55 = -logpx[138126.9], -det[-13022.7], -norms[-243606.2], reg[0.0073]; bits/pixel: 6.29  [  430/  469]\n",
            "loss: 3418.65 = -logpx[138463.3], -det[-13001.6], -norms[-243951.5], reg[0.0074]; bits/pixel: 6.29  [  440/  469]\n",
            "loss: 3368.52 = -logpx[132426.4], -det[-12983.7], -norms[-244348.6], reg[0.0075]; bits/pixel: 6.20  [  450/  469]\n",
            "loss: 3406.98 = -logpx[137596.4], -det[-12973.0], -norms[-244606.8], reg[0.0075]; bits/pixel: 6.27  [  460/  469]\n",
            "Test Error: \n",
            " Avg loss: 3426.45; 6.31 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 3461.46 = -logpx[144886.2], -det[-12956.2], -norms[-244940.4], reg[0.0076]; bits/pixel: 6.37  [    0/  469]\n",
            "loss: 3419.97 = -logpx[139894.3], -det[-12937.4], -norms[-245277.7], reg[0.0077]; bits/pixel: 6.29  [   10/  469]\n",
            "loss: 3428.96 = -logpx[141387.1], -det[-12912.7], -norms[-245644.6], reg[0.0077]; bits/pixel: 6.31  [   20/  469]\n",
            "loss: 3423.16 = -logpx[140896.7], -det[-12886.9], -norms[-245922.2], reg[0.0078]; bits/pixel: 6.30  [   30/  469]\n",
            "loss: 3366.43 = -logpx[134126.0], -det[-12864.5], -norms[-246435.9], reg[0.0079]; bits/pixel: 6.19  [   40/  469]\n",
            "loss: 3387.47 = -logpx[137039.0], -det[-12853.2], -norms[-246666.1], reg[0.0080]; bits/pixel: 6.23  [   50/  469]\n",
            "loss: 3413.71 = -logpx[140690.6], -det[-12830.0], -norms[-246983.1], reg[0.0080]; bits/pixel: 6.28  [   60/  469]\n",
            "loss: 3420.30 = -logpx[141811.7], -det[-12810.0], -norms[-247280.2], reg[0.0081]; bits/pixel: 6.29  [   70/  469]\n",
            "loss: 3426.23 = -logpx[142799.3], -det[-12791.2], -norms[-247527.5], reg[0.0082]; bits/pixel: 6.30  [   80/  469]\n",
            "loss: 3387.93 = -logpx[138310.2], -det[-12776.1], -norms[-247956.4], reg[0.0082]; bits/pixel: 6.23  [   90/  469]\n",
            "loss: 3358.75 = -logpx[134929.9], -det[-12766.2], -norms[-248321.0], reg[0.0083]; bits/pixel: 6.18  [  100/  469]\n",
            "loss: 3352.66 = -logpx[134418.7], -det[-12750.0], -norms[-248605.7], reg[0.0084]; bits/pixel: 6.17  [  110/  469]\n",
            "loss: 3431.92 = -logpx[144851.6], -det[-12736.5], -norms[-248905.9], reg[0.0084]; bits/pixel: 6.32  [  120/  469]\n",
            "loss: 3374.65 = -logpx[137741.7], -det[-12711.0], -norms[-249152.0], reg[0.0085]; bits/pixel: 6.21  [  130/  469]\n",
            "loss: 3390.11 = -logpx[139819.8], -det[-12683.1], -norms[-249279.0], reg[0.0086]; bits/pixel: 6.24  [  140/  469]\n",
            "loss: 3376.79 = -logpx[138504.2], -det[-12661.9], -norms[-249690.6], reg[0.0086]; bits/pixel: 6.21  [  150/  469]\n",
            "loss: 3388.20 = -logpx[140212.6], -det[-12643.2], -norms[-249956.8], reg[0.0087]; bits/pixel: 6.23  [  160/  469]\n",
            "loss: 3375.30 = -logpx[138840.0], -det[-12626.8], -norms[-250251.3], reg[0.0088]; bits/pixel: 6.21  [  170/  469]\n",
            "loss: 3364.74 = -logpx[137891.0], -det[-12615.1], -norms[-250666.4], reg[0.0089]; bits/pixel: 6.19  [  180/  469]\n",
            "loss: 3371.86 = -logpx[139151.2], -det[-12614.2], -norms[-251015.8], reg[0.0089]; bits/pixel: 6.20  [  190/  469]\n",
            "loss: 3353.98 = -logpx[137254.3], -det[-12595.3], -norms[-251426.5], reg[0.0090]; bits/pixel: 6.17  [  200/  469]\n",
            "loss: 3437.32 = -logpx[148036.6], -det[-12577.1], -norms[-251558.8], reg[0.0091]; bits/pixel: 6.33  [  210/  469]\n",
            "loss: 3337.10 = -logpx[135509.8], -det[-12551.3], -norms[-251886.3], reg[0.0091]; bits/pixel: 6.14  [  220/  469]\n",
            "loss: 3365.89 = -logpx[139566.8], -det[-12535.5], -norms[-252273.6], reg[0.0092]; bits/pixel: 6.19  [  230/  469]\n",
            "loss: 3392.08 = -logpx[143117.8], -det[-12514.5], -norms[-252493.5], reg[0.0093]; bits/pixel: 6.24  [  240/  469]\n",
            "loss: 3388.73 = -logpx[142902.3], -det[-12484.4], -norms[-252736.8], reg[0.0093]; bits/pixel: 6.24  [  250/  469]\n",
            "loss: 3394.84 = -logpx[144102.6], -det[-12464.9], -norms[-253175.4], reg[0.0094]; bits/pixel: 6.25  [  260/  469]\n",
            "loss: 3333.23 = -logpx[136365.3], -det[-12444.3], -norms[-253344.0], reg[0.0095]; bits/pixel: 6.13  [  270/  469]\n",
            "loss: 3427.59 = -logpx[148778.8], -det[-12430.7], -norms[-253693.6], reg[0.0096]; bits/pixel: 6.31  [  280/  469]\n",
            "loss: 3383.46 = -logpx[143199.8], -det[-12407.5], -norms[-253786.2], reg[0.0096]; bits/pixel: 6.23  [  290/  469]\n",
            "loss: 3353.58 = -logpx[139466.7], -det[-12367.8], -norms[-253917.5], reg[0.0097]; bits/pixel: 6.17  [  300/  469]\n",
            "loss: 3377.84 = -logpx[142781.0], -det[-12337.8], -norms[-254157.0], reg[0.0098]; bits/pixel: 6.22  [  310/  469]\n",
            "loss: 3371.38 = -logpx[142234.0], -det[-12313.1], -norms[-254460.7], reg[0.0099]; bits/pixel: 6.20  [  320/  469]\n",
            "loss: 3357.10 = -logpx[140735.8], -det[-12285.8], -norms[-254818.0], reg[0.0099]; bits/pixel: 6.18  [  330/  469]\n",
            "loss: 3338.39 = -logpx[138647.7], -det[-12265.7], -norms[-255145.0], reg[0.0100]; bits/pixel: 6.14  [  340/  469]\n",
            "loss: 3379.00 = -logpx[144024.6], -det[-12250.5], -norms[-255339.3], reg[0.0101]; bits/pixel: 6.22  [  350/  469]\n",
            "loss: 3323.42 = -logpx[136957.9], -det[-12191.6], -norms[-255445.1], reg[0.0102]; bits/pixel: 6.12  [  360/  469]\n",
            "loss: 3353.50 = -logpx[141116.5], -det[-12168.8], -norms[-255776.2], reg[0.0102]; bits/pixel: 6.17  [  370/  469]\n",
            "loss: 3309.88 = -logpx[135815.5], -det[-12151.4], -norms[-256076.3], reg[0.0103]; bits/pixel: 6.09  [  380/  469]\n",
            "loss: 3339.06 = -logpx[139735.0], -det[-12128.9], -norms[-256283.5], reg[0.0104]; bits/pixel: 6.14  [  390/  469]\n",
            "loss: 3312.06 = -logpx[136660.0], -det[-12100.2], -norms[-256693.5], reg[0.0105]; bits/pixel: 6.09  [  400/  469]\n",
            "loss: 3340.68 = -logpx[140748.8], -det[-12089.1], -norms[-257129.1], reg[0.0105]; bits/pixel: 6.15  [  410/  469]\n",
            "loss: 3394.08 = -logpx[148052.8], -det[-12089.1], -norms[-257598.5], reg[0.0106]; bits/pixel: 6.25  [  420/  469]\n",
            "loss: 3314.05 = -logpx[137972.9], -det[-12075.6], -norms[-257776.2], reg[0.0107]; bits/pixel: 6.10  [  430/  469]\n",
            "loss: 3314.12 = -logpx[138320.4], -det[-12059.1], -norms[-258130.8], reg[0.0108]; bits/pixel: 6.10  [  440/  469]\n",
            "loss: 3301.28 = -logpx[136960.9], -det[-12046.8], -norms[-258426.7], reg[0.0108]; bits/pixel: 6.07  [  450/  469]\n",
            "loss: 3307.34 = -logpx[138063.8], -det[-12035.2], -norms[-258765.5], reg[0.0109]; bits/pixel: 6.09  [  460/  469]\n",
            "Test Error: \n",
            " Avg loss: 3324.77; 6.12 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 3350.38 = -logpx[143692.2], -det[-12024.1], -norms[-258895.8], reg[0.0110]; bits/pixel: 6.17  [    0/  469]\n",
            "loss: 3305.15 = -logpx[138384.8], -det[-12015.2], -norms[-259387.3], reg[0.0111]; bits/pixel: 6.08  [   10/  469]\n",
            "loss: 3340.28 = -logpx[143036.3], -det[-12005.8], -norms[-259551.5], reg[0.0111]; bits/pixel: 6.15  [   20/  469]\n",
            "loss: 3369.79 = -logpx[146956.1], -det[-11992.6], -norms[-259707.4], reg[0.0112]; bits/pixel: 6.20  [   30/  469]\n",
            "loss: 3292.38 = -logpx[137421.1], -det[-11973.8], -norms[-260099.2], reg[0.0113]; bits/pixel: 6.06  [   40/  469]\n",
            "loss: 3292.41 = -logpx[137752.5], -det[-11962.8], -norms[-260437.9], reg[0.0114]; bits/pixel: 6.06  [   50/  469]\n",
            "loss: 3368.47 = -logpx[147618.2], -det[-11945.0], -norms[-260586.0], reg[0.0114]; bits/pixel: 6.20  [   60/  469]\n",
            "loss: 3305.54 = -logpx[139855.9], -det[-11932.5], -norms[-260890.9], reg[0.0115]; bits/pixel: 6.08  [   70/  469]\n",
            "loss: 3295.69 = -logpx[138842.6], -det[-11917.1], -norms[-261154.0], reg[0.0116]; bits/pixel: 6.06  [   80/  469]\n",
            "loss: 3278.74 = -logpx[136863.8], -det[-11896.0], -norms[-261365.8], reg[0.0117]; bits/pixel: 6.03  [   90/  469]\n",
            "loss: 3273.41 = -logpx[136444.9], -det[-11875.9], -norms[-261648.8], reg[0.0117]; bits/pixel: 6.02  [  100/  469]\n",
            "loss: 3328.55 = -logpx[143707.5], -det[-11858.4], -norms[-261871.7], reg[0.0118]; bits/pixel: 6.13  [  110/  469]\n",
            "loss: 3284.74 = -logpx[138384.9], -det[-11836.5], -norms[-262179.2], reg[0.0119]; bits/pixel: 6.04  [  120/  469]\n",
            "loss: 3257.44 = -logpx[135224.3], -det[-11825.4], -norms[-262523.4], reg[0.0120]; bits/pixel: 5.99  [  130/  469]\n",
            "loss: 3308.20 = -logpx[141948.2], -det[-11816.3], -norms[-262759.1], reg[0.0120]; bits/pixel: 6.09  [  140/  469]\n",
            "loss: 3295.07 = -logpx[140596.9], -det[-11804.4], -norms[-263100.7], reg[0.0121]; bits/pixel: 6.06  [  150/  469]\n",
            "loss: 3238.56 = -logpx[133711.8], -det[-11796.9], -norms[-263456.0], reg[0.0122]; bits/pixel: 5.96  [  160/  469]\n",
            "loss: 3310.88 = -logpx[143226.5], -det[-11786.5], -norms[-263724.2], reg[0.0122]; bits/pixel: 6.09  [  170/  469]\n",
            "loss: 3269.96 = -logpx[138296.8], -det[-11777.9], -norms[-264040.8], reg[0.0123]; bits/pixel: 6.02  [  180/  469]\n",
            "loss: 3289.76 = -logpx[141052.2], -det[-11765.9], -norms[-264273.7], reg[0.0124]; bits/pixel: 6.05  [  190/  469]\n",
            "loss: 3261.98 = -logpx[137901.0], -det[-11762.0], -norms[-264682.3], reg[0.0124]; bits/pixel: 6.00  [  200/  469]\n",
            "loss: 3306.48 = -logpx[143854.5], -det[-11753.3], -norms[-264948.6], reg[0.0125]; bits/pixel: 6.08  [  210/  469]\n",
            "loss: 3267.60 = -logpx[139020.9], -det[-11741.8], -norms[-265103.4], reg[0.0126]; bits/pixel: 6.01  [  220/  469]\n",
            "loss: 3248.91 = -logpx[136738.0], -det[-11711.8], -norms[-265242.9], reg[0.0127]; bits/pixel: 5.98  [  230/  469]\n",
            "loss: 3232.94 = -logpx[134886.4], -det[-11684.7], -norms[-265462.6], reg[0.0128]; bits/pixel: 5.95  [  240/  469]\n",
            "loss: 3219.06 = -logpx[133362.2], -det[-11683.7], -norms[-265715.4], reg[0.0129]; bits/pixel: 5.92  [  250/  469]\n",
            "loss: 3300.24 = -logpx[143769.3], -det[-11644.3], -norms[-265771.2], reg[0.0129]; bits/pixel: 6.07  [  260/  469]\n",
            "loss: 3320.86 = -logpx[146651.8], -det[-11614.2], -norms[-266044.4], reg[0.0130]; bits/pixel: 6.11  [  270/  469]\n",
            "loss: 3289.04 = -logpx[142625.8], -det[-11584.5], -norms[-266121.1], reg[0.0131]; bits/pixel: 6.05  [  280/  469]\n",
            "loss: 3289.87 = -logpx[142910.4], -det[-11550.6], -norms[-266334.0], reg[0.0132]; bits/pixel: 6.05  [  290/  469]\n",
            "loss: 3249.13 = -logpx[137980.1], -det[-11526.1], -norms[-266642.6], reg[0.0133]; bits/pixel: 5.98  [  300/  469]\n",
            "loss: 3251.10 = -logpx[138378.3], -det[-11502.4], -norms[-266812.5], reg[0.0133]; bits/pixel: 5.98  [  310/  469]\n",
            "loss: 3293.31 = -logpx[143921.0], -det[-11489.5], -norms[-266964.3], reg[0.0134]; bits/pixel: 6.06  [  320/  469]\n",
            "loss: 3244.41 = -logpx[137864.8], -det[-11472.4], -norms[-267184.4], reg[0.0135]; bits/pixel: 5.97  [  330/  469]\n",
            "loss: 3223.62 = -logpx[135576.6], -det[-11450.8], -norms[-267579.3], reg[0.0136]; bits/pixel: 5.93  [  340/  469]\n",
            "loss: 3308.48 = -logpx[146552.5], -det[-11429.9], -norms[-267713.7], reg[0.0136]; bits/pixel: 6.09  [  350/  469]\n",
            "loss: 3303.39 = -logpx[145912.0], -det[-11393.4], -norms[-267761.7], reg[0.0137]; bits/pixel: 6.08  [  360/  469]\n",
            "loss: 3237.55 = -logpx[137887.2], -det[-11368.1], -norms[-268189.4], reg[0.0138]; bits/pixel: 5.96  [  370/  469]\n",
            "loss: 3243.78 = -logpx[139204.8], -det[-11365.6], -norms[-268712.8], reg[0.0139]; bits/pixel: 5.97  [  380/  469]\n",
            "loss: 3223.88 = -logpx[136895.9], -det[-11358.8], -norms[-268957.0], reg[0.0140]; bits/pixel: 5.93  [  390/  469]\n",
            "loss: 3243.57 = -logpx[139636.2], -det[-11343.3], -norms[-269192.1], reg[0.0141]; bits/pixel: 5.97  [  400/  469]\n",
            "loss: 3253.60 = -logpx[141252.0], -det[-11336.3], -norms[-269532.4], reg[0.0141]; bits/pixel: 5.99  [  410/  469]\n",
            "loss: 3209.59 = -logpx[135698.9], -det[-11313.3], -norms[-269635.2], reg[0.0142]; bits/pixel: 5.91  [  420/  469]\n",
            "loss: 3217.75 = -logpx[136962.2], -det[-11298.2], -norms[-269869.4], reg[0.0143]; bits/pixel: 5.92  [  430/  469]\n",
            "loss: 3205.90 = -logpx[135520.3], -det[-11275.7], -norms[-269966.2], reg[0.0144]; bits/pixel: 5.90  [  440/  469]\n",
            "loss: 3231.10 = -logpx[138936.2], -det[-11258.6], -norms[-270174.1], reg[0.0145]; bits/pixel: 5.95  [  450/  469]\n",
            "loss: 3180.85 = -logpx[132596.7], -det[-11228.0], -norms[-270296.1], reg[0.0145]; bits/pixel: 5.85  [  460/  469]\n",
            "Test Error: \n",
            " Avg loss: 3243.84; 5.97 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 3276.88 = -logpx[144873.4], -det[-11203.7], -norms[-270306.3], reg[0.0146]; bits/pixel: 6.03  [    0/  469]\n",
            "loss: 3233.07 = -logpx[139416.3], -det[-11173.5], -norms[-270487.2], reg[0.0147]; bits/pixel: 5.95  [   10/  469]\n",
            "loss: 3186.55 = -logpx[133767.3], -det[-11155.2], -norms[-270810.6], reg[0.0147]; bits/pixel: 5.86  [   20/  469]\n",
            "loss: 3271.48 = -logpx[145038.9], -det[-11151.8], -norms[-271215.1], reg[0.0148]; bits/pixel: 6.02  [   30/  469]\n",
            "loss: 3247.78 = -logpx[142334.7], -det[-11156.6], -norms[-271538.6], reg[0.0149]; bits/pixel: 5.98  [   40/  469]\n",
            "loss: 3207.75 = -logpx[137366.7], -det[-11146.2], -norms[-271705.2], reg[0.0150]; bits/pixel: 5.90  [   50/  469]\n",
            "loss: 3252.56 = -logpx[143357.8], -det[-11134.7], -norms[-271972.8], reg[0.0151]; bits/pixel: 5.99  [   60/  469]\n",
            "loss: 3236.55 = -logpx[141435.0], -det[-11113.3], -norms[-272120.7], reg[0.0151]; bits/pixel: 5.96  [   70/  469]\n",
            "loss: 3197.92 = -logpx[136807.1], -det[-11096.8], -norms[-272453.9], reg[0.0152]; bits/pixel: 5.88  [   80/  469]\n",
            "loss: 3263.04 = -logpx[145422.1], -det[-11095.1], -norms[-272734.6], reg[0.0153]; bits/pixel: 6.00  [   90/  469]\n",
            "loss: 3246.26 = -logpx[143444.1], -det[-11080.0], -norms[-272919.9], reg[0.0154]; bits/pixel: 5.97  [  100/  469]\n",
            "loss: 3180.35 = -logpx[135158.4], -det[-11060.5], -norms[-273090.1], reg[0.0155]; bits/pixel: 5.85  [  110/  469]\n",
            "loss: 3208.62 = -logpx[139085.8], -det[-11047.0], -norms[-273412.7], reg[0.0155]; bits/pixel: 5.90  [  120/  469]\n",
            "loss: 3172.32 = -logpx[134797.3], -det[-11032.8], -norms[-273783.9], reg[0.0156]; bits/pixel: 5.84  [  130/  469]\n",
            "loss: 3204.69 = -logpx[139203.7], -det[-11024.9], -norms[-274055.2], reg[0.0157]; bits/pixel: 5.90  [  140/  469]\n",
            "loss: 3191.54 = -logpx[137906.5], -det[-11024.1], -norms[-274442.0], reg[0.0158]; bits/pixel: 5.87  [  150/  469]\n",
            "loss: 3296.30 = -logpx[151314.2], -det[-11014.6], -norms[-274449.9], reg[0.0159]; bits/pixel: 6.07  [  160/  469]\n",
            "loss: 3188.15 = -logpx[137763.0], -det[-10997.7], -norms[-274758.8], reg[0.0159]; bits/pixel: 5.87  [  170/  469]\n",
            "loss: 3243.58 = -logpx[145039.3], -det[-10986.7], -norms[-274951.9], reg[0.0160]; bits/pixel: 5.97  [  180/  469]\n",
            "loss: 3197.13 = -logpx[139252.6], -det[-10969.8], -norms[-275126.7], reg[0.0161]; bits/pixel: 5.88  [  190/  469]\n",
            "loss: 3227.31 = -logpx[143182.4], -det[-10948.6], -norms[-275215.2], reg[0.0162]; bits/pixel: 5.94  [  200/  469]\n",
            "loss: 3246.57 = -logpx[145666.8], -det[-10927.9], -norms[-275254.6], reg[0.0163]; bits/pixel: 5.97  [  210/  469]\n",
            "loss: 3219.46 = -logpx[142461.5], -det[-10909.2], -norms[-275538.7], reg[0.0163]; bits/pixel: 5.92  [  220/  469]\n",
            "loss: 3240.02 = -logpx[145211.1], -det[-10890.3], -norms[-275675.7], reg[0.0164]; bits/pixel: 5.96  [  230/  469]\n",
            "loss: 3162.35 = -logpx[135466.9], -det[-10864.8], -norms[-275898.8], reg[0.0165]; bits/pixel: 5.82  [  240/  469]\n",
            "loss: 3209.63 = -logpx[141773.8], -det[-10847.6], -norms[-276169.8], reg[0.0166]; bits/pixel: 5.91  [  250/  469]\n",
            "loss: 3210.20 = -logpx[141903.8], -det[-10822.5], -norms[-276252.4], reg[0.0167]; bits/pixel: 5.91  [  260/  469]\n",
            "loss: 3186.05 = -logpx[139003.2], -det[-10798.6], -norms[-276466.9], reg[0.0167]; bits/pixel: 5.86  [  270/  469]\n",
            "loss: 3225.97 = -logpx[144379.8], -det[-10780.3], -norms[-276752.4], reg[0.0168]; bits/pixel: 5.94  [  280/  469]\n",
            "loss: 3205.14 = -logpx[141855.3], -det[-10760.9], -norms[-276913.5], reg[0.0169]; bits/pixel: 5.90  [  290/  469]\n",
            "loss: 3143.77 = -logpx[134230.2], -det[-10745.9], -norms[-277158.2], reg[0.0170]; bits/pixel: 5.79  [  300/  469]\n",
            "loss: 3207.19 = -logpx[142670.9], -det[-10737.1], -norms[-277490.5], reg[0.0170]; bits/pixel: 5.90  [  310/  469]\n",
            "loss: 3200.51 = -logpx[142178.2], -det[-10732.7], -norms[-277856.9], reg[0.0171]; bits/pixel: 5.89  [  320/  469]\n",
            "loss: 3260.14 = -logpx[149801.0], -det[-10727.2], -norms[-277853.1], reg[0.0172]; bits/pixel: 6.00  [  330/  469]\n",
            "loss: 3193.18 = -logpx[141551.0], -det[-10706.0], -norms[-278194.6], reg[0.0173]; bits/pixel: 5.88  [  340/  469]\n",
            "loss: 3206.73 = -logpx[143633.5], -det[-10698.7], -norms[-278550.1], reg[0.0174]; bits/pixel: 5.90  [  350/  469]\n",
            "loss: 3147.46 = -logpx[136259.6], -det[-10681.8], -norms[-278780.0], reg[0.0174]; bits/pixel: 5.79  [  360/  469]\n",
            "loss: 3175.34 = -logpx[139881.3], -det[-10653.8], -norms[-278860.8], reg[0.0175]; bits/pixel: 5.84  [  370/  469]\n",
            "loss: 3226.17 = -logpx[146533.9], -det[-10631.2], -norms[-279029.8], reg[0.0176]; bits/pixel: 5.94  [  380/  469]\n",
            "loss: 3166.70 = -logpx[139143.2], -det[-10608.3], -norms[-279274.3], reg[0.0177]; bits/pixel: 5.83  [  390/  469]\n",
            "loss: 3228.01 = -logpx[147315.3], -det[-10598.7], -norms[-279607.7], reg[0.0177]; bits/pixel: 5.94  [  400/  469]\n",
            "loss: 3176.06 = -logpx[140767.2], -det[-10583.0], -norms[-279725.6], reg[0.0178]; bits/pixel: 5.84  [  410/  469]\n",
            "loss: 3147.46 = -logpx[137313.6], -det[-10566.9], -norms[-279949.3], reg[0.0179]; bits/pixel: 5.79  [  420/  469]\n",
            "loss: 3179.95 = -logpx[141604.9], -det[-10549.6], -norms[-280099.1], reg[0.0180]; bits/pixel: 5.85  [  430/  469]\n",
            "loss: 3217.21 = -logpx[146464.0], -det[-10529.1], -norms[-280208.5], reg[0.0180]; bits/pixel: 5.92  [  440/  469]\n",
            "loss: 3092.55 = -logpx[130815.5], -det[-10504.9], -norms[-280541.2], reg[0.0181]; bits/pixel: 5.69  [  450/  469]\n",
            "loss: 3161.53 = -logpx[139813.8], -det[-10488.1], -norms[-280726.5], reg[0.0182]; bits/pixel: 5.82  [  460/  469]\n",
            "Test Error: \n",
            " Avg loss: 3172.06; 5.84 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 3252.29 = -logpx[151432.5], -det[-10473.9], -norms[-280741.9], reg[0.0183]; bits/pixel: 5.98  [    0/  469]\n",
            "loss: 3170.41 = -logpx[141161.4], -det[-10456.7], -norms[-280968.6], reg[0.0183]; bits/pixel: 5.83  [   10/  469]\n",
            "loss: 3118.12 = -logpx[134630.2], -det[-10439.2], -norms[-281148.9], reg[0.0184]; bits/pixel: 5.74  [   20/  469]\n",
            "loss: 3120.73 = -logpx[135350.9], -det[-10431.8], -norms[-281543.0], reg[0.0185]; bits/pixel: 5.74  [   30/  469]\n",
            "loss: 3206.87 = -logpx[146614.7], -det[-10429.0], -norms[-281783.2], reg[0.0186]; bits/pixel: 5.90  [   40/  469]\n",
            "loss: 3164.40 = -logpx[141405.0], -det[-10420.1], -norms[-282017.9], reg[0.0186]; bits/pixel: 5.82  [   50/  469]\n",
            "loss: 3219.22 = -logpx[148380.7], -det[-10408.3], -norms[-281989.4], reg[0.0187]; bits/pixel: 5.92  [   60/  469]\n",
            "loss: 3161.53 = -logpx[140995.2], -det[-10372.3], -norms[-282023.8], reg[0.0188]; bits/pixel: 5.82  [   70/  469]\n",
            "loss: 3149.82 = -logpx[139712.5], -det[-10352.2], -norms[-282260.2], reg[0.0189]; bits/pixel: 5.80  [   80/  469]\n",
            "loss: 3151.29 = -logpx[140111.2], -det[-10337.8], -norms[-282485.2], reg[0.0190]; bits/pixel: 5.80  [   90/  469]\n",
            "loss: 3114.16 = -logpx[135587.6], -det[-10315.1], -norms[-282737.3], reg[0.0190]; bits/pixel: 5.73  [  100/  469]\n",
            "loss: 3146.06 = -logpx[139960.3], -det[-10304.3], -norms[-283037.6], reg[0.0191]; bits/pixel: 5.79  [  110/  469]\n",
            "loss: 3258.35 = -logpx[154419.9], -det[-10290.7], -norms[-283136.7], reg[0.0192]; bits/pixel: 6.00  [  120/  469]\n",
            "loss: 3189.77 = -logpx[145743.5], -det[-10261.3], -norms[-283268.8], reg[0.0193]; bits/pixel: 5.87  [  130/  469]\n",
            "loss: 3190.77 = -logpx[146063.9], -det[-10242.0], -norms[-283480.2], reg[0.0194]; bits/pixel: 5.87  [  140/  469]\n",
            "loss: 3213.76 = -logpx[148844.1], -det[-10210.9], -norms[-283348.8], reg[0.0195]; bits/pixel: 5.91  [  150/  469]\n",
            "loss: 3261.95 = -logpx[155077.1], -det[-10184.0], -norms[-283440.1], reg[0.0195]; bits/pixel: 6.00  [  160/  469]\n",
            "loss: 3147.01 = -logpx[140772.0], -det[-10163.7], -norms[-283867.9], reg[0.0196]; bits/pixel: 5.79  [  170/  469]\n",
            "loss: 3218.54 = -logpx[150009.2], -det[-10141.2], -norms[-283971.5], reg[0.0197]; bits/pixel: 5.92  [  180/  469]\n",
            "loss: 3089.40 = -logpx[133478.2], -det[-10102.1], -norms[-284009.6], reg[0.0197]; bits/pixel: 5.69  [  190/  469]\n",
            "loss: 3136.81 = -logpx[139964.1], -det[-10085.3], -norms[-284444.2], reg[0.0198]; bits/pixel: 5.77  [  200/  469]\n",
            "loss: 3114.98 = -logpx[137335.9], -det[-10082.9], -norms[-284612.4], reg[0.0199]; bits/pixel: 5.73  [  210/  469]\n",
            "loss: 3112.54 = -logpx[137138.5], -det[-10052.3], -norms[-284757.7], reg[0.0200]; bits/pixel: 5.73  [  220/  469]\n",
            "loss: 3118.65 = -logpx[138343.5], -det[-10033.0], -norms[-285199.7], reg[0.0201]; bits/pixel: 5.74  [  230/  469]\n",
            "loss: 3126.37 = -logpx[139435.6], -det[-10014.1], -norms[-285322.8], reg[0.0202]; bits/pixel: 5.75  [  240/  469]\n",
            "loss: 3111.69 = -logpx[137919.0], -det[-9996.2], -norms[-285703.6], reg[0.0203]; bits/pixel: 5.73  [  250/  469]\n",
            "loss: 3095.13 = -logpx[136201.3], -det[-9988.6], -norms[-286112.5], reg[0.0203]; bits/pixel: 5.70  [  260/  469]\n",
            "loss: 3096.64 = -logpx[136550.3], -det[-9975.1], -norms[-286282.8], reg[0.0204]; bits/pixel: 5.70  [  270/  469]\n",
            "loss: 3122.73 = -logpx[139786.8], -det[-9942.8], -norms[-286210.9], reg[0.0205]; bits/pixel: 5.75  [  280/  469]\n",
            "loss: 3106.83 = -logpx[138259.4], -det[-9926.4], -norms[-286735.4], reg[0.0206]; bits/pixel: 5.72  [  290/  469]\n",
            "loss: 3152.56 = -logpx[144359.4], -det[-9923.5], -norms[-286985.5], reg[0.0207]; bits/pixel: 5.80  [  300/  469]\n",
            "loss: 3108.00 = -logpx[138737.1], -det[-9910.5], -norms[-287079.8], reg[0.0208]; bits/pixel: 5.72  [  310/  469]\n",
            "loss: 3187.95 = -logpx[148987.2], -det[-9878.3], -norms[-287128.2], reg[0.0209]; bits/pixel: 5.87  [  320/  469]\n",
            "loss: 3083.73 = -logpx[135654.3], -det[-9839.8], -norms[-287173.6], reg[0.0209]; bits/pixel: 5.67  [  330/  469]\n",
            "loss: 3125.54 = -logpx[141151.8], -det[-9814.4], -norms[-287345.5], reg[0.0210]; bits/pixel: 5.75  [  340/  469]\n",
            "loss: 3125.87 = -logpx[141229.2], -det[-9787.9], -norms[-287406.5], reg[0.0211]; bits/pixel: 5.75  [  350/  469]\n",
            "loss: 3145.98 = -logpx[144125.2], -det[-9777.0], -norms[-287739.1], reg[0.0212]; bits/pixel: 5.79  [  360/  469]\n",
            "loss: 3115.54 = -logpx[140274.1], -det[-9759.1], -norms[-287803.0], reg[0.0213]; bits/pixel: 5.73  [  370/  469]\n",
            "loss: 3064.58 = -logpx[133929.1], -det[-9740.9], -norms[-287999.2], reg[0.0213]; bits/pixel: 5.64  [  380/  469]\n",
            "loss: 3163.85 = -logpx[146761.0], -det[-9728.9], -norms[-288136.2], reg[0.0214]; bits/pixel: 5.82  [  390/  469]\n",
            "loss: 3093.72 = -logpx[137591.5], -det[-9695.2], -norms[-287977.4], reg[0.0215]; bits/pixel: 5.69  [  400/  469]\n",
            "loss: 3120.40 = -logpx[141110.3], -det[-9666.6], -norms[-288109.4], reg[0.0216]; bits/pixel: 5.74  [  410/  469]\n",
            "loss: 3117.66 = -logpx[140977.8], -det[-9664.5], -norms[-288330.2], reg[0.0217]; bits/pixel: 5.74  [  420/  469]\n",
            "loss: 3133.13 = -logpx[143212.7], -det[-9660.9], -norms[-288588.4], reg[0.0217]; bits/pixel: 5.77  [  430/  469]\n",
            "loss: 3253.44 = -logpx[158970.2], -det[-9727.7], -norms[-288878.5], reg[0.0218]; bits/pixel: 5.99  [  440/  469]\n",
            "loss: 3080.03 = -logpx[137018.8], -det[-9690.0], -norms[-289161.7], reg[0.0219]; bits/pixel: 5.67  [  450/  469]\n",
            "loss: 3077.28 = -logpx[136787.1], -det[-9704.7], -norms[-289267.2], reg[0.0220]; bits/pixel: 5.66  [  460/  469]\n",
            "Test Error: \n",
            " Avg loss: 3118.86; 5.74 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 3099.51 = -logpx[140051.0], -det[-9737.0], -norms[-289654.2], reg[0.0220]; bits/pixel: 5.70  [    0/  469]\n",
            "loss: 3076.40 = -logpx[137182.0], -det[-9733.3], -norms[-289746.6], reg[0.0221]; bits/pixel: 5.66  [   10/  469]\n",
            "loss: 3116.96 = -logpx[142692.0], -det[-9806.6], -norms[-289991.5], reg[0.0222]; bits/pixel: 5.74  [   20/  469]\n",
            "loss: 3047.50 = -logpx[133921.8], -det[-9840.8], -norms[-290077.8], reg[0.0223]; bits/pixel: 5.61  [   30/  469]\n",
            "loss: 3017.90 = -logpx[130582.2], -det[-10041.2], -norms[-290327.2], reg[0.0224]; bits/pixel: 5.55  [   40/  469]\n",
            "loss: 3060.83 = -logpx[136302.0], -det[-9884.1], -norms[-290708.7], reg[0.0225]; bits/pixel: 5.63  [   50/  469]\n",
            "loss: 3049.38 = -logpx[135328.9], -det[-10131.3], -norms[-290953.6], reg[0.0226]; bits/pixel: 5.61  [   60/  469]\n",
            "loss: 3070.40 = -logpx[138005.2], -det[-9948.7], -norms[-291121.9], reg[0.0226]; bits/pixel: 5.65  [   70/  469]\n",
            "loss: 3075.39 = -logpx[139176.3], -det[-10261.7], -norms[-291341.8], reg[0.0227]; bits/pixel: 5.66  [   80/  469]\n",
            "loss: 3120.34 = -logpx[145037.8], -det[-10104.3], -norms[-291607.3], reg[0.0228]; bits/pixel: 5.74  [   90/  469]\n",
            "loss: 3071.97 = -logpx[138722.6], -det[-10093.7], -norms[-291494.1], reg[0.0229]; bits/pixel: 5.65  [  100/  469]\n",
            "loss: 3130.21 = -logpx[146253.4], -det[-10029.6], -norms[-291633.7], reg[0.0230]; bits/pixel: 5.76  [  110/  469]\n",
            "loss: 3123.39 = -logpx[145476.9], -det[-9937.1], -norms[-291823.2], reg[0.0230]; bits/pixel: 5.75  [  120/  469]\n",
            "loss: 3135.20 = -logpx[147230.8], -det[-10058.4], -norms[-291943.6], reg[0.0231]; bits/pixel: 5.77  [  130/  469]\n",
            "loss: 3036.13 = -logpx[134728.2], -det[-10060.2], -norms[-292120.3], reg[0.0232]; bits/pixel: 5.59  [  140/  469]\n",
            "loss: 3091.56 = -logpx[142177.3], -det[-10121.5], -norms[-292412.9], reg[0.0233]; bits/pixel: 5.69  [  150/  469]\n",
            "loss: 3057.58 = -logpx[137627.5], -det[-9904.1], -norms[-292430.1], reg[0.0234]; bits/pixel: 5.63  [  160/  469]\n",
            "loss: 3074.16 = -logpx[139846.7], -det[-9961.9], -norms[-292468.7], reg[0.0235]; bits/pixel: 5.66  [  170/  469]\n",
            "loss: 3099.76 = -logpx[143454.3], -det[-10084.6], -norms[-292677.1], reg[0.0235]; bits/pixel: 5.70  [  180/  469]\n",
            "loss: 3036.07 = -logpx[135515.2], -det[-10149.5], -norms[-292825.9], reg[0.0236]; bits/pixel: 5.59  [  190/  469]\n",
            "loss: 3118.35 = -logpx[146344.5], -det[-10248.0], -norms[-293024.1], reg[0.0237]; bits/pixel: 5.74  [  200/  469]\n",
            "loss: 3055.88 = -logpx[138156.6], -det[-9940.3], -norms[-293140.5], reg[0.0238]; bits/pixel: 5.62  [  210/  469]\n",
            "loss: 3041.32 = -logpx[136372.0], -det[-9921.7], -norms[-293238.3], reg[0.0239]; bits/pixel: 5.60  [  220/  469]\n",
            "loss: 3139.66 = -logpx[149219.0], -det[-9876.0], -norms[-293542.8], reg[0.0239]; bits/pixel: 5.78  [  230/  469]\n",
            "loss: 3151.48 = -logpx[150575.4], -det[-9825.3], -norms[-293436.9], reg[0.0240]; bits/pixel: 5.80  [  240/  469]\n",
            "loss: 3028.77 = -logpx[135230.9], -det[-10170.0], -norms[-293454.9], reg[0.0241]; bits/pixel: 5.57  [  250/  469]\n",
            "loss: 3240.60 = -logpx[162213.2], -det[-9965.6], -norms[-293527.8], reg[0.0242]; bits/pixel: 5.96  [  260/  469]\n",
            "loss: 3134.36 = -logpx[148586.9], -det[-9822.4], -norms[-293643.7], reg[0.0242]; bits/pixel: 5.77  [  270/  469]\n",
            "loss: 3041.05 = -logpx[136859.8], -det[-9833.7], -norms[-293848.1], reg[0.0243]; bits/pixel: 5.60  [  280/  469]\n",
            "loss: 3007.90 = -logpx[132757.3], -det[-9817.4], -norms[-294006.0], reg[0.0244]; bits/pixel: 5.54  [  290/  469]\n",
            "loss: 3053.74 = -logpx[138717.2], -det[-9733.6], -norms[-294182.1], reg[0.0245]; bits/pixel: 5.62  [  300/  469]\n",
            "loss: 3115.07 = -logpx[146848.2], -det[-9858.0], -norms[-294338.6], reg[0.0246]; bits/pixel: 5.73  [  310/  469]\n",
            "loss: 3112.94 = -logpx[146496.3], -det[-9588.4], -norms[-294528.5], reg[0.0246]; bits/pixel: 5.73  [  320/  469]\n",
            "loss: 3075.86 = -logpx[141685.4], -det[-9543.6], -norms[-294508.6], reg[0.0247]; bits/pixel: 5.66  [  330/  469]\n",
            "loss: 3036.10 = -logpx[136980.4], -det[-9697.0], -norms[-294739.7], reg[0.0248]; bits/pixel: 5.59  [  340/  469]\n",
            "loss: 3011.49 = -logpx[134292.7], -det[-9743.9], -norms[-295155.7], reg[0.0249]; bits/pixel: 5.54  [  350/  469]\n",
            "loss: 3085.87 = -logpx[143870.7], -det[-9577.1], -norms[-295378.9], reg[0.0250]; bits/pixel: 5.68  [  360/  469]\n",
            "loss: 3022.72 = -logpx[136107.1], -det[-9716.0], -norms[-295560.3], reg[0.0250]; bits/pixel: 5.56  [  370/  469]\n",
            "loss: 3098.23 = -logpx[145939.4], -det[-9734.7], -norms[-295708.1], reg[0.0251]; bits/pixel: 5.70  [  380/  469]\n",
            "loss: 3040.97 = -logpx[138737.7], -det[-9659.3], -norms[-295911.0], reg[0.0252]; bits/pixel: 5.60  [  390/  469]\n",
            "loss: 3090.81 = -logpx[145355.8], -det[-9686.3], -norms[-296122.9], reg[0.0252]; bits/pixel: 5.69  [  400/  469]\n",
            "loss: 3050.70 = -logpx[140615.0], -det[-9943.2], -norms[-296258.7], reg[0.0253]; bits/pixel: 5.61  [  410/  469]\n",
            "loss: 3041.92 = -logpx[139338.4], -det[-9627.8], -norms[-296421.9], reg[0.0254]; bits/pixel: 5.60  [  420/  469]\n",
            "loss: 2989.73 = -logpx[133244.0], -det[-9886.4], -norms[-296748.7], reg[0.0255]; bits/pixel: 5.50  [  430/  469]\n",
            "loss: 3031.45 = -logpx[138545.9], -det[-9672.8], -norms[-296924.2], reg[0.0256]; bits/pixel: 5.58  [  440/  469]\n",
            "loss: 3208.33 = -logpx[161211.6], -det[-9608.9], -norms[-297013.8], reg[0.0256]; bits/pixel: 5.90  [  450/  469]\n",
            "loss: 3144.15 = -logpx[152968.6], -det[-9620.1], -norms[-296974.2], reg[0.0257]; bits/pixel: 5.79  [  460/  469]\n",
            "Test Error: \n",
            " Avg loss: 3062.91; 5.64 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 3012.44 = -logpx[136427.0], -det[-9725.2], -norms[-297186.2], reg[0.0258]; bits/pixel: 5.54  [    0/  469]\n",
            "loss: 3028.08 = -logpx[138696.6], -det[-9561.9], -norms[-297617.4], reg[0.0259]; bits/pixel: 5.57  [   10/  469]\n",
            "loss: 3003.09 = -logpx[135752.7], -det[-9750.0], -norms[-297684.4], reg[0.0259]; bits/pixel: 5.53  [   20/  469]\n",
            "loss: 3006.76 = -logpx[136481.7], -det[-9917.1], -norms[-297776.0], reg[0.0260]; bits/pixel: 5.53  [   30/  469]\n",
            "loss: 3012.97 = -logpx[137311.2], -det[-9906.3], -norms[-297821.7], reg[0.0261]; bits/pixel: 5.54  [   40/  469]\n",
            "loss: 3053.07 = -logpx[142300.3], -det[-9772.9], -norms[-297811.0], reg[0.0262]; bits/pixel: 5.62  [   50/  469]\n",
            "loss: 3096.78 = -logpx[147867.6], -det[-9760.3], -norms[-297796.6], reg[0.0262]; bits/pixel: 5.70  [   60/  469]\n",
            "loss: 3042.88 = -logpx[141453.3], -det[-9921.2], -norms[-298120.5], reg[0.0263]; bits/pixel: 5.60  [   70/  469]\n",
            "loss: 3000.36 = -logpx[135763.7], -det[-9484.2], -norms[-298310.4], reg[0.0264]; bits/pixel: 5.52  [   80/  469]\n",
            "loss: 3045.08 = -logpx[141565.3], -det[-9536.0], -norms[-298336.6], reg[0.0265]; bits/pixel: 5.60  [   90/  469]\n",
            "loss: 2950.05 = -logpx[130150.0], -det[-9968.9], -norms[-298651.1], reg[0.0265]; bits/pixel: 5.43  [  100/  469]\n",
            "loss: 3128.37 = -logpx[152778.1], -det[-9564.3], -norms[-298859.6], reg[0.0266]; bits/pixel: 5.76  [  110/  469]\n",
            "loss: 3012.49 = -logpx[138036.7], -det[-9599.6], -norms[-298914.7], reg[0.0267]; bits/pixel: 5.54  [  120/  469]\n",
            "loss: 3006.83 = -logpx[137898.2], -det[-9751.6], -norms[-299348.8], reg[0.0268]; bits/pixel: 5.53  [  130/  469]\n",
            "loss: 3060.52 = -logpx[145018.2], -det[-9718.2], -norms[-299630.9], reg[0.0269]; bits/pixel: 5.63  [  140/  469]\n",
            "loss: 3029.61 = -logpx[141092.4], -det[-9546.5], -norms[-299832.9], reg[0.0269]; bits/pixel: 5.58  [  150/  469]\n",
            "loss: 3020.01 = -logpx[139985.0], -det[-9587.3], -norms[-299912.9], reg[0.0270]; bits/pixel: 5.56  [  160/  469]\n",
            "loss: 3032.17 = -logpx[141665.1], -det[-9552.3], -norms[-300072.4], reg[0.0271]; bits/pixel: 5.58  [  170/  469]\n",
            "loss: 3100.05 = -logpx[150644.8], -det[-9591.7], -norms[-300323.3], reg[0.0272]; bits/pixel: 5.70  [  180/  469]\n",
            "loss: 2964.81 = -logpx[133525.7], -det[-9681.4], -norms[-300425.2], reg[0.0273]; bits/pixel: 5.46  [  190/  469]\n",
            "loss: 2986.35 = -logpx[136732.3], -det[-9933.5], -norms[-300622.8], reg[0.0273]; bits/pixel: 5.50  [  200/  469]\n",
            "loss: 3104.35 = -logpx[151435.2], -det[-9409.6], -norms[-300745.4], reg[0.0274]; bits/pixel: 5.71  [  210/  469]\n",
            "loss: 3046.73 = -logpx[144005.4], -det[-9613.6], -norms[-300487.4], reg[0.0275]; bits/pixel: 5.61  [  220/  469]\n",
            "loss: 3062.02 = -logpx[146280.3], -det[-9820.2], -norms[-300598.4], reg[0.0276]; bits/pixel: 5.63  [  230/  469]\n",
            "loss: 3043.46 = -logpx[144070.3], -det[-9784.7], -norms[-300800.2], reg[0.0276]; bits/pixel: 5.60  [  240/  469]\n",
            "loss: 2991.32 = -logpx[137379.5], -det[-9504.1], -norms[-301063.0], reg[0.0277]; bits/pixel: 5.50  [  250/  469]\n",
            "loss: 2999.12 = -logpx[139046.5], -det[-10058.2], -norms[-301178.2], reg[0.0278]; bits/pixel: 5.52  [  260/  469]\n",
            "loss: 2960.49 = -logpx[134008.0], -det[-9902.6], -norms[-301239.4], reg[0.0279]; bits/pixel: 5.45  [  270/  469]\n",
            "loss: 3022.54 = -logpx[142220.0], -det[-10108.2], -norms[-301303.5], reg[0.0280]; bits/pixel: 5.56  [  280/  469]\n",
            "loss: 2935.25 = -logpx[131008.4], -det[-9931.6], -norms[-301441.5], reg[0.0280]; bits/pixel: 5.40  [  290/  469]\n",
            "loss: 3055.32 = -logpx[146171.2], -det[-9801.2], -norms[-301366.1], reg[0.0281]; bits/pixel: 5.62  [  300/  469]\n",
            "loss: 2982.43 = -logpx[136179.7], -det[-9434.5], -norms[-301070.7], reg[0.0282]; bits/pixel: 5.49  [  310/  469]\n",
            "loss: 2949.97 = -logpx[132657.0], -det[-9925.6], -norms[-301211.4], reg[0.0282]; bits/pixel: 5.43  [  320/  469]\n",
            "loss: 3022.46 = -logpx[142014.0], -det[-9819.3], -norms[-301396.8], reg[0.0283]; bits/pixel: 5.56  [  330/  469]\n",
            "loss: 2998.28 = -logpx[138981.5], -det[-9789.0], -norms[-301490.0], reg[0.0284]; bits/pixel: 5.52  [  340/  469]\n",
            "loss: 2981.12 = -logpx[137152.7], -det[-9915.8], -norms[-301730.9], reg[0.0285]; bits/pixel: 5.49  [  350/  469]\n",
            "loss: 3071.10 = -logpx[148867.7], -det[-9952.5], -norms[-301891.2], reg[0.0285]; bits/pixel: 5.65  [  360/  469]\n",
            "loss: 3126.76 = -logpx[155609.8], -det[-9489.3], -norms[-301972.4], reg[0.0286]; bits/pixel: 5.75  [  370/  469]\n",
            "loss: 3027.47 = -logpx[143050.9], -det[-9599.3], -norms[-302011.8], reg[0.0287]; bits/pixel: 5.57  [  380/  469]\n",
            "loss: 2992.58 = -logpx[138878.2], -det[-10049.2], -norms[-301855.8], reg[0.0288]; bits/pixel: 5.51  [  390/  469]\n",
            "loss: 3047.91 = -logpx[146059.5], -det[-10145.4], -norms[-301858.3], reg[0.0288]; bits/pixel: 5.61  [  400/  469]\n",
            "loss: 2934.94 = -logpx[131527.1], -det[-9882.0], -norms[-302049.8], reg[0.0289]; bits/pixel: 5.40  [  410/  469]\n",
            "loss: 2979.62 = -logpx[137371.3], -det[-9772.2], -norms[-302285.0], reg[0.0290]; bits/pixel: 5.48  [  420/  469]\n",
            "loss: 2965.49 = -logpx[136179.0], -det[-9924.1], -norms[-302749.4], reg[0.0290]; bits/pixel: 5.46  [  430/  469]\n",
            "loss: 2981.62 = -logpx[138586.0], -det[-10150.3], -norms[-302865.3], reg[0.0291]; bits/pixel: 5.49  [  440/  469]\n",
            "loss: 2950.08 = -logpx[134375.6], -det[-10073.5], -norms[-302769.1], reg[0.0291]; bits/pixel: 5.43  [  450/  469]\n",
            "loss: 3038.04 = -logpx[145399.1], -det[-9661.4], -norms[-302945.2], reg[0.0292]; bits/pixel: 5.59  [  460/  469]\n",
            "Test Error: \n",
            " Avg loss: 3006.77; 5.53 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 2972.45 = -logpx[137303.6], -det[-9956.8], -norms[-302949.7], reg[0.0293]; bits/pixel: 5.47  [    0/  469]\n",
            "loss: 2995.04 = -logpx[140090.7], -det[-9685.1], -norms[-303117.0], reg[0.0293]; bits/pixel: 5.51  [   10/  469]\n",
            "loss: 2973.81 = -logpx[137596.3], -det[-9556.8], -norms[-303468.9], reg[0.0294]; bits/pixel: 5.47  [   20/  469]\n",
            "loss: 2934.46 = -logpx[133172.6], -det[-9977.4], -norms[-303661.2], reg[0.0295]; bits/pixel: 5.40  [   30/  469]\n",
            "loss: 2964.70 = -logpx[137461.6], -det[-10111.5], -norms[-303946.0], reg[0.0295]; bits/pixel: 5.46  [   40/  469]\n",
            "loss: 3080.55 = -logpx[151891.7], -det[-9733.5], -norms[-303925.3], reg[0.0296]; bits/pixel: 5.67  [   50/  469]\n",
            "loss: 2967.45 = -logpx[138081.6], -det[-10176.7], -norms[-304148.7], reg[0.0297]; bits/pixel: 5.46  [   60/  469]\n",
            "loss: 2969.96 = -logpx[138556.0], -det[-9923.0], -norms[-304554.6], reg[0.0298]; bits/pixel: 5.47  [   70/  469]\n",
            "loss: 3107.03 = -logpx[155965.6], -det[-9746.4], -norms[-304595.7], reg[0.0298]; bits/pixel: 5.72  [   80/  469]\n",
            "loss: 2940.58 = -logpx[135943.1], -det[-10489.7], -norms[-305136.2], reg[0.0299]; bits/pixel: 5.41  [   90/  469]\n",
            "loss: 3013.91 = -logpx[144992.7], -det[-10079.7], -norms[-305209.9], reg[0.0300]; bits/pixel: 5.55  [  100/  469]\n",
            "loss: 2945.04 = -logpx[136591.0], -det[-10082.9], -norms[-305619.4], reg[0.0300]; bits/pixel: 5.42  [  110/  469]\n",
            "loss: 3048.00 = -logpx[150021.8], -det[-10192.1], -norms[-305762.2], reg[0.0301]; bits/pixel: 5.61  [  120/  469]\n",
            "loss: 2888.82 = -logpx[130553.2], -det[-10696.5], -norms[-306164.7], reg[0.0302]; bits/pixel: 5.32  [  130/  469]\n",
            "loss: 2959.59 = -logpx[138919.2], -det[-9978.3], -norms[-306190.4], reg[0.0303]; bits/pixel: 5.45  [  140/  469]\n",
            "loss: 2958.54 = -logpx[139159.0], -det[-10104.3], -norms[-306438.1], reg[0.0304]; bits/pixel: 5.44  [  150/  469]\n",
            "loss: 2977.07 = -logpx[142090.2], -det[-10431.8], -norms[-306670.5], reg[0.0304]; bits/pixel: 5.48  [  160/  469]\n",
            "loss: 2994.85 = -logpx[144409.2], -det[-10433.3], -norms[-306711.4], reg[0.0305]; bits/pixel: 5.51  [  170/  469]\n",
            "loss: 2947.76 = -logpx[138559.5], -det[-10591.1], -norms[-306732.0], reg[0.0306]; bits/pixel: 5.42  [  180/  469]\n",
            "loss: 2936.53 = -logpx[137050.0], -det[-10273.8], -norms[-306977.2], reg[0.0306]; bits/pixel: 5.40  [  190/  469]\n",
            "loss: 2956.16 = -logpx[139885.5], -det[-10408.1], -norms[-307165.8], reg[0.0307]; bits/pixel: 5.44  [  200/  469]\n",
            "loss: 2970.93 = -logpx[142201.9], -det[-10588.0], -norms[-307411.6], reg[0.0308]; bits/pixel: 5.47  [  210/  469]\n",
            "loss: 2942.49 = -logpx[138957.4], -det[-10728.7], -norms[-307666.4], reg[0.0309]; bits/pixel: 5.41  [  220/  469]\n",
            "loss: 2938.13 = -logpx[139584.2], -det[-11809.7], -norms[-307770.8], reg[0.0309]; bits/pixel: 5.41  [  230/  469]\n",
            "loss: 2941.37 = -logpx[140100.0], -det[-11730.4], -norms[-307950.7], reg[0.0310]; bits/pixel: 5.41  [  240/  469]\n",
            "loss: 2937.41 = -logpx[140213.9], -det[-12076.4], -norms[-308226.1], reg[0.0311]; bits/pixel: 5.41  [  250/  469]\n",
            "loss: 2902.53 = -logpx[135323.2], -det[-11728.0], -norms[-308148.0], reg[0.0312]; bits/pixel: 5.34  [  260/  469]\n",
            "loss: 2908.20 = -logpx[137131.3], -det[-12598.1], -norms[-308360.2], reg[0.0313]; bits/pixel: 5.35  [  270/  469]\n",
            "loss: 3008.19 = -logpx[150104.2], -det[-12754.4], -norms[-308378.2], reg[0.0313]; bits/pixel: 5.54  [  280/  469]\n",
            "loss: 2918.48 = -logpx[138599.1], -det[-12591.6], -norms[-308519.1], reg[0.0314]; bits/pixel: 5.37  [  290/  469]\n",
            "loss: 2941.94 = -logpx[140626.9], -det[-11838.5], -norms[-308296.4], reg[0.0315]; bits/pixel: 5.41  [  300/  469]\n",
            "loss: 2889.62 = -logpx[135518.2], -det[-13436.8], -norms[-308287.4], reg[0.0316]; bits/pixel: 5.32  [  310/  469]\n",
            "loss: 2913.83 = -logpx[138558.0], -det[-13323.1], -norms[-308341.6], reg[0.0317]; bits/pixel: 5.36  [  320/  469]\n",
            "loss: 2915.04 = -logpx[139516.8], -det[-13999.6], -norms[-308468.7], reg[0.0318]; bits/pixel: 5.36  [  330/  469]\n",
            "loss: 2898.31 = -logpx[137078.5], -det[-13477.0], -norms[-308694.5], reg[0.0318]; bits/pixel: 5.33  [  340/  469]\n",
            "loss: 2940.77 = -logpx[143983.0], -det[-14814.9], -norms[-308826.4], reg[0.0319]; bits/pixel: 5.41  [  350/  469]\n",
            "loss: 2864.80 = -logpx[134432.3], -det[-14800.1], -norms[-309014.9], reg[0.0320]; bits/pixel: 5.27  [  360/  469]\n",
            "loss: 2851.05 = -logpx[132025.3], -det[-14005.9], -norms[-309162.4], reg[0.0321]; bits/pixel: 5.25  [  370/  469]\n",
            "loss: 2844.62 = -logpx[132630.9], -det[-14984.6], -norms[-309611.4], reg[0.0322]; bits/pixel: 5.23  [  380/  469]\n",
            "loss: 2856.15 = -logpx[134664.5], -det[-15294.3], -norms[-309859.9], reg[0.0323]; bits/pixel: 5.26  [  390/  469]\n",
            "loss: 2895.27 = -logpx[138097.5], -det[-13675.5], -norms[-309903.8], reg[0.0324]; bits/pixel: 5.33  [  400/  469]\n",
            "loss: 2872.16 = -logpx[135688.5], -det[-13841.1], -norms[-310288.2], reg[0.0325]; bits/pixel: 5.29  [  410/  469]\n",
            "loss: 2894.18 = -logpx[139829.7], -det[-14701.5], -norms[-310750.4], reg[0.0326]; bits/pixel: 5.33  [  420/  469]\n",
            "loss: 2852.00 = -logpx[135556.2], -det[-15561.9], -norms[-311015.7], reg[0.0327]; bits/pixel: 5.25  [  430/  469]\n",
            "loss: 2901.93 = -logpx[141392.4], -det[-14974.2], -norms[-311047.6], reg[0.0328]; bits/pixel: 5.34  [  440/  469]\n",
            "loss: 3028.31 = -logpx[157771.0], -det[-15020.8], -norms[-311203.8], reg[0.0329]; bits/pixel: 5.57  [  450/  469]\n",
            "loss: 2900.93 = -logpx[141723.2], -det[-15179.5], -norms[-311302.0], reg[0.0330]; bits/pixel: 5.34  [  460/  469]\n",
            "Test Error: \n",
            " Avg loss: 2897.48; 5.33 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 2848.82 = -logpx[135942.7], -det[-15936.8], -norms[-311434.1], reg[0.0331]; bits/pixel: 5.24  [    0/  469]\n",
            "loss: 2882.60 = -logpx[140233.5], -det[-15611.3], -norms[-311726.7], reg[0.0332]; bits/pixel: 5.30  [   10/  469]\n",
            "loss: 2873.53 = -logpx[139877.6], -det[-16239.9], -norms[-311902.8], reg[0.0332]; bits/pixel: 5.29  [   20/  469]\n",
            "loss: 2903.71 = -logpx[143650.7], -det[-16073.8], -norms[-311979.6], reg[0.0333]; bits/pixel: 5.34  [   30/  469]\n",
            "loss: 2936.47 = -logpx[147649.9], -det[-15522.2], -norms[-312337.1], reg[0.0334]; bits/pixel: 5.40  [   40/  469]\n",
            "loss: 2918.52 = -logpx[144886.6], -det[-14942.8], -norms[-312450.7], reg[0.0335]; bits/pixel: 5.37  [   50/  469]\n",
            "loss: 2826.35 = -logpx[134639.3], -det[-16172.8], -norms[-312770.2], reg[0.0336]; bits/pixel: 5.20  [   60/  469]\n",
            "loss: 2822.39 = -logpx[134505.2], -det[-16208.4], -norms[-313108.3], reg[0.0337]; bits/pixel: 5.19  [   70/  469]\n",
            "loss: 2814.27 = -logpx[135244.0], -det[-17704.2], -norms[-313390.4], reg[0.0338]; bits/pixel: 5.18  [   80/  469]\n",
            "loss: 2815.44 = -logpx[135157.2], -det[-17358.7], -norms[-313498.4], reg[0.0339]; bits/pixel: 5.18  [   90/  469]\n",
            "loss: 2822.91 = -logpx[134898.5], -det[-16067.3], -norms[-313575.1], reg[0.0339]; bits/pixel: 5.19  [  100/  469]\n",
            "loss: 2826.55 = -logpx[135990.2], -det[-16492.5], -norms[-313775.7], reg[0.0340]; bits/pixel: 5.20  [  110/  469]\n",
            "loss: 2795.67 = -logpx[133010.8], -det[-17265.9], -norms[-313976.0], reg[0.0341]; bits/pixel: 5.14  [  120/  469]\n",
            "loss: 2847.37 = -logpx[139096.9], -det[-16737.9], -norms[-313971.9], reg[0.0342]; bits/pixel: 5.24  [  130/  469]\n",
            "loss: 2848.14 = -logpx[140216.6], -det[-17636.9], -norms[-314094.6], reg[0.0343]; bits/pixel: 5.24  [  140/  469]\n",
            "loss: 2847.45 = -logpx[138611.4], -det[-15894.1], -norms[-314321.2], reg[0.0344]; bits/pixel: 5.24  [  150/  469]\n",
            "loss: 2842.74 = -logpx[139855.1], -det[-17627.6], -norms[-314433.5], reg[0.0344]; bits/pixel: 5.23  [  160/  469]\n",
            "loss: 2822.13 = -logpx[136447.4], -det[-16660.2], -norms[-314631.8], reg[0.0345]; bits/pixel: 5.19  [  170/  469]\n",
            "loss: 2901.59 = -logpx[147563.5], -det[-17381.3], -norms[-314855.3], reg[0.0346]; bits/pixel: 5.34  [  180/  469]\n",
            "loss: 2828.54 = -logpx[139476.5], -det[-18643.6], -norms[-314856.8], reg[0.0347]; bits/pixel: 5.20  [  190/  469]\n",
            "loss: 2827.57 = -logpx[138623.3], -det[-17865.4], -norms[-314906.4], reg[0.0348]; bits/pixel: 5.20  [  200/  469]\n",
            "loss: 2813.13 = -logpx[137270.2], -det[-18307.6], -norms[-314959.0], reg[0.0349]; bits/pixel: 5.18  [  210/  469]\n",
            "loss: 2935.43 = -logpx[153691.5], -det[-18846.7], -norms[-315187.2], reg[0.0350]; bits/pixel: 5.40  [  220/  469]\n",
            "loss: 2899.25 = -logpx[147280.0], -det[-17193.5], -norms[-315059.2], reg[0.0351]; bits/pixel: 5.34  [  230/  469]\n",
            "loss: 2794.01 = -logpx[135477.7], -det[-18424.8], -norms[-315496.4], reg[0.0351]; bits/pixel: 5.14  [  240/  469]\n",
            "loss: 2788.63 = -logpx[135641.6], -det[-19120.9], -norms[-315653.3], reg[0.0352]; bits/pixel: 5.13  [  250/  469]\n",
            "loss: 2764.86 = -logpx[131887.0], -det[-18368.7], -norms[-315693.5], reg[0.0353]; bits/pixel: 5.09  [  260/  469]\n",
            "loss: 2891.00 = -logpx[147275.0], -det[-17604.7], -norms[-315698.7], reg[0.0354]; bits/pixel: 5.32  [  270/  469]\n",
            "loss: 2820.45 = -logpx[139433.9], -det[-18809.5], -norms[-315684.2], reg[0.0355]; bits/pixel: 5.19  [  280/  469]\n",
            "loss: 2757.69 = -logpx[131911.8], -det[-19213.1], -norms[-315790.7], reg[0.0356]; bits/pixel: 5.07  [  290/  469]\n",
            "loss: 2774.42 = -logpx[133699.6], -det[-18846.5], -norms[-315804.5], reg[0.0357]; bits/pixel: 5.11  [  300/  469]\n",
            "loss: 3010.89 = -logpx[162136.0], -det[-17036.7], -norms[-315782.6], reg[0.0357]; bits/pixel: 5.54  [  310/  469]\n",
            "loss: 2804.85 = -logpx[136040.9], -det[-17298.6], -norms[-315798.1], reg[0.0358]; bits/pixel: 5.16  [  320/  469]\n",
            "loss: 2806.17 = -logpx[138365.9], -det[-19152.4], -norms[-316100.8], reg[0.0359]; bits/pixel: 5.16  [  330/  469]\n",
            "loss: 2868.03 = -logpx[146670.7], -det[-19329.2], -norms[-316309.9], reg[0.0360]; bits/pixel: 5.28  [  340/  469]\n",
            "loss: 2797.93 = -logpx[136794.0], -det[-18069.4], -norms[-316665.9], reg[0.0361]; bits/pixel: 5.15  [  350/  469]\n",
            "loss: 2870.13 = -logpx[147770.7], -det[-19605.3], -norms[-316865.6], reg[0.0361]; bits/pixel: 5.28  [  360/  469]\n",
            "loss: 2741.89 = -logpx[131428.8], -det[-19307.8], -norms[-317235.5], reg[0.0362]; bits/pixel: 5.05  [  370/  469]\n",
            "loss: 2780.59 = -logpx[137723.7], -det[-20605.9], -norms[-317279.6], reg[0.0363]; bits/pixel: 5.12  [  380/  469]\n",
            "loss: 2780.79 = -logpx[136808.2], -det[-19455.0], -norms[-317488.4], reg[0.0364]; bits/pixel: 5.12  [  390/  469]\n",
            "loss: 2780.15 = -logpx[136461.5], -det[-18936.5], -norms[-317742.7], reg[0.0365]; bits/pixel: 5.12  [  400/  469]\n",
            "loss: 2945.94 = -logpx[158046.6], -det[-19424.5], -norms[-317618.9], reg[0.0366]; bits/pixel: 5.42  [  410/  469]\n",
            "loss: 2766.09 = -logpx[135328.1], -det[-19588.6], -norms[-317756.6], reg[0.0367]; bits/pixel: 5.09  [  420/  469]\n",
            "loss: 2725.19 = -logpx[131979.8], -det[-21233.9], -norms[-317998.5], reg[0.0368]; bits/pixel: 5.01  [  430/  469]\n",
            "loss: 2732.24 = -logpx[132842.9], -det[-20852.3], -norms[-318341.1], reg[0.0369]; bits/pixel: 5.03  [  440/  469]\n",
            "loss: 2831.78 = -logpx[144437.0], -det[-19851.7], -norms[-318193.7], reg[0.0370]; bits/pixel: 5.21  [  450/  469]\n",
            "loss: 2823.15 = -logpx[143010.5], -det[-19397.9], -norms[-318326.6], reg[0.0371]; bits/pixel: 5.20  [  460/  469]\n",
            "Test Error: \n",
            " Avg loss: 2807.86; 5.17 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 2806.04 = -logpx[141541.2], -det[-20073.0], -norms[-318372.4], reg[0.0372]; bits/pixel: 5.16  [    0/  469]\n",
            "loss: 2721.73 = -logpx[131925.2], -det[-21218.4], -norms[-318402.4], reg[0.0372]; bits/pixel: 5.01  [   10/  469]\n",
            "loss: 2987.29 = -logpx[165336.8], -det[-20432.8], -norms[-318607.4], reg[0.0373]; bits/pixel: 5.50  [   20/  469]\n",
            "loss: 2784.69 = -logpx[138998.3], -det[-19981.9], -norms[-318653.4], reg[0.0374]; bits/pixel: 5.12  [   30/  469]\n",
            "loss: 2727.16 = -logpx[133451.8], -det[-21691.6], -norms[-318760.8], reg[0.0375]; bits/pixel: 5.02  [   40/  469]\n",
            "loss: 2742.40 = -logpx[135642.9], -det[-21869.8], -norms[-318823.5], reg[0.0376]; bits/pixel: 5.05  [   50/  469]\n",
            "loss: 2854.27 = -logpx[148529.2], -det[-20330.4], -norms[-318929.4], reg[0.0376]; bits/pixel: 5.25  [   60/  469]\n",
            "loss: 2800.67 = -logpx[142639.8], -det[-21093.6], -norms[-319136.9], reg[0.0377]; bits/pixel: 5.15  [   70/  469]\n",
            "loss: 2750.37 = -logpx[137867.5], -det[-22613.7], -norms[-319283.3], reg[0.0378]; bits/pixel: 5.06  [   80/  469]\n",
            "loss: 2858.11 = -logpx[151100.5], -det[-22021.3], -norms[-319317.6], reg[0.0379]; bits/pixel: 5.26  [   90/  469]\n",
            "loss: 2839.90 = -logpx[145838.3], -det[-18786.5], -norms[-319621.5], reg[0.0380]; bits/pixel: 5.23  [  100/  469]\n",
            "loss: 2783.35 = -logpx[139799.1], -det[-19744.4], -norms[-319863.0], reg[0.0381]; bits/pixel: 5.12  [  110/  469]\n",
            "loss: 2789.37 = -logpx[141401.4], -det[-20395.5], -norms[-320043.2], reg[0.0381]; bits/pixel: 5.13  [  120/  469]\n",
            "loss: 2698.76 = -logpx[131329.7], -det[-21768.8], -norms[-320196.7], reg[0.0382]; bits/pixel: 4.97  [  130/  469]\n",
            "loss: 2779.42 = -logpx[141248.9], -det[-21219.7], -norms[-320340.7], reg[0.0383]; bits/pixel: 5.11  [  140/  469]\n",
            "loss: 2716.25 = -logpx[133605.9], -det[-21520.6], -norms[-320482.5], reg[0.0384]; bits/pixel: 5.00  [  150/  469]\n",
            "loss: 2712.30 = -logpx[134234.0], -det[-22363.8], -norms[-320772.1], reg[0.0385]; bits/pixel: 4.99  [  160/  469]\n",
            "loss: 2742.28 = -logpx[136573.6], -det[-20822.6], -norms[-320815.8], reg[0.0386]; bits/pixel: 5.05  [  170/  469]\n",
            "loss: 3015.86 = -logpx[169937.3], -det[-19245.1], -norms[-320739.0], reg[0.0386]; bits/pixel: 5.55  [  180/  469]\n",
            "loss: 2720.15 = -logpx[134534.9], -det[-21493.9], -norms[-320938.9], reg[0.0387]; bits/pixel: 5.01  [  190/  469]\n",
            "loss: 2708.43 = -logpx[134280.0], -det[-22489.5], -norms[-321188.1], reg[0.0388]; bits/pixel: 4.98  [  200/  469]\n",
            "loss: 2714.08 = -logpx[133994.5], -det[-21270.5], -norms[-321398.2], reg[0.0389]; bits/pixel: 4.99  [  210/  469]\n",
            "loss: 2658.66 = -logpx[129285.8], -det[-23316.5], -norms[-321738.3], reg[0.0390]; bits/pixel: 4.89  [  220/  469]\n",
            "loss: 2743.45 = -logpx[138714.5], -det[-21893.0], -norms[-321736.6], reg[0.0390]; bits/pixel: 5.05  [  230/  469]\n",
            "loss: 2816.21 = -logpx[147301.0], -det[-21180.5], -norms[-321722.9], reg[0.0391]; bits/pixel: 5.18  [  240/  469]\n",
            "loss: 2715.31 = -logpx[134973.9], -det[-21662.0], -norms[-321828.9], reg[0.0392]; bits/pixel: 5.00  [  250/  469]\n",
            "loss: 2904.46 = -logpx[158019.7], -det[-20747.8], -norms[-321577.4], reg[0.0393]; bits/pixel: 5.34  [  260/  469]\n",
            "loss: 2738.24 = -logpx[138726.5], -det[-22310.3], -norms[-321997.8], reg[0.0393]; bits/pixel: 5.04  [  270/  469]\n",
            "loss: 2668.48 = -logpx[132342.9], -det[-24653.5], -norms[-322200.9], reg[0.0394]; bits/pixel: 4.91  [  280/  469]\n",
            "loss: 2701.66 = -logpx[135407.5], -det[-23325.4], -norms[-322346.8], reg[0.0395]; bits/pixel: 4.97  [  290/  469]\n",
            "loss: 2679.70 = -logpx[133210.3], -det[-23735.7], -norms[-322550.0], reg[0.0395]; bits/pixel: 4.93  [  300/  469]\n",
            "loss: 2760.98 = -logpx[141365.0], -det[-21300.7], -norms[-322735.5], reg[0.0396]; bits/pixel: 5.08  [  310/  469]\n",
            "loss: 2907.53 = -logpx[159587.2], -det[-20782.0], -norms[-322718.6], reg[0.0397]; bits/pixel: 5.35  [  320/  469]\n",
            "loss: 2704.25 = -logpx[136314.1], -det[-23357.6], -norms[-322888.9], reg[0.0397]; bits/pixel: 4.98  [  330/  469]\n",
            "loss: 2817.55 = -logpx[150598.3], -det[-22928.4], -norms[-323100.6], reg[0.0398]; bits/pixel: 5.18  [  340/  469]\n",
            "loss: 2681.94 = -logpx[135087.0], -det[-24629.8], -norms[-323245.3], reg[0.0399]; bits/pixel: 4.94  [  350/  469]\n",
            "loss: 2754.23 = -logpx[140498.5], -det[-20646.2], -norms[-323387.3], reg[0.0400]; bits/pixel: 5.07  [  360/  469]\n",
            "loss: 2703.64 = -logpx[136685.2], -det[-23130.7], -norms[-323565.7], reg[0.0401]; bits/pixel: 4.98  [  370/  469]\n",
            "loss: 2823.42 = -logpx[152408.2], -det[-23269.2], -norms[-323818.2], reg[0.0402]; bits/pixel: 5.20  [  380/  469]\n",
            "loss: 2679.45 = -logpx[134586.3], -det[-23741.4], -norms[-323952.2], reg[0.0403]; bits/pixel: 4.93  [  390/  469]\n",
            "loss: 2750.93 = -logpx[141791.0], -det[-21749.7], -norms[-323999.3], reg[0.0403]; bits/pixel: 5.06  [  400/  469]\n",
            "loss: 2782.73 = -logpx[147288.3], -det[-23042.2], -norms[-324133.7], reg[0.0404]; bits/pixel: 5.12  [  410/  469]\n",
            "loss: 2702.05 = -logpx[139076.6], -det[-24917.2], -norms[-324373.8], reg[0.0405]; bits/pixel: 4.97  [  420/  469]\n",
            "loss: 2686.66 = -logpx[136175.5], -det[-23909.3], -norms[-324451.1], reg[0.0405]; bits/pixel: 4.94  [  430/  469]\n",
            "loss: 2674.82 = -logpx[135308.4], -det[-24249.3], -norms[-324758.9], reg[0.0406]; bits/pixel: 4.92  [  440/  469]\n",
            "loss: 2700.68 = -logpx[138691.2], -det[-24111.7], -norms[-324969.7], reg[0.0407]; bits/pixel: 4.97  [  450/  469]\n",
            "loss: 2687.34 = -logpx[137110.8], -det[-24092.6], -norms[-325115.2], reg[0.0408]; bits/pixel: 4.95  [  460/  469]\n",
            "Test Error: \n",
            " Avg loss: 2722.32; 5.01 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 2915.08 = -logpx[166482.3], -det[-24248.4], -norms[-325180.9], reg[0.0408]; bits/pixel: 5.36  [    0/  469]\n",
            "loss: 2816.37 = -logpx[154847.9], -det[-25225.4], -norms[-325204.6], reg[0.0409]; bits/pixel: 5.18  [   10/  469]\n",
            "loss: 2714.99 = -logpx[141389.7], -det[-24327.4], -norms[-325620.9], reg[0.0410]; bits/pixel: 5.00  [   20/  469]\n",
            "loss: 2700.67 = -logpx[139932.0], -det[-24602.4], -norms[-325721.1], reg[0.0411]; bits/pixel: 4.97  [   30/  469]\n",
            "loss: 2709.54 = -logpx[141366.6], -det[-24774.3], -norms[-325848.7], reg[0.0412]; bits/pixel: 4.99  [   40/  469]\n",
            "loss: 2820.02 = -logpx[157147.4], -det[-26454.0], -norms[-325807.2], reg[0.0412]; bits/pixel: 5.19  [   50/  469]\n",
            "loss: 2715.05 = -logpx[142206.8], -det[-24982.2], -norms[-325775.3], reg[0.0413]; bits/pixel: 5.00  [   60/  469]\n",
            "loss: 2719.19 = -logpx[143354.3], -det[-25451.5], -norms[-325923.8], reg[0.0414]; bits/pixel: 5.00  [   70/  469]\n",
            "loss: 2651.13 = -logpx[133178.5], -det[-23852.6], -norms[-326058.7], reg[0.0415]; bits/pixel: 4.88  [   80/  469]\n",
            "loss: 2668.00 = -logpx[136214.2], -det[-24772.6], -norms[-326014.0], reg[0.0416]; bits/pixel: 4.91  [   90/  469]\n",
            "loss: 2639.00 = -logpx[133594.6], -det[-25720.2], -norms[-326159.7], reg[0.0416]; bits/pixel: 4.86  [  100/  469]\n",
            "loss: 2728.20 = -logpx[144300.2], -det[-24800.9], -norms[-326367.0], reg[0.0417]; bits/pixel: 5.02  [  110/  469]\n",
            "loss: 2728.05 = -logpx[146575.6], -det[-27000.5], -norms[-326461.3], reg[0.0418]; bits/pixel: 5.02  [  120/  469]\n",
            "loss: 2698.14 = -logpx[143616.9], -det[-27833.7], -norms[-326497.9], reg[0.0419]; bits/pixel: 4.97  [  130/  469]\n",
            "loss: 2624.27 = -logpx[131890.4], -det[-25786.2], -norms[-326274.3], reg[0.0420]; bits/pixel: 4.83  [  140/  469]\n",
            "loss: 2685.42 = -logpx[140452.5], -det[-26334.4], -norms[-326461.1], reg[0.0421]; bits/pixel: 4.94  [  150/  469]\n",
            "loss: 2666.39 = -logpx[138166.9], -det[-26304.1], -norms[-326641.5], reg[0.0421]; bits/pixel: 4.91  [  160/  469]\n",
            "loss: 2636.88 = -logpx[135317.3], -det[-27285.5], -norms[-326587.8], reg[0.0422]; bits/pixel: 4.85  [  170/  469]\n",
            "loss: 2644.28 = -logpx[134423.3], -det[-25362.9], -norms[-326669.2], reg[0.0423]; bits/pixel: 4.87  [  180/  469]\n",
            "loss: 2692.92 = -logpx[140537.3], -det[-24813.9], -norms[-327106.9], reg[0.0424]; bits/pixel: 4.96  [  190/  469]\n",
            "loss: 2562.96 = -logpx[128701.0], -det[-29438.9], -norms[-327280.1], reg[0.0425]; bits/pixel: 4.72  [  200/  469]\n",
            "loss: 2643.05 = -logpx[136570.9], -det[-27035.1], -norms[-327302.9], reg[0.0425]; bits/pixel: 4.86  [  210/  469]\n",
            "loss: 2687.25 = -logpx[139516.3], -det[-24284.0], -norms[-327341.4], reg[0.0426]; bits/pixel: 4.95  [  220/  469]\n",
            "loss: 2688.73 = -logpx[142145.5], -det[-26587.2], -norms[-327477.3], reg[0.0427]; bits/pixel: 4.95  [  230/  469]\n",
            "loss: 2622.77 = -logpx[132597.8], -det[-25268.0], -norms[-327692.3], reg[0.0428]; bits/pixel: 4.83  [  240/  469]\n",
            "loss: 2631.17 = -logpx[134543.1], -det[-25908.2], -norms[-327922.4], reg[0.0429]; bits/pixel: 4.84  [  250/  469]\n",
            "loss: 2656.43 = -logpx[137081.2], -det[-24908.2], -norms[-328226.9], reg[0.0430]; bits/pixel: 4.89  [  260/  469]\n",
            "loss: 2623.43 = -logpx[134598.2], -det[-26568.8], -norms[-328307.3], reg[0.0430]; bits/pixel: 4.83  [  270/  469]\n",
            "loss: 2657.51 = -logpx[139794.6], -det[-27288.3], -norms[-328421.4], reg[0.0431]; bits/pixel: 4.89  [  280/  469]\n",
            "loss: 2679.44 = -logpx[139775.0], -det[-24380.4], -norms[-328503.1], reg[0.0432]; bits/pixel: 4.93  [  290/  469]\n",
            "loss: 2610.97 = -logpx[134971.8], -det[-28203.6], -norms[-328641.5], reg[0.0433]; bits/pixel: 4.80  [  300/  469]\n",
            "loss: 2670.52 = -logpx[141796.8], -det[-27379.8], -norms[-328667.2], reg[0.0434]; bits/pixel: 4.91  [  310/  469]\n",
            "loss: 2663.21 = -logpx[138989.5], -det[-25483.8], -norms[-328692.0], reg[0.0434]; bits/pixel: 4.90  [  320/  469]\n",
            "loss: 2653.33 = -logpx[137162.7], -det[-24805.2], -norms[-328808.7], reg[0.0435]; bits/pixel: 4.88  [  330/  469]\n",
            "loss: 2804.67 = -logpx[156870.0], -det[-25070.9], -norms[-328878.3], reg[0.0436]; bits/pixel: 5.16  [  340/  469]\n",
            "loss: 2689.32 = -logpx[145816.8], -det[-28635.4], -norms[-329025.6], reg[0.0436]; bits/pixel: 4.95  [  350/  469]\n",
            "loss: 2628.77 = -logpx[139719.9], -det[-30064.3], -norms[-329250.3], reg[0.0437]; bits/pixel: 4.84  [  360/  469]\n",
            "loss: 2680.96 = -logpx[144020.2], -det[-27337.6], -norms[-329596.7], reg[0.0438]; bits/pixel: 4.93  [  370/  469]\n",
            "loss: 2604.44 = -logpx[135584.3], -det[-28410.1], -norms[-329883.2], reg[0.0439]; bits/pixel: 4.79  [  380/  469]\n",
            "loss: 2642.94 = -logpx[139322.9], -det[-27032.4], -norms[-330071.1], reg[0.0439]; bits/pixel: 4.86  [  390/  469]\n",
            "loss: 2611.69 = -logpx[136196.7], -det[-27645.2], -norms[-330332.3], reg[0.0440]; bits/pixel: 4.81  [  400/  469]\n",
            "loss: 2653.60 = -logpx[140061.9], -det[-25953.8], -norms[-330524.2], reg[0.0441]; bits/pixel: 4.88  [  410/  469]\n",
            "loss: 2617.80 = -logpx[136571.0], -det[-27031.7], -norms[-330538.5], reg[0.0442]; bits/pixel: 4.82  [  420/  469]\n",
            "loss: 2588.01 = -logpx[133274.1], -det[-27375.0], -norms[-330710.7], reg[0.0443]; bits/pixel: 4.76  [  430/  469]\n",
            "loss: 2557.09 = -logpx[130861.9], -det[-28723.6], -norms[-330907.9], reg[0.0444]; bits/pixel: 4.71  [  440/  469]\n",
            "loss: 2947.08 = -logpx[177381.8], -det[-25338.6], -norms[-330894.0], reg[0.0444]; bits/pixel: 5.42  [  450/  469]\n",
            "loss: 2621.41 = -logpx[138018.7], -det[-27390.2], -norms[-331164.5], reg[0.0445]; bits/pixel: 4.82  [  460/  469]\n",
            "Test Error: \n",
            " Avg loss: 2652.29; 4.88 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 2588.05 = -logpx[135349.0], -det[-28704.7], -norms[-331451.0], reg[0.0446]; bits/pixel: 4.76  [    0/  469]\n",
            "loss: 2637.49 = -logpx[140224.3], -det[-26968.0], -norms[-331734.0], reg[0.0446]; bits/pixel: 4.85  [   10/  469]\n",
            "loss: 2597.30 = -logpx[136664.8], -det[-28340.9], -norms[-331946.6], reg[0.0447]; bits/pixel: 4.78  [   20/  469]\n",
            "loss: 2603.23 = -logpx[139531.9], -det[-30356.3], -norms[-332038.4], reg[0.0448]; bits/pixel: 4.79  [   30/  469]\n",
            "loss: 2564.53 = -logpx[134444.8], -det[-30105.9], -norms[-332155.6], reg[0.0449]; bits/pixel: 4.72  [   40/  469]\n",
            "loss: 2615.16 = -logpx[138950.6], -det[-27847.8], -norms[-332438.9], reg[0.0449]; bits/pixel: 4.81  [   50/  469]\n",
            "loss: 2670.91 = -logpx[142927.6], -det[-24810.8], -norms[-332316.7], reg[0.0450]; bits/pixel: 4.91  [   60/  469]\n",
            "loss: 2582.99 = -logpx[135794.0], -det[-28762.0], -norms[-332486.6], reg[0.0451]; bits/pixel: 4.75  [   70/  469]\n",
            "loss: 2547.65 = -logpx[133463.2], -det[-31024.2], -norms[-332417.2], reg[0.0452]; bits/pixel: 4.69  [   80/  469]\n",
            "loss: 2595.70 = -logpx[137164.6], -det[-28624.3], -norms[-332367.8], reg[0.0453]; bits/pixel: 4.78  [   90/  469]\n",
            "loss: 2661.43 = -logpx[146394.7], -det[-29367.1], -norms[-332441.4], reg[0.0453]; bits/pixel: 4.90  [  100/  469]\n",
            "loss: 2720.55 = -logpx[153060.9], -det[-28393.9], -norms[-332513.0], reg[0.0454]; bits/pixel: 5.01  [  110/  469]\n",
            "loss: 2553.34 = -logpx[131249.4], -det[-27803.5], -norms[-332694.8], reg[0.0455]; bits/pixel: 4.70  [  120/  469]\n",
            "loss: 2575.48 = -logpx[137942.3], -det[-31668.0], -norms[-332690.1], reg[0.0456]; bits/pixel: 4.74  [  130/  469]\n",
            "loss: 2749.40 = -logpx[157289.4], -det[-28801.2], -norms[-332641.8], reg[0.0457]; bits/pixel: 5.06  [  140/  469]\n",
            "loss: 2557.63 = -logpx[136087.8], -det[-31772.7], -norms[-333016.0], reg[0.0457]; bits/pixel: 4.71  [  150/  469]\n",
            "loss: 2559.47 = -logpx[136593.4], -det[-31831.2], -norms[-333227.1], reg[0.0458]; bits/pixel: 4.71  [  160/  469]\n",
            "loss: 2619.16 = -logpx[140201.8], -det[-28070.0], -norms[-332955.9], reg[0.0459]; bits/pixel: 4.82  [  170/  469]\n",
            "loss: 2661.66 = -logpx[146678.8], -det[-29307.6], -norms[-332755.6], reg[0.0460]; bits/pixel: 4.90  [  180/  469]\n",
            "loss: 2628.31 = -logpx[140622.0], -det[-27559.0], -norms[-332715.9], reg[0.0460]; bits/pixel: 4.84  [  190/  469]\n",
            "loss: 2541.97 = -logpx[131296.8], -det[-29173.8], -norms[-332827.9], reg[0.0461]; bits/pixel: 4.68  [  200/  469]\n",
            "loss: 2575.05 = -logpx[135338.5], -det[-28846.1], -norms[-332963.2], reg[0.0462]; bits/pixel: 4.74  [  210/  469]\n",
            "loss: 2589.13 = -logpx[135581.4], -det[-27352.4], -norms[-332897.3], reg[0.0463]; bits/pixel: 4.76  [  220/  469]\n",
            "loss: 2553.56 = -logpx[131479.6], -det[-27406.1], -norms[-333294.5], reg[0.0463]; bits/pixel: 4.70  [  230/  469]\n",
            "loss: 2648.00 = -logpx[145580.1], -det[-29417.4], -norms[-333295.1], reg[0.0464]; bits/pixel: 4.87  [  240/  469]\n",
            "loss: 2575.66 = -logpx[136247.8], -det[-29113.6], -norms[-333526.9], reg[0.0465]; bits/pixel: 4.74  [  250/  469]\n",
            "loss: 2583.70 = -logpx[136500.5], -det[-28237.2], -norms[-333626.3], reg[0.0465]; bits/pixel: 4.75  [  260/  469]\n",
            "loss: 2525.69 = -logpx[133580.3], -det[-32517.1], -norms[-333851.8], reg[0.0466]; bits/pixel: 4.65  [  270/  469]\n",
            "loss: 2608.31 = -logpx[142205.8], -det[-30257.7], -norms[-334161.8], reg[0.0467]; bits/pixel: 4.80  [  280/  469]\n",
            "loss: 2531.16 = -logpx[132521.7], -det[-30540.4], -norms[-334069.8], reg[0.0468]; bits/pixel: 4.66  [  290/  469]\n",
            "loss: 2599.35 = -logpx[139040.6], -det[-28549.6], -norms[-333850.9], reg[0.0469]; bits/pixel: 4.78  [  300/  469]\n",
            "loss: 2589.00 = -logpx[138922.7], -det[-29464.6], -norms[-334142.4], reg[0.0469]; bits/pixel: 4.76  [  310/  469]\n",
            "loss: 2575.94 = -logpx[138314.9], -det[-30470.4], -norms[-334201.2], reg[0.0470]; bits/pixel: 4.74  [  320/  469]\n",
            "loss: 2562.50 = -logpx[135561.5], -det[-29195.1], -norms[-334442.9], reg[0.0471]; bits/pixel: 4.72  [  330/  469]\n",
            "loss: 2542.71 = -logpx[133412.8], -det[-29285.1], -norms[-334737.6], reg[0.0472]; bits/pixel: 4.68  [  340/  469]\n",
            "loss: 2633.82 = -logpx[144598.2], -det[-28695.7], -norms[-334850.7], reg[0.0472]; bits/pixel: 4.85  [  350/  469]\n",
            "loss: 2538.55 = -logpx[134520.8], -det[-30679.2], -norms[-334984.5], reg[0.0473]; bits/pixel: 4.67  [  360/  469]\n",
            "loss: 2653.23 = -logpx[147850.1], -det[-29077.6], -norms[-335236.1], reg[0.0474]; bits/pixel: 4.88  [  370/  469]\n",
            "loss: 2550.90 = -logpx[135387.1], -det[-29583.5], -norms[-335365.4], reg[0.0475]; bits/pixel: 4.69  [  380/  469]\n",
            "loss: 2614.21 = -logpx[143607.7], -det[-29700.3], -norms[-335365.1], reg[0.0476]; bits/pixel: 4.81  [  390/  469]\n",
            "loss: 2554.36 = -logpx[136347.0], -det[-29908.3], -norms[-335558.2], reg[0.0477]; bits/pixel: 4.70  [  400/  469]\n",
            "loss: 2485.70 = -logpx[130050.3], -det[-32078.8], -norms[-335879.2], reg[0.0477]; bits/pixel: 4.57  [  410/  469]\n",
            "loss: 2510.01 = -logpx[133642.5], -det[-32540.0], -norms[-335898.7], reg[0.0478]; bits/pixel: 4.62  [  420/  469]\n",
            "loss: 2590.46 = -logpx[141464.7], -det[-30059.1], -norms[-335903.5], reg[0.0479]; bits/pixel: 4.77  [  430/  469]\n",
            "loss: 2541.84 = -logpx[134831.8], -det[-29369.5], -norms[-336183.1], reg[0.0480]; bits/pixel: 4.68  [  440/  469]\n",
            "loss: 2566.50 = -logpx[137157.8], -det[-28550.4], -norms[-336172.8], reg[0.0481]; bits/pixel: 4.72  [  450/  469]\n",
            "loss: 2530.83 = -logpx[135194.4], -det[-31057.4], -norms[-336268.2], reg[0.0481]; bits/pixel: 4.66  [  460/  469]\n",
            "Test Error: \n",
            " Avg loss: 2591.98; 4.77 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 2533.65 = -logpx[135615.1], -det[-31028.8], -norms[-336355.5], reg[0.0482]; bits/pixel: 4.66  [    0/  469]\n",
            "loss: 2561.74 = -logpx[139831.3], -det[-31351.1], -norms[-336654.7], reg[0.0483]; bits/pixel: 4.71  [   10/  469]\n",
            "loss: 2554.18 = -logpx[137143.8], -det[-29684.7], -norms[-336601.1], reg[0.0484]; bits/pixel: 4.70  [   20/  469]\n",
            "loss: 2523.38 = -logpx[134712.9], -det[-30941.3], -norms[-336856.5], reg[0.0484]; bits/pixel: 4.64  [   30/  469]\n",
            "loss: 2497.42 = -logpx[133281.7], -det[-32831.5], -norms[-336857.1], reg[0.0485]; bits/pixel: 4.60  [   40/  469]\n",
            "loss: 2542.79 = -logpx[135369.2], -det[-28867.9], -norms[-337100.8], reg[0.0486]; bits/pixel: 4.68  [   50/  469]\n",
            "loss: 2716.46 = -logpx[156584.6], -det[-28027.6], -norms[-336927.1], reg[0.0487]; bits/pixel: 5.00  [   60/  469]\n",
            "loss: 2535.68 = -logpx[136335.2], -det[-30696.1], -norms[-337149.4], reg[0.0488]; bits/pixel: 4.67  [   70/  469]\n",
            "loss: 2531.75 = -logpx[136228.9], -det[-30830.0], -norms[-337412.5], reg[0.0488]; bits/pixel: 4.66  [   80/  469]\n",
            "loss: 2531.66 = -logpx[137329.3], -det[-31797.6], -norms[-337555.6], reg[0.0489]; bits/pixel: 4.66  [   90/  469]\n",
            "loss: 2795.02 = -logpx[170500.9], -det[-31379.6], -norms[-337436.2], reg[0.0490]; bits/pixel: 5.14  [  100/  469]\n",
            "loss: 2549.70 = -logpx[139228.9], -det[-31180.4], -norms[-337763.6], reg[0.0491]; bits/pixel: 4.69  [  110/  469]\n",
            "loss: 2671.33 = -logpx[154887.6], -det[-31095.5], -norms[-337938.7], reg[0.0491]; bits/pixel: 4.92  [  120/  469]\n",
            "loss: 2521.06 = -logpx[136206.0], -det[-31458.1], -norms[-338128.6], reg[0.0492]; bits/pixel: 4.64  [  130/  469]\n",
            "loss: 2518.86 = -logpx[136827.1], -det[-32236.0], -norms[-338254.3], reg[0.0493]; bits/pixel: 4.64  [  140/  469]\n",
            "loss: 2529.77 = -logpx[139615.6], -det[-33391.2], -norms[-338491.3], reg[0.0494]; bits/pixel: 4.66  [  150/  469]\n",
            "loss: 2500.15 = -logpx[133628.0], -det[-31212.1], -norms[-338474.1], reg[0.0495]; bits/pixel: 4.60  [  160/  469]\n",
            "loss: 2526.71 = -logpx[136358.9], -det[-30474.0], -norms[-338542.7], reg[0.0496]; bits/pixel: 4.65  [  170/  469]\n",
            "loss: 2599.78 = -logpx[146710.0], -det[-31389.4], -norms[-338625.5], reg[0.0497]; bits/pixel: 4.78  [  180/  469]\n",
            "loss: 2530.30 = -logpx[139463.9], -det[-32695.9], -norms[-338966.2], reg[0.0497]; bits/pixel: 4.66  [  190/  469]\n",
            "loss: 2561.55 = -logpx[140621.5], -det[-29706.5], -norms[-339113.2], reg[0.0498]; bits/pixel: 4.71  [  200/  469]\n",
            "loss: 2523.08 = -logpx[136626.3], -det[-30648.0], -norms[-339100.6], reg[0.0499]; bits/pixel: 4.64  [  210/  469]\n",
            "loss: 2502.02 = -logpx[135120.8], -det[-31728.5], -norms[-339211.0], reg[0.0500]; bits/pixel: 4.60  [  220/  469]\n",
            "loss: 2806.60 = -logpx[173728.6], -det[-31631.8], -norms[-338929.0], reg[0.0500]; bits/pixel: 5.16  [  230/  469]\n",
            "loss: 2528.80 = -logpx[138584.7], -det[-31864.0], -norms[-339110.7], reg[0.0501]; bits/pixel: 4.65  [  240/  469]\n",
            "loss: 2544.85 = -logpx[137689.1], -det[-28821.9], -norms[-339203.1], reg[0.0502]; bits/pixel: 4.68  [  250/  469]\n",
            "loss: 2534.52 = -logpx[137300.0], -det[-29499.4], -norms[-339459.1], reg[0.0503]; bits/pixel: 4.66  [  260/  469]\n",
            "loss: 2530.62 = -logpx[137787.5], -det[-30441.8], -norms[-339503.6], reg[0.0503]; bits/pixel: 4.66  [  270/  469]\n",
            "loss: 2524.31 = -logpx[137800.8], -det[-30847.5], -norms[-339918.4], reg[0.0504]; bits/pixel: 4.65  [  280/  469]\n",
            "loss: 2463.11 = -logpx[131539.5], -det[-32360.9], -norms[-339977.9], reg[0.0505]; bits/pixel: 4.53  [  290/  469]\n",
            "loss: 2525.89 = -logpx[140011.3], -det[-32726.8], -norms[-340047.6], reg[0.0506]; bits/pixel: 4.65  [  300/  469]\n",
            "loss: 2519.69 = -logpx[136571.2], -det[-30157.7], -norms[-339970.6], reg[0.0507]; bits/pixel: 4.64  [  310/  469]\n",
            "loss: 2685.23 = -logpx[158223.5], -det[-30554.6], -norms[-340036.4], reg[0.0507]; bits/pixel: 4.94  [  320/  469]\n",
            "loss: 2506.77 = -logpx[136454.4], -det[-31354.6], -norms[-340309.6], reg[0.0508]; bits/pixel: 4.61  [  330/  469]\n",
            "loss: 2549.32 = -logpx[141667.6], -det[-31358.7], -norms[-340072.2], reg[0.0509]; bits/pixel: 4.69  [  340/  469]\n",
            "loss: 2613.95 = -logpx[149102.1], -det[-30432.3], -norms[-340161.6], reg[0.0509]; bits/pixel: 4.81  [  350/  469]\n",
            "loss: 2533.47 = -logpx[139745.1], -det[-31240.3], -norms[-340298.1], reg[0.0510]; bits/pixel: 4.66  [  360/  469]\n",
            "loss: 2523.40 = -logpx[137257.9], -det[-29837.0], -norms[-340502.2], reg[0.0511]; bits/pixel: 4.64  [  370/  469]\n",
            "loss: 2513.42 = -logpx[140535.3], -det[-34394.7], -norms[-340500.0], reg[0.0512]; bits/pixel: 4.63  [  380/  469]\n",
            "loss: 2581.75 = -logpx[145831.2], -det[-30657.5], -norms[-340786.2], reg[0.0512]; bits/pixel: 4.75  [  390/  469]\n",
            "loss: 2468.90 = -logpx[134745.4], -det[-34021.7], -norms[-340781.6], reg[0.0513]; bits/pixel: 4.54  [  400/  469]\n",
            "loss: 2501.86 = -logpx[135467.4], -det[-30818.3], -norms[-340488.4], reg[0.0514]; bits/pixel: 4.60  [  410/  469]\n",
            "loss: 2649.51 = -logpx[156419.2], -det[-32703.1], -norms[-340656.3], reg[0.0515]; bits/pixel: 4.88  [  420/  469]\n",
            "loss: 2494.82 = -logpx[136944.0], -det[-33077.1], -norms[-340607.1], reg[0.0516]; bits/pixel: 4.59  [  430/  469]\n",
            "loss: 2541.09 = -logpx[143938.7], -det[-34017.0], -norms[-340739.8], reg[0.0516]; bits/pixel: 4.68  [  440/  469]\n",
            "loss: 2530.85 = -logpx[138754.6], -det[-30019.1], -norms[-340864.2], reg[0.0517]; bits/pixel: 4.66  [  450/  469]\n",
            "loss: 2538.58 = -logpx[141467.4], -det[-31622.6], -norms[-340983.2], reg[0.0518]; bits/pixel: 4.67  [  460/  469]\n",
            "Test Error: \n",
            " Avg loss: 2546.39; 4.69 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 2534.07 = -logpx[141141.4], -det[-31768.7], -norms[-341089.3], reg[0.0519]; bits/pixel: 4.66  [    0/  469]\n",
            "loss: 2504.49 = -logpx[137919.3], -det[-32049.4], -norms[-341371.9], reg[0.0519]; bits/pixel: 4.61  [   10/  469]\n",
            "loss: 2455.69 = -logpx[133422.7], -det[-33562.9], -norms[-341607.9], reg[0.0520]; bits/pixel: 4.52  [   20/  469]\n",
            "loss: 2431.60 = -logpx[131699.6], -det[-34630.8], -norms[-341901.2], reg[0.0521]; bits/pixel: 4.47  [   30/  469]\n",
            "loss: 2580.91 = -logpx[146582.4], -det[-30538.0], -norms[-341764.3], reg[0.0522]; bits/pixel: 4.75  [   40/  469]\n",
            "loss: 2589.78 = -logpx[147922.3], -det[-30697.1], -norms[-341810.2], reg[0.0522]; bits/pixel: 4.77  [   50/  469]\n",
            "loss: 2506.59 = -logpx[140349.0], -det[-33669.5], -norms[-341912.6], reg[0.0523]; bits/pixel: 4.61  [   60/  469]\n",
            "loss: 2519.20 = -logpx[141870.7], -det[-33425.9], -norms[-342064.1], reg[0.0524]; bits/pixel: 4.64  [   70/  469]\n",
            "loss: 2447.00 = -logpx[134254.9], -det[-35095.0], -norms[-342021.3], reg[0.0525]; bits/pixel: 4.50  [   80/  469]\n",
            "loss: 2771.76 = -logpx[171522.7], -det[-30957.1], -norms[-341857.3], reg[0.0526]; bits/pixel: 5.10  [   90/  469]\n",
            "loss: 2543.31 = -logpx[144081.7], -det[-32769.7], -norms[-341844.7], reg[0.0527]; bits/pixel: 4.68  [  100/  469]\n",
            "loss: 2485.26 = -logpx[136175.1], -det[-32086.9], -norms[-342051.3], reg[0.0527]; bits/pixel: 4.57  [  110/  469]\n",
            "loss: 2489.28 = -logpx[137629.1], -det[-32851.6], -norms[-342226.2], reg[0.0528]; bits/pixel: 4.58  [  120/  469]\n",
            "loss: 2451.27 = -logpx[133296.8], -det[-33068.2], -norms[-342543.1], reg[0.0529]; bits/pixel: 4.51  [  130/  469]\n",
            "loss: 2493.66 = -logpx[137161.1], -det[-31367.4], -norms[-342682.1], reg[0.0530]; bits/pixel: 4.59  [  140/  469]\n",
            "loss: 2435.63 = -logpx[133745.5], -det[-35058.6], -norms[-343002.7], reg[0.0531]; bits/pixel: 4.48  [  150/  469]\n",
            "loss: 2443.38 = -logpx[135750.2], -det[-36287.2], -norms[-342787.6], reg[0.0532]; bits/pixel: 4.50  [  160/  469]\n",
            "loss: 2510.19 = -logpx[139823.0], -det[-31512.8], -norms[-343083.0], reg[0.0533]; bits/pixel: 4.62  [  170/  469]\n",
            "loss: 2454.45 = -logpx[136608.6], -det[-35350.4], -norms[-343165.9], reg[0.0534]; bits/pixel: 4.52  [  180/  469]\n",
            "loss: 2430.18 = -logpx[132806.2], -det[-34492.9], -norms[-343327.7], reg[0.0534]; bits/pixel: 4.47  [  190/  469]\n",
            "loss: 2593.15 = -logpx[153143.6], -det[-33868.5], -norms[-343428.9], reg[0.0535]; bits/pixel: 4.77  [  200/  469]\n",
            "loss: 2493.11 = -logpx[137773.6], -det[-31453.8], -norms[-343278.4], reg[0.0536]; bits/pixel: 4.59  [  210/  469]\n",
            "loss: 2497.53 = -logpx[144320.3], -det[-37110.0], -norms[-343602.9], reg[0.0537]; bits/pixel: 4.60  [  220/  469]\n",
            "loss: 2445.24 = -logpx[134681.7], -det[-34318.5], -norms[-343449.9], reg[0.0537]; bits/pixel: 4.50  [  230/  469]\n",
            "loss: 2500.14 = -logpx[137488.7], -det[-30029.0], -norms[-343518.4], reg[0.0538]; bits/pixel: 4.60  [  240/  469]\n",
            "loss: 2434.52 = -logpx[134954.9], -det[-35725.2], -norms[-343687.7], reg[0.0539]; bits/pixel: 4.48  [  250/  469]\n",
            "loss: 2436.71 = -logpx[136457.0], -det[-36823.7], -norms[-343810.9], reg[0.0540]; bits/pixel: 4.48  [  260/  469]\n",
            "loss: 2453.79 = -logpx[137504.0], -det[-35558.9], -norms[-343936.4], reg[0.0541]; bits/pixel: 4.52  [  270/  469]\n",
            "loss: 2439.64 = -logpx[135117.0], -det[-34694.6], -norms[-344225.7], reg[0.0541]; bits/pixel: 4.49  [  280/  469]\n",
            "loss: 2434.63 = -logpx[134974.0], -det[-35114.2], -norms[-344304.2], reg[0.0542]; bits/pixel: 4.48  [  290/  469]\n",
            "loss: 2439.92 = -logpx[137680.9], -det[-37204.3], -norms[-344243.9], reg[0.0543]; bits/pixel: 4.49  [  300/  469]\n",
            "loss: 2454.90 = -logpx[139008.1], -det[-36422.9], -norms[-344434.7], reg[0.0544]; bits/pixel: 4.52  [  310/  469]\n",
            "loss: 2438.05 = -logpx[135255.1], -det[-34858.8], -norms[-344402.4], reg[0.0544]; bits/pixel: 4.49  [  320/  469]\n",
            "loss: 2453.16 = -logpx[138376.2], -det[-35994.6], -norms[-344454.0], reg[0.0545]; bits/pixel: 4.51  [  330/  469]\n",
            "loss: 2469.04 = -logpx[136160.4], -det[-31523.6], -norms[-344676.5], reg[0.0546]; bits/pixel: 4.54  [  340/  469]\n",
            "loss: 2443.50 = -logpx[135337.5], -det[-33948.7], -norms[-344697.9], reg[0.0546]; bits/pixel: 4.50  [  350/  469]\n",
            "loss: 2465.08 = -logpx[140301.8], -det[-35927.0], -norms[-344922.0], reg[0.0547]; bits/pixel: 4.54  [  360/  469]\n",
            "loss: 2454.79 = -logpx[137748.8], -det[-34848.3], -norms[-344763.9], reg[0.0548]; bits/pixel: 4.52  [  370/  469]\n",
            "loss: 2452.62 = -logpx[134866.7], -det[-32149.5], -norms[-344858.8], reg[0.0549]; bits/pixel: 4.51  [  380/  469]\n",
            "loss: 2425.55 = -logpx[133336.0], -det[-34049.1], -norms[-344893.8], reg[0.0550]; bits/pixel: 4.46  [  390/  469]\n",
            "loss: 2491.77 = -logpx[139482.5], -det[-31581.8], -norms[-345031.6], reg[0.0551]; bits/pixel: 4.59  [  400/  469]\n",
            "loss: 2458.97 = -logpx[141201.5], -det[-37146.2], -norms[-345384.2], reg[0.0551]; bits/pixel: 4.52  [  410/  469]\n",
            "loss: 2500.16 = -logpx[144981.9], -det[-35384.2], -norms[-345654.0], reg[0.0552]; bits/pixel: 4.60  [  420/  469]\n",
            "loss: 2588.44 = -logpx[157870.1], -det[-36754.1], -norms[-345873.1], reg[0.0553]; bits/pixel: 4.76  [  430/  469]\n",
            "loss: 2488.96 = -logpx[143163.8], -det[-34492.0], -norms[-346161.8], reg[0.0554]; bits/pixel: 4.58  [  440/  469]\n",
            "loss: 2468.63 = -logpx[139630.6], -det[-33535.4], -norms[-346187.6], reg[0.0555]; bits/pixel: 4.54  [  450/  469]\n",
            "loss: 2450.72 = -logpx[138486.3], -det[-34616.3], -norms[-346254.4], reg[0.0556]; bits/pixel: 4.51  [  460/  469]\n",
            "Test Error: \n",
            " Avg loss: 2495.29; 4.59 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 2559.35 = -logpx[153160.0], -det[-35475.9], -norms[-346164.4], reg[0.0556]; bits/pixel: 4.71  [    0/  469]\n",
            "loss: 2436.17 = -logpx[136771.6], -det[-34866.6], -norms[-346151.6], reg[0.0557]; bits/pixel: 4.48  [   10/  469]\n",
            "loss: 2401.57 = -logpx[133396.5], -det[-35682.5], -norms[-346389.6], reg[0.0558]; bits/pixel: 4.42  [   20/  469]\n",
            "loss: 2421.02 = -logpx[138460.2], -det[-37940.8], -norms[-346705.3], reg[0.0559]; bits/pixel: 4.46  [   30/  469]\n",
            "loss: 2671.53 = -logpx[169504.4], -det[-36791.4], -norms[-346834.0], reg[0.0560]; bits/pixel: 4.92  [   40/  469]\n",
            "loss: 2442.40 = -logpx[139549.5], -det[-36110.9], -norms[-346888.5], reg[0.0561]; bits/pixel: 4.49  [   50/  469]\n",
            "loss: 2544.58 = -logpx[149460.7], -det[-32880.3], -norms[-346950.6], reg[0.0562]; bits/pixel: 4.68  [   60/  469]\n",
            "loss: 2461.82 = -logpx[141948.0], -det[-36101.1], -norms[-346811.1], reg[0.0563]; bits/pixel: 4.53  [   70/  469]\n",
            "loss: 2416.18 = -logpx[135150.1], -det[-35105.3], -norms[-346851.2], reg[0.0563]; bits/pixel: 4.45  [   80/  469]\n",
            "loss: 2516.41 = -logpx[149654.3], -det[-36385.2], -norms[-347245.4], reg[0.0564]; bits/pixel: 4.63  [   90/  469]\n",
            "loss: 2527.09 = -logpx[149997.6], -det[-35420.9], -norms[-347185.8], reg[0.0565]; bits/pixel: 4.65  [  100/  469]\n",
            "loss: 2453.55 = -logpx[142072.8], -det[-36873.4], -norms[-347222.1], reg[0.0566]; bits/pixel: 4.51  [  110/  469]\n",
            "loss: 2511.00 = -logpx[147089.1], -det[-34415.0], -norms[-347343.7], reg[0.0567]; bits/pixel: 4.62  [  120/  469]\n",
            "loss: 2416.22 = -logpx[137221.7], -det[-36391.0], -norms[-347631.2], reg[0.0568]; bits/pixel: 4.45  [  130/  469]\n",
            "loss: 2475.88 = -logpx[142821.8], -det[-34390.0], -norms[-347595.6], reg[0.0569]; bits/pixel: 4.56  [  140/  469]\n",
            "loss: 2413.93 = -logpx[138180.6], -det[-37549.4], -norms[-347725.2], reg[0.0570]; bits/pixel: 4.44  [  150/  469]\n",
            "loss: 2399.19 = -logpx[135647.6], -det[-36609.1], -norms[-348019.4], reg[0.0571]; bits/pixel: 4.41  [  160/  469]\n",
            "loss: 2594.56 = -logpx[163031.0], -det[-38725.1], -norms[-348279.2], reg[0.0571]; bits/pixel: 4.77  [  170/  469]\n",
            "loss: 2455.06 = -logpx[142949.9], -det[-36274.3], -norms[-348505.4], reg[0.0572]; bits/pixel: 4.52  [  180/  469]\n",
            "loss: 2412.72 = -logpx[138064.4], -det[-36536.0], -norms[-348777.6], reg[0.0573]; bits/pixel: 4.44  [  190/  469]\n",
            "loss: 2405.59 = -logpx[137147.4], -det[-36551.9], -norms[-348756.9], reg[0.0574]; bits/pixel: 4.43  [  200/  469]\n",
            "loss: 2390.86 = -logpx[135506.9], -det[-36707.4], -norms[-348846.3], reg[0.0575]; bits/pixel: 4.40  [  210/  469]\n",
            "loss: 2403.36 = -logpx[136202.5], -det[-35814.5], -norms[-348834.8], reg[0.0576]; bits/pixel: 4.42  [  220/  469]\n",
            "loss: 2396.57 = -logpx[137746.9], -det[-38195.4], -norms[-348867.1], reg[0.0576]; bits/pixel: 4.41  [  230/  469]\n",
            "loss: 2421.54 = -logpx[140638.9], -det[-38049.4], -norms[-348709.7], reg[0.0577]; bits/pixel: 4.46  [  240/  469]\n",
            "loss: 2388.08 = -logpx[134073.9], -det[-35595.1], -norms[-348881.3], reg[0.0578]; bits/pixel: 4.39  [  250/  469]\n",
            "loss: 2388.36 = -logpx[135853.8], -det[-37290.0], -norms[-348930.4], reg[0.0579]; bits/pixel: 4.39  [  260/  469]\n",
            "loss: 2469.10 = -logpx[146138.9], -det[-37128.4], -norms[-349043.1], reg[0.0580]; bits/pixel: 4.54  [  270/  469]\n",
            "loss: 2396.65 = -logpx[136780.0], -det[-36730.0], -norms[-349356.4], reg[0.0581]; bits/pixel: 4.41  [  280/  469]\n",
            "loss: 2403.78 = -logpx[139904.2], -det[-39008.3], -norms[-349289.4], reg[0.0581]; bits/pixel: 4.42  [  290/  469]\n",
            "loss: 2435.19 = -logpx[139046.9], -det[-33901.1], -norms[-349517.8], reg[0.0582]; bits/pixel: 4.48  [  300/  469]\n",
            "loss: 2446.82 = -logpx[144962.2], -det[-38257.1], -norms[-349589.4], reg[0.0583]; bits/pixel: 4.50  [  310/  469]\n",
            "loss: 2324.09 = -logpx[130398.9], -det[-39273.4], -norms[-349718.8], reg[0.0584]; bits/pixel: 4.28  [  320/  469]\n",
            "loss: 2494.30 = -logpx[148522.5], -det[-35595.8], -norms[-349733.6], reg[0.0584]; bits/pixel: 4.59  [  330/  469]\n",
            "loss: 2474.39 = -logpx[144249.7], -det[-33891.7], -norms[-349713.1], reg[0.0585]; bits/pixel: 4.55  [  340/  469]\n",
            "loss: 2533.03 = -logpx[148786.3], -det[-31125.5], -norms[-349510.1], reg[0.0586]; bits/pixel: 4.66  [  350/  469]\n",
            "loss: 2452.88 = -logpx[142347.9], -det[-34769.9], -norms[-349686.0], reg[0.0587]; bits/pixel: 4.51  [  360/  469]\n",
            "loss: 2334.66 = -logpx[129720.4], -det[-37172.7], -norms[-349788.0], reg[0.0587]; bits/pixel: 4.30  [  370/  469]\n",
            "loss: 2544.76 = -logpx[156285.2], -det[-37047.9], -norms[-349584.9], reg[0.0588]; bits/pixel: 4.68  [  380/  469]\n",
            "loss: 2392.32 = -logpx[135935.2], -det[-35945.2], -norms[-349850.1], reg[0.0589]; bits/pixel: 4.40  [  390/  469]\n",
            "loss: 2418.45 = -logpx[141727.5], -det[-38250.5], -norms[-349992.9], reg[0.0590]; bits/pixel: 4.45  [  400/  469]\n",
            "loss: 2448.32 = -logpx[142190.5], -det[-34802.9], -norms[-350079.5], reg[0.0591]; bits/pixel: 4.51  [  410/  469]\n",
            "loss: 2471.79 = -logpx[145004.8], -det[-34418.6], -norms[-350274.6], reg[0.0592]; bits/pixel: 4.55  [  420/  469]\n",
            "loss: 2359.30 = -logpx[134425.4], -det[-38250.4], -norms[-350261.6], reg[0.0593]; bits/pixel: 4.34  [  430/  469]\n",
            "loss: 2410.18 = -logpx[138698.8], -det[-36053.1], -norms[-350219.4], reg[0.0593]; bits/pixel: 4.44  [  440/  469]\n",
            "loss: 2493.21 = -logpx[146290.5], -det[-33342.9], -norms[-349893.7], reg[0.0594]; bits/pixel: 4.59  [  450/  469]\n",
            "loss: 2404.83 = -logpx[138824.1], -det[-37192.2], -norms[-349891.1], reg[0.0595]; bits/pixel: 4.43  [  460/  469]\n",
            "Test Error: \n",
            " Avg loss: 2460.71; 4.53 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 2402.78 = -logpx[133468.5], -det[-31837.3], -norms[-350151.9], reg[0.0596]; bits/pixel: 4.42  [    0/  469]\n",
            "loss: 2384.61 = -logpx[136077.4], -det[-36624.3], -norms[-350300.2], reg[0.0597]; bits/pixel: 4.39  [   10/  469]\n",
            "loss: 2377.71 = -logpx[134519.9], -det[-35614.1], -norms[-350636.2], reg[0.0597]; bits/pixel: 4.38  [   20/  469]\n",
            "loss: 2367.81 = -logpx[132846.8], -det[-34963.5], -norms[-350881.1], reg[0.0598]; bits/pixel: 4.36  [   30/  469]\n",
            "loss: 2378.67 = -logpx[136391.8], -det[-36828.9], -norms[-351170.7], reg[0.0599]; bits/pixel: 4.38  [   40/  469]\n",
            "loss: 2392.70 = -logpx[138154.7], -det[-36588.9], -norms[-351377.6], reg[0.0600]; bits/pixel: 4.40  [   50/  469]\n",
            "loss: 2376.23 = -logpx[137396.2], -det[-38070.8], -norms[-351244.4], reg[0.0601]; bits/pixel: 4.37  [   60/  469]\n",
            "loss: 2515.63 = -logpx[154339.6], -det[-37217.5], -norms[-351198.4], reg[0.0602]; bits/pixel: 4.63  [   70/  469]\n",
            "loss: 2357.83 = -logpx[135676.1], -det[-38645.3], -norms[-351305.4], reg[0.0603]; bits/pixel: 4.34  [   80/  469]\n",
            "loss: 2410.31 = -logpx[140442.4], -det[-36731.4], -norms[-351268.1], reg[0.0603]; bits/pixel: 4.44  [   90/  469]\n",
            "loss: 2440.36 = -logpx[145732.8], -det[-38357.3], -norms[-351087.1], reg[0.0604]; bits/pixel: 4.49  [  100/  469]\n",
            "loss: 2350.05 = -logpx[135717.8], -det[-39569.7], -norms[-351418.2], reg[0.0604]; bits/pixel: 4.32  [  110/  469]\n",
            "loss: 2452.63 = -logpx[147388.3], -det[-38049.8], -norms[-351479.4], reg[0.0605]; bits/pixel: 4.51  [  120/  469]\n",
            "loss: 2376.63 = -logpx[136688.8], -det[-37317.3], -norms[-351239.7], reg[0.0606]; bits/pixel: 4.37  [  130/  469]\n",
            "loss: 2387.35 = -logpx[140581.9], -det[-39640.5], -norms[-351437.6], reg[0.0606]; bits/pixel: 4.39  [  140/  469]\n",
            "loss: 2363.36 = -logpx[135074.6], -det[-37172.1], -norms[-351469.3], reg[0.0607]; bits/pixel: 4.35  [  150/  469]\n",
            "loss: 2336.69 = -logpx[136546.8], -det[-41985.2], -norms[-351542.4], reg[0.0608]; bits/pixel: 4.30  [  160/  469]\n",
            "loss: 2402.69 = -logpx[139090.1], -det[-35981.9], -norms[-351640.5], reg[0.0609]; bits/pixel: 4.42  [  170/  469]\n",
            "loss: 2352.36 = -logpx[136243.3], -det[-39223.0], -norms[-351994.8], reg[0.0609]; bits/pixel: 4.33  [  180/  469]\n",
            "loss: 2417.88 = -logpx[140290.4], -det[-34651.8], -norms[-352227.0], reg[0.0610]; bits/pixel: 4.45  [  190/  469]\n",
            "loss: 2434.11 = -logpx[144857.5], -det[-36960.1], -norms[-352408.2], reg[0.0611]; bits/pixel: 4.48  [  200/  469]\n",
            "loss: 2670.49 = -logpx[176864.4], -det[-38889.1], -norms[-352229.8], reg[0.0612]; bits/pixel: 4.91  [  210/  469]\n",
            "loss: 2450.23 = -logpx[145968.2], -det[-36058.2], -norms[-352357.5], reg[0.0612]; bits/pixel: 4.51  [  220/  469]\n",
            "loss: 2361.34 = -logpx[136230.0], -det[-37768.6], -norms[-352286.7], reg[0.0613]; bits/pixel: 4.35  [  230/  469]\n",
            "loss: 2385.99 = -logpx[136901.4], -det[-35523.6], -norms[-352048.0], reg[0.0614]; bits/pixel: 4.39  [  240/  469]\n",
            "loss: 2343.07 = -logpx[135318.8], -det[-39259.6], -norms[-352223.7], reg[0.0615]; bits/pixel: 4.31  [  250/  469]\n",
            "loss: 2359.95 = -logpx[135737.0], -det[-37320.0], -norms[-352420.2], reg[0.0615]; bits/pixel: 4.34  [  260/  469]\n",
            "loss: 2426.37 = -logpx[143023.1], -det[-36131.6], -norms[-352392.6], reg[0.0616]; bits/pixel: 4.46  [  270/  469]\n",
            "loss: 2359.39 = -logpx[136595.6], -det[-38207.5], -norms[-352463.1], reg[0.0617]; bits/pixel: 4.34  [  280/  469]\n",
            "loss: 2383.92 = -logpx[139274.8], -det[-37824.6], -norms[-352385.6], reg[0.0618]; bits/pixel: 4.39  [  290/  469]\n",
            "loss: 2453.69 = -logpx[149499.1], -det[-38910.0], -norms[-352593.2], reg[0.0619]; bits/pixel: 4.52  [  300/  469]\n",
            "loss: 2429.89 = -logpx[140444.5], -det[-32892.4], -norms[-352603.6], reg[0.0620]; bits/pixel: 4.47  [  310/  469]\n",
            "loss: 2281.26 = -logpx[131622.0], -det[-42677.1], -norms[-353020.5], reg[0.0621]; bits/pixel: 4.20  [  320/  469]\n",
            "loss: 2406.55 = -logpx[143999.4], -det[-39009.6], -norms[-353028.0], reg[0.0621]; bits/pixel: 4.43  [  330/  469]\n",
            "loss: 2588.85 = -logpx[168254.8], -det[-39896.3], -norms[-353062.5], reg[0.0622]; bits/pixel: 4.76  [  340/  469]\n",
            "loss: 2357.22 = -logpx[139155.4], -det[-40196.0], -norms[-353312.1], reg[0.0623]; bits/pixel: 4.34  [  350/  469]\n",
            "loss: 2365.74 = -logpx[139604.5], -det[-39555.3], -norms[-353311.3], reg[0.0624]; bits/pixel: 4.35  [  360/  469]\n",
            "loss: 2352.27 = -logpx[136726.2], -det[-38191.9], -norms[-353520.7], reg[0.0625]; bits/pixel: 4.33  [  370/  469]\n",
            "loss: 2458.29 = -logpx[152468.9], -det[-40260.3], -norms[-353624.5], reg[0.0625]; bits/pixel: 4.52  [  380/  469]\n",
            "loss: 2353.92 = -logpx[136256.2], -det[-37275.5], -norms[-353756.4], reg[0.0626]; bits/pixel: 4.33  [  390/  469]\n",
            "loss: 2457.29 = -logpx[149711.7], -det[-37535.3], -norms[-353720.4], reg[0.0627]; bits/pixel: 4.52  [  400/  469]\n",
            "loss: 2366.10 = -logpx[140378.4], -det[-39573.3], -norms[-354021.5], reg[0.0627]; bits/pixel: 4.35  [  410/  469]\n",
            "loss: 2341.83 = -logpx[140858.1], -det[-42920.0], -norms[-354261.1], reg[0.0628]; bits/pixel: 4.31  [  420/  469]\n",
            "loss: 2362.17 = -logpx[138780.4], -det[-38062.2], -norms[-354438.1], reg[0.0629]; bits/pixel: 4.35  [  430/  469]\n",
            "loss: 2314.77 = -logpx[136328.9], -det[-41534.1], -norms[-354580.8], reg[0.0630]; bits/pixel: 4.26  [  440/  469]\n",
            "loss: 2382.62 = -logpx[140874.6], -det[-37137.8], -norms[-354838.0], reg[0.0631]; bits/pixel: 4.38  [  450/  469]\n",
            "loss: 2403.14 = -logpx[143617.7], -det[-37542.6], -norms[-354549.6], reg[0.0632]; bits/pixel: 4.42  [  460/  469]\n",
            "Test Error: \n",
            " Avg loss: 2428.03; 4.47 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 2334.59 = -logpx[136074.9], -det[-38742.2], -norms[-354581.9], reg[0.0633]; bits/pixel: 4.30  [    0/  469]\n",
            "loss: 2373.61 = -logpx[143205.0], -det[-40634.7], -norms[-354824.7], reg[0.0634]; bits/pixel: 4.37  [   10/  469]\n",
            "loss: 2345.18 = -logpx[137438.0], -det[-38681.6], -norms[-354650.6], reg[0.0635]; bits/pixel: 4.32  [   20/  469]\n",
            "loss: 2387.90 = -logpx[143287.1], -det[-39015.0], -norms[-354697.8], reg[0.0635]; bits/pixel: 4.39  [   30/  469]\n",
            "loss: 2357.16 = -logpx[139480.8], -det[-38876.2], -norms[-354964.5], reg[0.0636]; bits/pixel: 4.34  [   40/  469]\n",
            "loss: 2276.70 = -logpx[133254.6], -det[-42589.9], -norms[-355323.7], reg[0.0637]; bits/pixel: 4.19  [   50/  469]\n",
            "loss: 2323.65 = -logpx[136590.2], -det[-39819.9], -norms[-355420.3], reg[0.0638]; bits/pixel: 4.28  [   60/  469]\n",
            "loss: 2599.09 = -logpx[166726.1], -det[-34885.5], -norms[-355234.2], reg[0.0639]; bits/pixel: 4.78  [   70/  469]\n",
            "loss: 2368.85 = -logpx[140781.3], -det[-38733.5], -norms[-354912.6], reg[0.0640]; bits/pixel: 4.36  [   80/  469]\n",
            "loss: 2488.98 = -logpx[153669.5], -det[-36396.0], -norms[-354760.4], reg[0.0641]; bits/pixel: 4.58  [   90/  469]\n",
            "loss: 2346.93 = -logpx[139102.4], -det[-39846.2], -norms[-354926.4], reg[0.0642]; bits/pixel: 4.32  [  100/  469]\n",
            "loss: 2328.22 = -logpx[135612.7], -det[-38530.4], -norms[-355147.1], reg[0.0643]; bits/pixel: 4.28  [  110/  469]\n",
            "loss: 2463.03 = -logpx[153324.5], -det[-38831.8], -norms[-355302.1], reg[0.0644]; bits/pixel: 4.53  [  120/  469]\n",
            "loss: 2292.94 = -logpx[134885.6], -det[-42026.9], -norms[-355439.6], reg[0.0644]; bits/pixel: 4.22  [  130/  469]\n",
            "loss: 2353.69 = -logpx[140333.0], -det[-39486.7], -norms[-355651.0], reg[0.0645]; bits/pixel: 4.33  [  140/  469]\n",
            "loss: 2326.47 = -logpx[134999.5], -det[-37671.9], -norms[-355616.9], reg[0.0646]; bits/pixel: 4.28  [  150/  469]\n",
            "loss: 2400.40 = -logpx[142379.9], -det[-35594.3], -norms[-355611.1], reg[0.0647]; bits/pixel: 4.42  [  160/  469]\n",
            "loss: 2299.26 = -logpx[134875.7], -det[-40982.3], -norms[-355665.1], reg[0.0648]; bits/pixel: 4.23  [  170/  469]\n",
            "loss: 2393.81 = -logpx[145626.1], -det[-39463.3], -norms[-355831.4], reg[0.0649]; bits/pixel: 4.41  [  180/  469]\n",
            "loss: 2333.76 = -logpx[136494.9], -det[-38031.6], -norms[-355819.6], reg[0.0649]; bits/pixel: 4.29  [  190/  469]\n",
            "loss: 2348.85 = -logpx[138525.5], -det[-38019.0], -norms[-355931.1], reg[0.0650]; bits/pixel: 4.32  [  200/  469]\n",
            "loss: 2357.44 = -logpx[139046.7], -det[-37442.4], -norms[-355929.2], reg[0.0651]; bits/pixel: 4.34  [  210/  469]\n",
            "loss: 2319.67 = -logpx[134108.6], -det[-37329.5], -norms[-355938.0], reg[0.0652]; bits/pixel: 4.27  [  220/  469]\n",
            "loss: 2365.37 = -logpx[140754.1], -det[-38015.3], -norms[-356047.8], reg[0.0652]; bits/pixel: 4.35  [  230/  469]\n",
            "loss: 2320.97 = -logpx[135953.3], -det[-38534.6], -norms[-356411.0], reg[0.0653]; bits/pixel: 4.27  [  240/  469]\n",
            "loss: 2318.29 = -logpx[135766.3], -det[-38790.1], -norms[-356311.5], reg[0.0654]; bits/pixel: 4.27  [  250/  469]\n",
            "loss: 2314.25 = -logpx[135533.6], -det[-38990.9], -norms[-356396.0], reg[0.0655]; bits/pixel: 4.26  [  260/  469]\n",
            "loss: 2400.71 = -logpx[147585.1], -det[-39934.6], -norms[-356437.1], reg[0.0656]; bits/pixel: 4.42  [  270/  469]\n",
            "loss: 2362.92 = -logpx[140892.2], -det[-37973.3], -norms[-356541.8], reg[0.0656]; bits/pixel: 4.35  [  280/  469]\n",
            "loss: 2320.59 = -logpx[135881.9], -det[-37990.6], -norms[-356932.8], reg[0.0657]; bits/pixel: 4.27  [  290/  469]\n",
            "loss: 2352.67 = -logpx[143303.1], -det[-41145.2], -norms[-357093.5], reg[0.0657]; bits/pixel: 4.33  [  300/  469]\n",
            "loss: 2358.95 = -logpx[145532.6], -det[-42844.2], -norms[-356820.3], reg[0.0658]; bits/pixel: 4.34  [  310/  469]\n",
            "loss: 2337.77 = -logpx[139823.7], -det[-39861.2], -norms[-356805.0], reg[0.0659]; bits/pixel: 4.30  [  320/  469]\n",
            "loss: 2337.84 = -logpx[139328.4], -det[-39252.3], -norms[-356908.9], reg[0.0659]; bits/pixel: 4.30  [  330/  469]\n",
            "loss: 2285.61 = -logpx[131129.0], -det[-37746.6], -norms[-356901.7], reg[0.0660]; bits/pixel: 4.21  [  340/  469]\n",
            "loss: 2281.96 = -logpx[133721.5], -det[-40945.2], -norms[-356762.1], reg[0.0660]; bits/pixel: 4.20  [  350/  469]\n",
            "loss: 2438.92 = -logpx[150632.3], -det[-37944.0], -norms[-356584.0], reg[0.0661]; bits/pixel: 4.49  [  360/  469]\n",
            "loss: 2357.11 = -logpx[145652.5], -det[-43701.2], -norms[-356318.4], reg[0.0662]; bits/pixel: 4.34  [  370/  469]\n",
            "loss: 2336.13 = -logpx[141677.9], -det[-42386.2], -norms[-356344.4], reg[0.0662]; bits/pixel: 4.30  [  380/  469]\n",
            "loss: 2356.90 = -logpx[139563.6], -det[-37535.5], -norms[-356422.4], reg[0.0663]; bits/pixel: 4.34  [  390/  469]\n",
            "loss: 2336.28 = -logpx[140562.9], -det[-41402.6], -norms[-356194.0], reg[0.0664]; bits/pixel: 4.30  [  400/  469]\n",
            "loss: 2644.19 = -logpx[175173.4], -det[-36614.7], -norms[-356178.8], reg[0.0665]; bits/pixel: 4.87  [  410/  469]\n",
            "loss: 2389.28 = -logpx[144910.0], -det[-38773.3], -norms[-356385.3], reg[0.0665]; bits/pixel: 4.40  [  420/  469]\n",
            "loss: 2283.52 = -logpx[133477.3], -det[-40592.7], -norms[-356671.6], reg[0.0666]; bits/pixel: 4.20  [  430/  469]\n",
            "loss: 2305.90 = -logpx[138513.4], -det[-42230.4], -norms[-357205.0], reg[0.0667]; bits/pixel: 4.24  [  440/  469]\n",
            "loss: 2333.55 = -logpx[142296.9], -det[-42415.8], -norms[-357263.3], reg[0.0668]; bits/pixel: 4.29  [  450/  469]\n",
            "loss: 2298.45 = -logpx[135798.4], -det[-40262.5], -norms[-357410.9], reg[0.0668]; bits/pixel: 4.23  [  460/  469]\n",
            "Test Error: \n",
            " Avg loss: 2394.71; 4.41 \n",
            "\n",
            "Done -  /content/drive/MyDrive/STDL_Assignment_1_Jinwon/Qs3mnist-19.model\n"
          ]
        }
      ],
      "source": [
        "model.train()\n",
        "\n",
        "best_validation = None\n",
        "PATH = '/content/drive/MyDrive/STDL_Assignment_1_Jinwon/Qs3'\n",
        "for t in range(epochs):\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(train_loader, model, loss_fn, optimizer, batch_size)\n",
        "    validation_loss = test_loop(test_loader, model, loss_fn)\n",
        "\n",
        "    torch.save({\n",
        "        'epoch': t,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'loss': validation_loss,\n",
        "    }, PATH + f'mnist-{t}.model')\n",
        "\n",
        "    if best_validation is None or validation_loss < best_validation:\n",
        "        best_validation = validation_loss\n",
        "        best_path = PATH + f'mnist-{t}.model'\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "print(\"Done - \", best_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-03-15T01:45:49.871919Z",
          "start_time": "2022-03-15T01:45:49.331923Z"
        },
        "id": "6qkarhKRD7yS"
      },
      "outputs": [],
      "source": [
        "model = NormalizingFlowMNist(num_coupling=4, num_final_coupling=1, planes=256).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "#checkpoint = torch.load('checkpoints/mnist-1.model')\n",
        "checkpoint = torch.load(best_path)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "epoch = checkpoint['epoch']\n",
        "loss = checkpoint['loss']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-14T02:14:36.224357Z",
          "start_time": "2022-02-14T02:14:36.221330Z"
        },
        "id": "Xp6-EdccD7yT"
      },
      "source": [
        "# Debug - Check that foward/reverse are (about) equal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-03-15T01:45:50.125022Z",
          "start_time": "2022-03-15T01:45:49.873735Z"
        },
        "id": "EFrKYUMQD7yT",
        "outputId": "94e1dd4d-8a61-451f-ecab-5c523df9b9a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(True, device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "# DEBUG - Checkmodel[s]\n",
        "model.validate()\n",
        "\n",
        "with torch.no_grad():\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False) #shuffle=True)\n",
        "    for x, _ in train_loader:\n",
        "        x_pre = pre_process(x).to(device)\n",
        "        y, s, norms, scale = model(x_pre)\n",
        "        break\n",
        "\n",
        "model.train()\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    xp = model(y)\n",
        "    x_post = post_process(xp)\n",
        "\n",
        "diff = x.to(device) - x_post\n",
        "print(torch.any(torch.abs(diff) > 1 / 255))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Interpolation (Linear, Sinusoidal)\n",
        "model.validate()\n",
        "\n",
        "with torch.no_grad():\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False) #shuffle=True)\n",
        "    for x, _ in train_loader:\n",
        "        x_pre = pre_process(x).to(device)\n",
        "        y, s, norms, scale = model(x_pre)\n",
        "        break\n",
        "\n",
        "#Get latent space\n",
        "z1, _, _, _ = model(x_pre[0].unsqueeze(0))\n",
        "z2, _, _, _ = model(x_pre[1].unsqueeze(0))\n",
        "\n",
        "model.eval()\n",
        "\n",
        "#Define lambda (0 to 1, step : 0.1)\n",
        "lamb = tensor = torch.arange(0, 1.1, 0.1).to(device)\n",
        "z_linear = (1 - lamb[:, None]) * z1 + lamb[:, None] * z2\n",
        "z_sinusoidal = (1 - torch.sin(lamb[:, None] * np.pi / 2)) * z1 + torch.sin(lamb[:, None] * np.pi / 2) * z2\n",
        "\n",
        "with torch.no_grad():\n",
        "    x_linear = model(z_linear)\n",
        "    x_sinusoidal = model(z_sinusoidal)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(15, 2))\n",
        "for i, x in enumerate(x_linear):\n",
        "    plt.subplot(1, len(lamb), i + 1)\n",
        "    plt.imshow(x[0].cpu().detach().numpy(), cmap='gray')\n",
        "    plt.title(f'λ={lamb[i]:.1f}')\n",
        "    plt.axis('off')\n",
        "plt.suptitle('Linear Interpolation')\n",
        "plt.show()\n",
        "plt.figure(figsize=(15, 2))\n",
        "for i, x in enumerate(x_sinusoidal):\n",
        "    plt.subplot(1, len(lamb), i + 1)\n",
        "    plt.imshow(x[0].cpu().detach().numpy(), cmap='gray')\n",
        "    plt.title(f'λ={lamb[i]:.1f}')\n",
        "    plt.axis('off')\n",
        "plt.suptitle('Sinusoidal Interpolation')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NotlPgezUdIL",
        "outputId": "3f82d7b8-7e89-48a1-9386-e5022ccac7f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x200 with 11 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x200 with 11 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-03-15T01:45:50.135401Z",
          "start_time": "2022-03-15T01:45:50.127426Z"
        },
        "id": "2apfvUvID7yT",
        "outputId": "380bdc96-08ce-4df1-ca35-4b04e18e2927",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 1, 28, 28])\n",
            "81 1 10 13 -0.003921628\n"
          ]
        }
      ],
      "source": [
        "print(diff.shape)\n",
        "for i in range(batch_size):\n",
        "    if torch.any(torch.abs(diff[i]) > 1 / 255):\n",
        "        #print(diff[i])\n",
        "        for j in range(28):\n",
        "            for k in range(28):\n",
        "                if torch.any(torch.abs(diff[i, 0, j, k]) > 1 / 255):\n",
        "                    print(i, 1, j, k, diff[i, 0, j, k].cpu().numpy())\n",
        "                    break\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-03-15T01:45:50.448219Z",
          "start_time": "2022-03-15T01:45:50.136892Z"
        },
        "id": "WvfCCV7yD7yT",
        "outputId": "f089904e-69f3-4dd9-82ca-f6a4a3aa2a67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count    100352.000000\n",
            "mean          0.034470\n",
            "std           0.970233\n",
            "min         -11.672347\n",
            "25%          -0.405276\n",
            "50%           0.026166\n",
            "75%           0.456320\n",
            "max          70.528587\n",
            "dtype: float64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "s = pd.Series(torch.flatten(y).cpu().numpy())\n",
        "print(s.describe())\n",
        "s.hist(bins=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-03-15T01:45:50.774422Z",
          "start_time": "2022-03-15T01:45:50.449830Z"
        },
        "scrolled": false,
        "id": "p-0hB-i-D7yT",
        "outputId": "3fd95377-d986-40d6-fb42-4b6d700d172c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 3, 3\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(train_dataset), size=(1,)).item()\n",
        "    img, label = train_dataset[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(str(label))\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-03-15T01:45:50.819830Z",
          "start_time": "2022-03-15T01:45:50.775911Z"
        },
        "id": "s_GMF8n6D7yT",
        "outputId": "3538f48b-8371-412d-e75c-cfda88f69303",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 784])\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    X = torch.Tensor(torch.randn((1, 28 * 28 * 1))).to(device)\n",
        "    Y = model(X)\n",
        "    print(X.shape)\n",
        "    samples = post_process(Y).cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-03-15T01:45:52.763750Z",
          "start_time": "2022-03-15T01:45:50.821508Z"
        },
        "id": "62FAudVmD7yT",
        "outputId": "dca1c684-4de5-4b10-fe10-890dff4592c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x1500 with 8 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "model.eval()\n",
        "\n",
        "cols, rows = 8, 1\n",
        "with torch.no_grad():\n",
        "    X = torch.Tensor(torch.normal(torch.zeros(cols * rows, 28 * 28 * 1),\n",
        "                                  torch.ones(cols * rows, 28 * 28 * 1))).to(device)\n",
        "    Y = model(X)\n",
        "    samples = post_process(Y).cpu().numpy()\n",
        "\n",
        "figure = plt.figure(figsize=(15, 15))\n",
        "for i in range(1, cols * rows + 1):\n",
        "    img = samples[i - 1]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sui0yE12D7yT"
      },
      "source": [
        "# 2022-03-14\n",
        "\n",
        "* Figured out why I was getting negative LL!  It was because I wasn't accounting for `x/255` transform that I did in the preprocessing step.  This is just a linear scale on each pixel, so it adds `log(255)` to the loss function or `log(255)/log(2)` bits per pixel.\n",
        "* I lowered the learning rate to `0.0005` because it looks like it was overfitting after one epoch and I changed batchnorm momentum to `0.005` (from `0.01`) since I was worried about too much bias to recent batches (and not enough batches).\n",
        "* I got a loss of 1.92 bits/pixel, which is not as good as GLOW results of 1.26 bits/pixel from this paper:\n",
        "  * `Do Deep Generative Models Know What They Don’t Know Now?`, Nalisnick et al\n",
        "  * But I'm using an older architecture so it's probably not terrible\n",
        "* Results still look pretty crappy (but sharp), good enough for now\n",
        "  \n",
        "My goodness!\n",
        "* Found a big bug. My model has function parameters of `num_coupling, num_final_coupling, planes` but I only passed in `(12, 32)` thinking that 32 represented planes, but it was actually coupling layers!\n",
        "* This masked another bug where I was ignoring the `12/32` last final coupling layers because my for loop ran from `reversed(range(num_coupling, num_final_coupling))`, where it should have actually been `range(num_coupling, num_coupling + num_final_coupling)`!\n",
        "    * Same issue on forward pass, so that's probably why it kind of worked?\n",
        "    * Is that why I was getting pretty garbage output?\n",
        "* Output looks a bit cleaner now and a bit more plausible but getting 1.67 bits/pixel, which isn't terrible (compared to 1.26 for GLOW):\n",
        "\n",
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gq0rR18GD7yU"
      },
      "source": [
        "# 2022-03-12\n",
        "\n",
        "* Found another bug from the last change.  Changed the initialization of `s_scale, t_scale, t_bias` all back to zero (originally small 0.1 norm for scale, and zero for bias; then to ones for the s_scale).  \n",
        "  * The reason is that we want to initialize so that `s * x + t` is just a pass through\n",
        "  * So of course we want `t` to be zero --> So we set the `t_scale, t_bias` to be zero\n",
        "  * And we want `s=exp(s_scale*...) = 1`, therefore we also want `s_scale = 0`\n",
        "* Also added checkpointing to epochs so I don't have to fiddle around with retrainign with different epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x00ED2xsD7yU"
      },
      "source": [
        "# 2022-03-06\n",
        "\n",
        "* Found a bug in BatchNorm code... wasn't taking log of the denominator!\n",
        "    * Fixed it and added back batchnorm to *every* layer (including ones outputting to y)\n",
        "* Samples still look funny (although they are sharp)\n",
        "    * I mean it's possible that the validation loss (bits/pixel) are good but the image is bad\n",
        "* Also expecting that my loss shouldn't go negative with the uniform noise I'm adding, going to investigate that...\n",
        "* Noticed few things:\n",
        "    * Changed momentum on batch layers to 0.01 -- if it's too high than the norm layer will \"tune\" (i.e. overfit) too well to the current batch, making it not so useful?\n",
        "        * This may also have caused issues with not having a good \"sample\" of the overall mean even for prediction\n",
        "    * BUG? I was initializing the s-scale and t-scale to small numbers near zero -- instead I initialized them straight to `1` because my prior for these really should just be pass throughs\n",
        "    * BUG: During validation (MNIST test set), I left the batch layer to keep changing the running mean!   This definitely was not intended, so I had to modify batch again to allow one to pass in whether or not we're in validation.\n",
        "* Now I'm not getting super negative bits/pixel in training (it's hovering between -0.5 to 1).  Let's see where this training finishes and how the images look."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-sgZbGxD7yU"
      },
      "source": [
        "# 2022-02-27\n",
        "\n",
        "Experiment 1:\n",
        "* Implemented the moving average batch norm, didn't really do that much (I think)\n",
        "* Still have issues if I add batch norm on the final checkboarding layers\n",
        "  * I wonder if that's also an issue with the vars when I factor them out\n",
        "  \n",
        "Experiment 2:\n",
        "* Removed batch norm from coupling layers before I factor out the vars into the final z values\n",
        "* Also reduced number of BasicBlocks (Resnet) to 2 from 4 (since I think MNIST shouldn't need that many)...\n",
        "* Increase batch size from 10 to 25\n",
        "   * Small batches may cause too much variance?\n",
        "* Now I'm getting negative loss again (the positive losses are probably due to batch norm making it normally distributed)\n",
        "  * Probably going to get not exactly zero-mean, std=1 on the z vars\n",
        "* Loss around -0.3\n",
        "\n",
        "Huzzah!  It looks like I have really crisp numbers now.  Let's try to train on the entire MNIST.\n",
        "\n",
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlXPSV91D7yU"
      },
      "source": [
        "# 2022-02-26\n",
        "\n",
        "* Had to build my own batch norm so I could return the scaling factor AND support the reverse operation\n",
        "* Holy molly, batch norm basically made the whole thing work!  Trying to overfit on a sample of 10 images, I've gotten the clearest images I've seen yet!\n",
        "  * Was able to use learning rate of 0.01 without much issue\n",
        "  * Loss also didn't decrease to negative territory, got something 1.74\n",
        "  * With the introduction of batch norm, the forward and backward pass test is not exact (I guess because of batch norm)\n",
        "* Interestingly, the histogram is very close to std norm: mean = 0.002, std = 0.96\n",
        "\n",
        "![image.png](attachment:image.png)\n",
        "\n",
        "Next up try to fit a larger sample..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wi2tBiMgD7yU"
      },
      "source": [
        "* Training on 100 seems to be worse... but it may be because of the way I'm limiting the batches\n",
        "* Lowest loss is around 2.5 (with randomization)\n",
        "\n",
        "NEXT:\n",
        "\n",
        "* Removing batch-norm right before latent vars (seems to have some problems)\n",
        "* Might need the averaging batch loss described in the paper?\n",
        "\n",
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2gZurHsD7yU"
      },
      "source": [
        "# 2022-02-20\n",
        "\n",
        "NEXT:\n",
        "\n",
        "* Use batch norm across each coupling layer\n",
        "    * Cannot use instance norm because you don't know mean and std when you reverse things!\n",
        "    * Instead with batch norm you just use the running average when you use the reverse network!\n",
        "* But will need to calculate `var` for the loss function, so will probably have to re-implement it, see these implementations to get you started:\n",
        "    * https://discuss.pytorch.org/t/implementing-batchnorm-in-pytorch-problem-with-updating-self-running-mean-and-self-running-var/49314/5\n",
        "    * https://discuss.pytorch.org/t/am-i-too-dumb-to-implement-instance-norm/16672\n",
        "    * https://pytorch.org/docs/stable/_modules/torch/nn/modules/batchnorm.html#BatchNorm2d\n",
        "* Should probably implement it as a layer (see second link) so that I can save the running statistics properly and encapsulate the different behavior in testing/training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9GNVgKJD7yU"
      },
      "source": [
        "# 2022-02-18\n",
        "\n",
        "* Changed up the s/t functions:\n",
        "   * Use a conv3x3 to expand to `planes`, use regular resnet blocks (from PyTorch), then use conv3x3 to convert back to inplanes\n",
        "   * Use `InstanceNorm2D`, which seems to be better for generative models and makes training a lot faster\n",
        "   * Can get to loss lower than -5.4/pxel and quality goes up\n",
        "* Need to tune epochs and lr to make sure get a good loss\n",
        "   \n",
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-cKejK9D7yU"
      },
      "source": [
        "* Same as above with 100 images and some tuning of epochs and lr\n",
        "\n",
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44bEm_0GD7yU"
      },
      "source": [
        "# 2022-02-13\n",
        "\n",
        "* Adding several checkerboard coupling layers at the end (with just one super-scale iteration) seemed to make fitting on a single image much better (sampling from a standard normal -- no more sampling from zeros):\n",
        "\n",
        "  * I suspect these coupling layers have very limited transformation power, that's why you need so many of them to even translate things.\n",
        "  * Detail: I'm still using pixel (no pre-processing) but am adding the U(0,1) pixel noise\n",
        "![image.png](attachment:image.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-13T23:37:17.151991Z",
          "start_time": "2022-02-13T23:37:17.146659Z"
        },
        "id": "LKYiSRmBD7yU"
      },
      "source": [
        "* When I try to fit two images though, I get something that looks like a superposition (between \"5\" and \"0\"):\n",
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJD60_wLD7yU"
      },
      "source": [
        "* Adding two multi-scale iterations (3 checker, 1 squeeze, 3 channel, 3 checker, 1 squeeze, 3 channel) + 4 checker) with two images\n",
        "    * Gets me closer to something that looks right\n",
        "    * It's still confusing things but can sometimes, *sort of* distiguish between \"5\" and \"0\" making some parts of the 0 darker to make the 5 standout (and vice versa)\n",
        "* I probably need the factoring out of variables that theoretically will have local/global sort of effect?    \n",
        "\n",
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pp7YmgEOD7yU"
      },
      "source": [
        "* Added the factoring code, surprisingly it wasn't that bad.  Pytorch is pretty easy to work with!\n",
        "* I can *sort of* do 2 images now?  In some cases, you have a clear distinction between \"5\" and \"0\".  In others, it's mixed.\n",
        "    * I think I just need longer training to perfect them... let's see.\n",
        "    * More noise of course, but maybe because I need more training?\n",
        "\n",
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zD6chKaZD7yU"
      },
      "source": [
        "* More training and training with 10 points, get something kind of blurry, but sort of recognizable\n",
        "* Need to do more investigation why the pictures aren't that sharp -- not clear to me at the moment\n",
        "* I tried increasing planes 64 -> 96, still get kind of the same loss (about -3.8/pixel)\n",
        "* The distribution mean is close to 0 (0.04) but std is around 0.4, not close to 1 (which was what it was when I trained a single example above)\n",
        "* Feels like I need more capacity\n",
        "\n",
        "TODO:\n",
        "\n",
        "* Try to increase number of bottleneck layers (4 -> 8)?\n",
        "\n",
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfuJZr9sD7yU"
      },
      "source": [
        "# 2022-02-12\n",
        "\n",
        "* Implemented the multi-scale architecture (with just one iteration)\n",
        "    * 3 checkerboard, squeeze, 3 channel\n",
        "* I can *sort of* overfit on a single image, but if I try to increase number of images, I still don't get anything that resembles a number.\n",
        "    * My conclusion is that checkboard alone cannot model an overal image, esp. if you are just going back and forth on the same variables.\n",
        "    * You want some mixing of variables (not just swapping back and forth), especially because these are affine transformations.\n",
        "    * Additionally, since the original # of channels = 1 (greyscale image), the conv operation is probably not doing much, as opposed to after squeeze, you have many more channels to work with\n",
        "* However... it does suggest something more plausible:\n",
        "    * Some center of mass\n",
        "    * Very dark and/or light pixels\n",
        "* NEXT:\n",
        "    * Try to implement more than one iteration of multi-scale architecture\n",
        "    * AND partition out some vars after each iteration (like the paper)\n",
        "    * Supposedly the lower Gaussians model the coarse detail, while the later ones will model finer detail\n",
        "    * If that is true, then it explains why I just get a big blob in the center\n",
        "\n",
        "\n",
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rsJVXtXD7yV"
      },
      "source": [
        "# 2022-02-10\n",
        "\n",
        "* Tried adding scale/bias parameters to make affine transform in the \"t\" var -- didn't really do anything\n",
        "* Tried to overfit on a **single** image\n",
        "    * By sampling from zeros(.), I can generate something *close* to the original image (not a perfect match) has a bit of noise still\n",
        "    * Strange I can't get a better fit... why is there still so much noise?\n",
        "\n",
        "![image.png](attachment:image.png)\n",
        "\n",
        "* Tried removing U(0,1) pixel noise -- didn't seem to work\n",
        "* Tried removing determinant from loss function -- didn't seem work\n",
        "* Tried removing this post-processing -- get a much clearer image ???\n",
        "* Tried training with 10 images -- get garbage when sampling from normal (but lots of 0/255)\n",
        "\n",
        "INVESTIGATE:\n",
        "\n",
        "* What is going on with post-processing?\n",
        "* Why doesn't training with 10 images work?\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlEY_BhlD7yV"
      },
      "source": [
        "# 2022-02-05\n",
        "\n",
        "* Looks like the inverse operation is working as expected:\n",
        "  * Pass in a vector in forward pass pixels -> pre_process -> gaussian -> post_process -> pixels and get the same number (with some small 10e-8 errors, also had some 10-3 errors but much more seldom)\n",
        "* Added L2 regularizer on s_scale param, not much changed\n",
        "* I keep getting a shifted distribution (negative mean) and less than 1 std when I take a batch of training and pass it through a forward pass to get z\n",
        "  * Tried removing the det terms and it still looks skewed\n",
        "* INVESTIGATE: This seems like it's relevant because if I'm sampling from a 0-mean Gaussian but real examples always end up shifted left, then of course I'm going to generate bad images\n",
        "* ANOTHER IDEA: overfit on a much smaller training set (10, 100 images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDp8KJjbD7yW"
      },
      "source": [
        "# 2022-02-02\n",
        "\n",
        "* Implemented post-processing to convert back to pixel space but still seems like I'm getting garbage, need to debug further.\n",
        "* Ideas to double check:\n",
        "    * loss function\n",
        "    * inverse operation (should check back and forwards give the same answer)\n",
        "    * Check that forward pass actually gives something Gaussian like..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdZeDJAuD7ya"
      },
      "source": [
        "# 2022-02-01\n",
        "\n",
        "* Finally got around to actually generating images... and they are just noise!\n",
        "* Might be a bug in the network, might be that I need to increase capacity of network.  Now the fun starts!\n",
        "    * I might also have to add the \"multi-scale architecture\"\n",
        "    * Another issue might be the batch-norm layers, which probably behave very differently in testing -- I actually did comment it out.\n",
        "    \n",
        "    \n",
        "I NEED TO CONVERT BACK TO PIXEL SPACE!!!!\n",
        "\n",
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAcsMW8ND7ya"
      },
      "source": [
        "# 2022-01-31\n",
        "\n",
        "* The negative values are coming from determinant because log |df/dx| = log(|exp(s)|) = s\n",
        "* So the loss is essentially trying to make `s` very large (more negative).\n",
        "* Theoretically, it's possible by allowing the unmasked variables to almost exactly predict the masked variables, so you could multiply by a large number s(unmasked) vars, and adjust by t(unmasked) = -s(unmasked) * unmasked, to get the maximum s*masked_x - t = s*unmasked_x - s*unmasked_x = 0, which is the maximum density point for the Gaussian\n",
        "* Need to look into how the determinant (i.e. s) is be generated.  From prelim debugging above, it looks like it's generating a lot of zeros (even in unmasked positions), so I have to sort out why that's the case.\n",
        "\n",
        "Wait... found a bug.  I was putting the determinant as `mask * s` instead of the correct `(1 - mask) * s`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzZShP4LD7ya"
      },
      "source": [
        "# 2022-01-29\n",
        "\n",
        "* Getting lots of NaNs -- debugged a bunch of things:\n",
        "    * Removed Resnet\n",
        "    * Removed exp()\n",
        "    * Made forward pass a simple feedforward\n",
        "* But it looks like issue is the data???    \n",
        "    * The stupid paper said the transform should be `logit(alpha + (1-alpha)*x/256)`...\n",
        "    * Data is originally in [0,1] (pytorch dataset)\n",
        "    * Convert back to pixels multiply by 255\n",
        "    * Add jitter to get upper bound on bits per pixel (see my post)\n",
        "    * Range is now [0, 256]\n",
        "    * Suggested alpha=0.05 (I had a bug and used 0.5)\n",
        "    * But that gets you really close to 256 (jitter is always less than 1.0 though) e.g.i logit(0.05 + 0.95 * ~255.99/256) ~= \\inf!\n",
        "    * Instead, I used this `logit(alpha + (1-alpha - 0.05)*x/256)`, which is symmetrical...\n",
        "    \n",
        "NEXT STEPS:\n",
        "* So things look good now, except that I get a negative loss, which shouldn't happen (after applying jitter)???\n",
        "    * It's because I need a new uniform noise sample per EPOCH???\n",
        "    * Or is it because I'm using continuous variables on the output?  So maybe I just need to measure this \"loss\" when I reverse the network?  \n",
        "        * It's probably this... if it's a continuous output, the log density surely doesn't need to be positive (vs. if I were directly outputting pixel values).\n",
        "        \n",
        "        \n",
        "I THINK I FIGURED IT OUT:  IT's becuase I didn't have the 1/sqrt(2pi) in the log-likelihood!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "qGuE_2p1D7ya"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}